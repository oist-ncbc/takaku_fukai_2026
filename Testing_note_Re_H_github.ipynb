{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.01):\n",
    "   \n",
    "    x = np.loadtxt(\"primal_long131test_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long131test_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0\n",
    "        var = 1\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main(num):\n",
    "    training_size = 200\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "    sparse = 1\n",
    "#     model_path = 'model/ReModeltest_30reset3addlong_estref_L2_interRNNrand_Reinh_AddRe_OUT5_131_s'+str(num)+'_100_4.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s'+str(num)+'_100_1_2.pth'\n",
    "#     model_path = 'model/ReModeltest_30reset3addlong_L2_interRNNrand_Reinh_AddRe_OUT5_131_s10_100_1.pth'\n",
    "#     model_path = 'model/ReModeltest_30addlong_interRNNrand_Reinh_AddRe_OUT5_131_s3_100_2.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_long_s7_200_2_1_'+str(num)+'.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_181_s'+str(num)+'_100_1.pth'\n",
    "#     model_path = 'model/ReModel_LSTMrand_noise_long131test_s'+str(num)+'_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_11311_s6_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H121_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H121_s3_100_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H2v121_s'+str(num)+'_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H2v121_s9_100_1.pth'\n",
    "#     model_path = 'model/R20_H/ReModel_L2_interRNNrand_OUT1_121H_s'+str(num)+'_100_1_epoch155.pth'\n",
    "    model_path = 'model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s'+str(num)+'_100_1_epoch160.pth'\n",
    "#     model_path = 'model/R20_uniPFC_H/ReModel_L2_interRNNrand_OUT1_uniPFC_121H_s'+str(num)+'_100_1_epoch95.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "    \n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "    test_x = mkOwnDataSet(test_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    for k in range(data_limit):\n",
    "#             print(data[k].shape)\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(torch.rand(10,2),hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*6):\n",
    "#             output += torch.randn(10,2)*0.01\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:100,0,0],traj[:100,0,1])\n",
    "    plt.plot(traj[100:,0,0],traj[100:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_w = np.array(p.data)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(10,5))\n",
    "    ax1 = fig2.add_subplot(141)\n",
    "    ax2 = fig2.add_subplot(142)\n",
    "    axre = fig2.add_subplot(143)\n",
    "    axout = fig2.add_subplot(144)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    axout.imshow(Output_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "    axout.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Output_w),np.min(Output_w)))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_w = np.array(p.data)\n",
    "                \n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(131)\n",
    "    ax2 = fig2.add_subplot(132)\n",
    "    axre = fig2.add_subplot(133)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))                \n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    HPC_feature = np.copy(feature)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "# #     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "# #     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "#     plt.show()\n",
    "\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    colors = ['C1','C2','C3','C4']\n",
    "    for i in range(4):\n",
    "        start = i*120\n",
    "        end = (i+1)*120\n",
    "        mid = int((start+end)/2)\n",
    "        ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2], color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start+40:start+41, 0], feature[start+40:start+41, 1], feature[start+40:start+41, 2],  \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[mid:mid+1, 0], feature[mid:mid+1, 1], feature[mid:mid+1, 2], \"o\", color=colors[i], alpha=0.5)  \n",
    "        ax3d.plot(feature[end:end+1, 0], feature[end:end+1, 1], feature[end:end+1, 2], \"o\", color=colors[i], alpha=0.5)        \n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    PFC_feature = np.copy(feature)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "#     colors = ['C1','C2','C3','C4']\n",
    "#     for i in range(4):\n",
    "#         start = i*120\n",
    "#         end = (i+1)*120\n",
    "#         mid = int((start+end)/2)\n",
    "#         ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2], color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[start+40:start+41, 0], feature[start+40:start+41, 1], feature[start+40:start+41, 2],  \"o\", color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[mid:mid+1, 0], feature[mid:mid+1, 1], feature[mid:mid+1, 2], \"o\", color=colors[i], alpha=0.5)  \n",
    "#         ax3d.plot(feature[end:end+1, 0], feature[end:end+1, 1], feature[end:end+1, 2], \"o\", color=colors[i], alpha=0.5)        \n",
    "# #     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    Re_feature = np.copy(feature)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     linelist = search_delay(traj[:,0])\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "#     plt.vlines(linelist,0,1)\n",
    "\n",
    "#     fig2d = plt.figure()\n",
    "#     plt.plot(feature[:200, 0], feature[:200, 1], alpha=0.8)\n",
    "#     plt.plot(feature[0:1, 0], feature[0:1, 1], \"o\", alpha=1)\n",
    "#     plt.show()\n",
    "    \n",
    "    return PFC_feature\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    features = []\n",
    "    for i in range(1):\n",
    "        features.append(main(i+1))\n",
    "\n",
    "#     fig2d = plt.figure()\n",
    "#     for feature in features:\n",
    "#         plt.plot(feature[:200, 0], feature[:200, 1], alpha=0.2)\n",
    "#         plt.plot(feature[0:1, 0], feature[0:1, 1], \"o\", alpha=1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.01):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.RNNCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 10\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0\n",
    "        var = 1\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size)*const, torch.ones(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        Re_hidden = torch.ones(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def hidden_randinsert(self,hidden):\n",
    "        var = 1\n",
    "        insert = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "#         insert = torch.rand(self.batch_size, self.hidden_size)*var\n",
    "        return [hidden[0],insert,hidden[2]]\n",
    "    \n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s'+str(num)+'_100_3.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s1_100_3_plus_'+str(num)+'.pth'\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_1.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 20\n",
    "    for k in range(data_limit):\n",
    "#             print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(torch.rand(10,2),hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    hidden = rnn.hidden_randinsert(hidden)\n",
    "    for k in range(data.shape[0]*4):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:100,0,0],traj[:100,0,1])\n",
    "    plt.plot(traj[100:,0,0],traj[100:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "#     for n, p in rnn.named_parameters():\n",
    "#             if n == \"PFC.weight_ih\":\n",
    "#                 PFC_w = np.array(p.data)\n",
    "#             if n == \"HPC.weight_ih\":\n",
    "#                 HPC_w = np.array(p.data)\n",
    "#             if n == \"Re.weight_ih\":\n",
    "#                 Re_w = np.array(p.data)\n",
    "\n",
    "#     fig2 = plt.figure()\n",
    "#     ax1 = fig2.add_subplot(131)\n",
    "#     ax2 = fig2.add_subplot(132)\n",
    "#     axre = fig2.add_subplot(133)\n",
    "    \n",
    "#     ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "#     ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "#     axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "#     ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "#     ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "#     axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_w = np.array(p.data)\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(131)\n",
    "    ax2 = fig2.add_subplot(132)\n",
    "    axre = fig2.add_subplot(133)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))                \n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for i in range(10):\n",
    "        main(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 200\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/ReModel_mixRNN_long_s'+str(num)+'_200_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_Yl_s5_200_5_2000.pth'\n",
    "    filename = \"primal_Y_long\"\n",
    "    print(model_path)\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 200\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*1):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "    filename = \"primal_long\"\n",
    "    print(model_path)\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    hidden = rnn.initHidden()\n",
    "            \n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*1):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    print(feature[200:])\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "#     ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for i in range(1):\n",
    "        main(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distance(list_a,list_b):\n",
    "    result = []\n",
    "    for point in list_b:\n",
    "        dis_list = []\n",
    "        for target in list_a:\n",
    "            dis_list.append(np.linalg.norm(point[:3] - target[:3]))\n",
    "        result.append(np.min(dis_list))\n",
    "    return np.array(result)\n",
    "\n",
    "def overlap_coefficient(list_a,list_b):\n",
    "    threshold = 0.025\n",
    "    #Aの各点からBにある任意の点の最小距離を計算\n",
    "    distance = check_distance(list_a,list_b)\n",
    "    \n",
    "    #集合Aの要素数を取得\n",
    "    num_listA = len(list_a)\n",
    "    return distance\n",
    "\n",
    "def plot_distance(data1,data2):\n",
    "    r = data1\n",
    "    l = data2\n",
    "    \n",
    "    overlap=overlap_coefficient(r,l)\n",
    "\n",
    "    plt.figure()\n",
    "#     plt.ylim(0,1)\n",
    "    plt.plot(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s9_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "        # if n == \"PFC.weight_ih\":\n",
    "        #     p.data[hidden_size:,hidden_size:].sub_(p.data[hidden_size:,hidden_size:])\n",
    "        if n == \"HPC.weight_ih\":\n",
    "            p.data[:,inputsize:].sub_(p.data[:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 100\n",
    "    ynum = 100\n",
    "    initx = 0.2\n",
    "    endx = 0.8\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    place = np.zeros((hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    data_limit = 20\n",
    "    for y in range(ynum+1):\n",
    "        for x in range(xnum+1):\n",
    "            hidden = rnn.initHidden()\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            for k in range(data_limit):\n",
    "                    #print(data[k].shape)\n",
    "                    output,hidden = rnn(point,hidden)\n",
    "            for n in range(hidden_size):\n",
    "                place[n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "                grid[n].append([initx+widex*x,widey*y,hidden[1][0].tolist()[0][n]])\n",
    "                \n",
    "    grid = np.array(grid)\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[i],cmap='jet',origin='lower',interpolation='bilinear', vmin=0)\n",
    "        plt.show()\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(grid[i,:,0],grid[i,:,1],grid[i,:,2])\n",
    "#         plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        x = np.arange(initx, endx+widex, widex)\n",
    "        y = np.arange(inity, endy+widey, widey)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = place[i]\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(x, y, z, cmap='jet')\n",
    "        plt.show()\n",
    "    \n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#init ari\n",
    "\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        ims.append([img])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         # if n == \"PFC.weight_ih\":\n",
    "#         #     p.data[hidden_size:,hidden_size:].sub_(p.data[hidden_size:,hidden_size:])\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[hidden_size:,inputsize:].sub_(p.data[hidden_size:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 20\n",
    "    ynum = 20\n",
    "    initx = 0\n",
    "    endx = 1\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    data_limit = 100\n",
    "    place = np.zeros((data_limit,hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    \n",
    "    x_list = np.array(range(xnum+1))\n",
    "    y_list = np.array(range(ynum+1))\n",
    "    np.random.shuffle(y_list)\n",
    "    for y in y_list:\n",
    "        np.random.shuffle(x_list)\n",
    "        for x in x_list:\n",
    "            hidden = rnn.initHidden()\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            for k in range(data_limit):\n",
    "                    #print(data[k].shape)\n",
    "                    output,hidden = rnn(point,hidden)\n",
    "                    for n in range(hidden_size):\n",
    "                        place[k][n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[0][i],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        plt.show()\n",
    "        \n",
    "        MakeAnimation_img(place[:,i],\"test!!!\"+str(i))\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#init nashi\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "        if n == \"HPC.weight_ih\":\n",
    "            p.data[:,inputsize:].sub_(p.data[:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 50\n",
    "    ynum = 50\n",
    "    initx = 0.2\n",
    "    endx = 0.8\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    place = np.zeros((hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    y_list = np.array(range(ynum+1))\n",
    "    np.random.shuffle(y_list)\n",
    "    for y in y_list:\n",
    "        x_list = np.array(range(xnum+1))\n",
    "        np.random.shuffle(x_list)\n",
    "        for x in x_list:\n",
    "            #if y % 2 == 0: x = xnum - x\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            output,hidden = rnn(point,hidden)\n",
    "            for n in range(hidden_size):\n",
    "                place[n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "                grid[n].append([initx+widex*x,widey*y,hidden[1][0].tolist()[0][n]])\n",
    "                \n",
    "    grid = np.array(grid)\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[i],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        plt.show()\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(grid[i,:,0],grid[i,:,1],grid[i,:,2])\n",
    "#         plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        x = np.arange(initx, endx+widex, widex)\n",
    "        y = np.arange(inity, endy+widey, widey)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = place[i]\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(x, y, z, cmap='jet')\n",
    "        plt.show()\n",
    "    \n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal_long_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 200\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "\n",
    "    target = [40,60]\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[target[0]:target[1],0:20]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[target[0]:target[1],inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)[0:20,0:20]\n",
    "                Re_w /= np.max(Re_w)\n",
    "                \n",
    "    fig = plt.figure()\n",
    "    G = nx.from_numpy_matrix(np.matrix(PFC_w), create_using=nx.DiGraph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    nx.draw(G, layout)\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(121)\n",
    "    ax2 = fig2.add_subplot(122)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    Renode = [(\"Re\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(PFCnode, bipartite=0)\n",
    "    A.add_nodes_from(HPCnode, bipartite=1)\n",
    "    A.add_nodes_from(Renode, bipartite=2)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if PFC_w[i,k]>0:\n",
    "                A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "            if Re_w[i,k]>0:\n",
    "                A.add_edge(Renode[i],PFCnode[k],weight=Re_w[i,k])\n",
    "    pos = {}\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(PFCnode))\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    pos.update((node, (3, index)) for index, node in enumerate(Renode))\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.eigenvector_centrality(A,weight=True)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(np.count_nonzero(PFC_w>0.3, axis=0),np.count_nonzero(HPC_w>0.3, axis=0),np.count_nonzero(Re_w>0.3, axis=0))\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    PFC2node = [(\"Re\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(PFCnode, bipartite=0)\n",
    "    A.add_nodes_from(HPCnode, bipartite=1)\n",
    "    A.add_nodes_from(Renode, bipartite=2)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if HPC_w[i,k]>0.5:\n",
    "                A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "            if PFC_w[i,k]>0.5:\n",
    "                A.add_edge(PFC2node[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(PFCnode))\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(HPCnode))\n",
    "    pos.update((node, (3, index)) for index, node in enumerate(PFC2node))\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.eigenvector_centrality(A,weight=True)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    B = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    B.add_nodes_from(PFCnode, bipartite=0)\n",
    "    B.add_nodes_from(HPCnode, bipartite=1)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if PFC_w[i,k]<0.8:\n",
    "                B.add_edge(PFCnode[i],HPCnode[k],weight=0)\n",
    "            else:\n",
    "                B.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "    bottom_nodes, top_nodes = bipartite.sets(B)\n",
    "    pos = {}\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(bottom_nodes))\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(top_nodes))\n",
    "    print(pos)\n",
    "    edges,weights = zip(*nx.get_edge_attributes(B,'weight').items())\n",
    "    nx.draw(B, pos=pos, node_color='b', edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/v4_2Model_0_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 100\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*3):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            #print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(HPCnode, bipartite=0)\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(PFCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(PFCnode))\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(HPCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(HPCnode))\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                    pos.update({PFCnode[i]: (t+1, i)})\n",
    "                    pos.update({HPCnode[k]: (t, k)})\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "                    pos.update({HPCnode[i]: (t+1, i)})\n",
    "                    pos.update({PFCnode[k]: (t, k)})\n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    initnode = 12\n",
    "    nodelinks = [HPCnode[initnode]]\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5 and HPCnode[k] in nodelinks:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                    pos.update({PFCnode[i]: (t+1, i)})\n",
    "                    pos.update({HPCnode[k]: (t, k)})\n",
    "                    nodelinks.append(PFCnode[i])\n",
    "                if HPC and HPC_w[i,k]>0.5 and PFCnode[k] in nodelinks:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "                    pos.update({HPCnode[i]: (t+1, i)})\n",
    "                    pos.update({PFCnode[k]: (t, k)})\n",
    "                    nodelinks.append(HPCnode[i])\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/v4_2Model_0_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 100\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*3):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            #print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.DiGraph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(HPCnode, bipartite=0)\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(PFCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(PFCnode))\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(HPCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(HPCnode))\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[k],PFCnode[i],weight=PFC_w[i,k])\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[k],HPCnode[i],weight=HPC_w[i,k])\n",
    "    sourcenode = 'HPC12'\n",
    "    targetnode = PFCnode[14]\n",
    "#     links = list(nx.shortest_path(A,target=targetnode).keys())\n",
    "    links = list(nx.shortest_path(A,source=sourcenode).keys())\n",
    "    for node in list(A.nodes(data=False)):\n",
    "        if node not in links:\n",
    "            A.remove_node(node)\n",
    "            pos.pop(node)\n",
    "    \n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long131test_s5_100_4.pth')\n",
    "model_list = glob.glob('model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_1_epoch150.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [2,4]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "\n",
    "for model_path in target_list:\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "\n",
    "    fig1.hist(PFC_w[PFC_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)\n",
    "    fig1.hist(PFC_inw[PFC_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)\n",
    "    fig2.hist(HPC_w[HPC_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)  \n",
    "    fig2.hist(HPC_inw[HPC_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)  \n",
    "    fig3.hist(Re_w[Re_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True) \n",
    "    fig3.hist(Re_inw[Re_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True) \n",
    "\n",
    "    \n",
    "#     fig1.hist(PFC_b[PFC_b.nonzero()],bins=20,alpha=0.5,density=False)\n",
    "#     fig1.hist(PFC_inb[PFC_inb.nonzero()],bins=10,alpha=0.5,density=False)\n",
    "#     fig2.hist(HPC_b[HPC_b.nonzero()],bins=20,alpha=0.5,density=False)  \n",
    "#     fig2.hist(HPC_inb[HPC_inb.nonzero()],bins=10,alpha=0.5,density=False)  \n",
    "#     fig3.hist(Re_b[Re_b.nonzero()],bins=20,alpha=0.5,density=False) \n",
    "#     fig3.hist(Re_inb[Re_inb.nonzero()],bins=10,alpha=0.5,density=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "model_list = glob.glob('model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_1_epoch190.pth')\n",
    "\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [2,4,7,8,9]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "PCA_list = np.array([[0,1,2,3,4,5]])\n",
    "\n",
    "for model_path in target_list:\n",
    "    print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "#     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]))\n",
    "    fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]))\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "#     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]))\n",
    "    fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]))\n",
    "    a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]))\n",
    "    a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]))\n",
    "\n",
    "#     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "    HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "#     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "    fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "    HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "    fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "#     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "    b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]))\n",
    "    b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]))\n",
    "\n",
    "\n",
    "#     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "#     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=100,density=True)\n",
    "    Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=20,density=True)\n",
    "    Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=10,density=True)\n",
    "    fig3.plot((make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]))\n",
    "#     fig3.plot((make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]))\n",
    "    c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]))\n",
    "    c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]))\n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[a1,a2,b1,b2,c1,c2]]),axis=0)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# # print(PCA_list[1:])\n",
    "# pca = PCA()\n",
    "# dfs = PCA_list[1:]\n",
    "# pca.fit(dfs)\n",
    "# feature = pca.transform(dfs)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "# #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# for i,n in enumerate(target_list):\n",
    "#     plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "# fig3d = plt.figure()\n",
    "# ax3d = Axes3D(fig3d)\n",
    "# ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "#     print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long_s*_200_?.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "# NGlist_name = np.array([\"s3_100_4\",\"s1_100_3\",\"s9_100_2\",\"s4_100_1\"])\n",
    "NGlist = np.array([])\n",
    "\n",
    "for NG in NGlist_name:\n",
    "    for i, n in enumerate(model_list):\n",
    "        if n[-12:-4] == NG:\n",
    "            NGlist = np.append(NGlist,int(i))\n",
    "print(NGlist)\n",
    "    \n",
    "# target = [2,4,7,8,9]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "PCA_list = np.array([np.ones(4)])\n",
    "\n",
    "for model_path in target_list:\n",
    "    print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "    PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=40,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=20,density=True)\n",
    "    a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]))\n",
    "    a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]))\n",
    "    PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=40,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=20,density=True)\n",
    "    a3 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]))\n",
    "    a4 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]))\n",
    "\n",
    "    HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=40,density=True)\n",
    "    HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=20,density=True)\n",
    "    b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]))\n",
    "    b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]))\n",
    "    HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=40,density=True)\n",
    "    HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=20,density=True)\n",
    "    b3 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]))\n",
    "    b4 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]))\n",
    "\n",
    "\n",
    "    Re_w_hist = np.histogram(Re_w[Re_w>0],bins=40,density=True)\n",
    "    Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=20,density=True)\n",
    "    c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]))\n",
    "    c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]))\n",
    "    Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=40,density=True)\n",
    "    Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "    c3 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]))\n",
    "    c4 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]))\n",
    "    \n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b>0]),bins=20,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb>0]),bins=10,density=True)\n",
    "#     a1 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a2 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b<0]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb<0]),bins=40,density=True)\n",
    "#     a3 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a4 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[a2,b2,a4,b4]]),axis=0)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# print(PCA_list[1:])\n",
    "pca = PCA()\n",
    "dfs = PCA_list[1:]\n",
    "pca.fit(dfs)\n",
    "feature = pca.transform(dfs)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(feature[i, 0], feature[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(dfs[:, 2], dfs[:, 3], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"a4\")\n",
    "plt.ylabel(\"b4\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(dfs[i, 2], dfs[i, 3]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(dfs[i, 2], dfs[i, 3], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    ax3d.plot(feature[[i], 0], feature[[i], 1], feature[[i], 2], \"o\", color=\"r\",alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s*_100_*.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "NGlist_name = np.array([\"s3_100_4\",\"s1_100_3\",\"s9_100_2\",\"s4_100_1\"])\n",
    "# NGlist_name = np.array([])\n",
    "NGlist = np.array([])\n",
    "\n",
    "for NG in NGlist_name:\n",
    "    for i, n in enumerate(model_list):\n",
    "        if n[-12:-4] == NG:\n",
    "            NGlist = np.append(NGlist,int(i))\n",
    "print(NGlist)\n",
    "    \n",
    "# target = [2,4,7,8,9]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "PCA_list = np.array([np.ones(6)])\n",
    "\n",
    "exp_plot = plt.figure()\n",
    "exp_plot1 = exp_plot.add_subplot(111)\n",
    "\n",
    "for model_path in target_list:\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "    PFC_w_exp = scipy.stats.expon.fit(np.abs(PFC_w[PFC_w>0]))\n",
    "    PFC_inw_exp = scipy.stats.expon.fit(np.abs(PFC_inw[PFC_inw>0]))\n",
    "    a1 = PFC_w_exp[1]\n",
    "    a2 = PFC_inw_exp[1]\n",
    "    PFC_w_exp = scipy.stats.expon.fit(np.abs(PFC_w[PFC_w<0]))\n",
    "    PFC_inw_exp = scipy.stats.expon.fit(np.abs(PFC_inw[PFC_inw<0]))\n",
    "    a3 = PFC_w_exp[1]\n",
    "    a4 = PFC_inw_exp[1]\n",
    "\n",
    "    HPC_w_exp = scipy.stats.expon.fit(np.abs(HPC_w[HPC_w>0]))\n",
    "    HPC_inw_exp = scipy.stats.expon.fit(np.abs(HPC_inw[HPC_inw>0]))\n",
    "    b1 = HPC_w_exp[1]\n",
    "    b2 = HPC_inw_exp[1]\n",
    "    HPC_w_exp = scipy.stats.expon.fit(np.abs(HPC_w[HPC_w<0]))\n",
    "    HPC_inw_exp = scipy.stats.expon.fit(np.abs(HPC_inw[HPC_inw<0]))\n",
    "    b3 = HPC_w_exp[1]\n",
    "    b4 = HPC_inw_exp[1]\n",
    "\n",
    "\n",
    "    Re_w_exp = scipy.stats.expon.fit(np.abs(Re_w[Re_w>0]))\n",
    "    Re_inw_exp = scipy.stats.expon.fit(np.abs(Re_inw[Re_inw>0]))\n",
    "    c1 = Re_w_exp[1]\n",
    "    c2 = Re_inw_exp[1]\n",
    "    Re_w_exp_n = scipy.stats.expon.fit(np.abs(Re_w[Re_w<0]))\n",
    "    Re_inw_exp_n = scipy.stats.expon.fit(np.abs(Re_inw[Re_inw<0]))\n",
    "    c3 = Re_w_exp_n[1]\n",
    "    c4 = Re_inw_exp_n[1]\n",
    "    \n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b>0]),bins=20,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb>0]),bins=10,density=True)\n",
    "#     a1 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a2 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b<0]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb<0]),bins=40,density=True)\n",
    "#     a3 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a4 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[b2,b4,a2,a4,c2,c4]]),axis=0)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "    xvalues = np.linspace(0,2,100)\n",
    "    pdf1 = scipy.stats.expon.pdf(xvalues,Re_inw_exp[0],Re_inw_exp[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(xvalues,Re_inw_exp_n[0],Re_inw_exp_n[1])\n",
    "    if model_path[-12:-4] == \"s9_100_2\":\n",
    "        exp_plot1.plot(pdf1,c=\"r\",alpha=1)\n",
    "        exp_plot1.plot(pdf2,c=\"r\",alpha=1)\n",
    "    elif model_path[-12:-4] == \"s4_100_1\":\n",
    "        exp_plot1.plot(pdf1,c=\"g\",alpha=1)\n",
    "        exp_plot1.plot(pdf2,c=\"g\",alpha=1)\n",
    "    else:\n",
    "        exp_plot1.plot(pdf1,c=\"b\",alpha=0.01)\n",
    "\n",
    "# print(PCA_list[1:])\n",
    "pca = PCA()\n",
    "dfs = PCA_list[1:]\n",
    "pca.fit(dfs)\n",
    "feature = pca.transform(dfs)\n",
    "\n",
    "print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "'+str(sparse)+'\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(feature[i, 0], feature[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(dfs[:, 0], dfs[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"a4\")\n",
    "plt.ylabel(\"b4\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(dfs[i, 0], dfs[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(dfs[i, 0], dfs[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    ax3d.plot(feature[[i], 0], feature[[i], 1], feature[[i], 2], \"o\", color=\"r\",alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KL(data1,data2):\n",
    "    x = np.linspace(-2,2,200)\n",
    "    params1 = scipy.stats.norm.fit(data1)\n",
    "    params2 = scipy.stats.norm.fit(data2)\n",
    "    pdf1 = scipy.stats.norm.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.norm.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)\n",
    "\n",
    "def calc_KL_exp(data1,data2):\n",
    "    x = np.linspace(0,2,200)\n",
    "    params1 = scipy.stats.expon.fit(np.abs(data1[data1>=0]))\n",
    "    params2 = scipy.stats.expon.fit(np.abs(data2[data2>=0]))\n",
    "    pdf1 = scipy.stats.expon.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)\n",
    "\n",
    "def calc_KL_exp2(data1):\n",
    "    x = np.linspace(0,2,200)\n",
    "    params1 = scipy.stats.expon.fit(np.abs(data1[data1>=0]))\n",
    "    params2 = scipy.stats.expon.fit(np.abs(data1[data1<=0]))\n",
    "    pdf1 = scipy.stats.expon.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import scipy\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s*_100_2.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "target_list = []\n",
    "\n",
    "ANOVA_list = []\n",
    "\n",
    "# target = [2,4]\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "\n",
    "fig_Re = plt.figure(figsize=(10,5))\n",
    "for i,model_path in enumerate(target_list):\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "                weight_PFC_w = PFC_w[PFC_w.nonzero()]\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "                weight_PFC_inw = PFC_inw[PFC_inw.nonzero()]\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "                weight_HPC_w = HPC_w[HPC_w.nonzero()]\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "                weight_HPC_inw = HPC_inw[HPC_inw.nonzero()]\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "                weight_Re_w = Re_w[Re_w.nonzero()]\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "                weight_Re_inw = Re_inw[Re_inw.nonzero()]\n",
    "    \n",
    "#     plt.plot(np.ones(weight_Re_inw.shape[0])*i,weight_Re_inw,\"o\") \n",
    "    plt.plot(np.ones(weight_Re_w.shape[0])*i,weight_Re_w,\"o\") \n",
    "    ANOVA_list.append(weight_Re_w)\n",
    "    \n",
    "    print(model_path)\n",
    "    \n",
    "#     print(calc_KL(weight_HPC_inw,weight_HPC_w)+calc_KL(weight_PFC_inw,weight_PFC_w)+calc_KL(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL(weight_HPC_w,weight_HPC_inw)+calc_KL(weight_PFC_w,weight_PFC_inw)+calc_KL(weight_Re_w,weight_Re_inw))\n",
    "\n",
    "#     print(calc_KL_exp(weight_HPC_inw,weight_HPC_w))\n",
    "#     print(calc_KL_exp(weight_HPC_w,weight_HPC_inw))\n",
    "#     print(calc_KL_exp(weight_PFC_inw,weight_PFC_w))\n",
    "#     print(calc_KL_exp(weight_PFC_w,weight_PFC_inw))\n",
    "#     print(calc_KL_exp(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL_exp(weight_Re_w,weight_Re_inw))\n",
    "    \n",
    "#     print(calc_KL_exp2(weight_HPC_inw))\n",
    "#     print(calc_KL_exp2(weight_PFC_inw))\n",
    "    print(calc_KL_exp2(weight_Re_inw))\n",
    "#     print(calc_KL_exp2(weight_HPC_w))\n",
    "#     print(calc_KL_exp2(weight_PFC_w))\n",
    "#     print(calc_KL_exp2(weight_Re_w))\n",
    "\n",
    "print(scipy.stats.f_oneway(ANOVA_list[3], ANOVA_list[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import scipy\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s1_100_3_plus_*.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "target_list = []\n",
    "\n",
    "ANOVA_list = []\n",
    "\n",
    "target = [4,8]\n",
    "for i in target:\n",
    "    target_list.append(model_list[i])\n",
    "\n",
    "# target_list = model_list\n",
    "\n",
    "fig_Re = plt.figure(figsize=(10,5))\n",
    "for i,model_path in enumerate(target_list):\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "                weight_PFC_w = PFC_w\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "                weight_PFC_inw = PFC_inw\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "                weight_HPC_w = HPC_w\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "                weight_HPC_inw = HPC_inw\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "                weight_Re_w = Re_w\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "                weight_Re_inw = Re_inw\n",
    "    \n",
    "#     plt.plot(np.ones(weight_Re_inw.shape[0])*i,weight_Re_inw,\"o\") \n",
    "    plt.plot(np.ones(weight_Re_w.shape[0])*i,weight_Re_w,\"o\") \n",
    "    ANOVA_list.append(weight_Re_inw)\n",
    "    \n",
    "    print(model_path)\n",
    "    \n",
    "#     print(calc_KL(weight_HPC_inw,weight_HPC_w)+calc_KL(weight_PFC_inw,weight_PFC_w)+calc_KL(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL(weight_HPC_w,weight_HPC_inw)+calc_KL(weight_PFC_w,weight_PFC_inw)+calc_KL(weight_Re_w,weight_Re_inw))\n",
    "\n",
    "#     print(calc_KL_exp(weight_HPC_inw,weight_HPC_w))\n",
    "#     print(calc_KL_exp(weight_HPC_w,weight_HPC_inw))\n",
    "#     print(calc_KL_exp(weight_PFC_inw,weight_PFC_w))\n",
    "#     print(calc_KL_exp(weight_PFC_w,weight_PFC_inw))\n",
    "#     print(calc_KL_exp(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL_exp(weight_Re_w,weight_Re_inw))\n",
    "    \n",
    "#     print(calc_KL_exp2(weight_HPC_inw))\n",
    "#     print(calc_KL_exp2(weight_PFC_inw))\n",
    "    print(calc_KL_exp2(weight_Re_inw))\n",
    "#     print(calc_KL_exp2(weight_HPC_w))\n",
    "#     print(calc_KL_exp2(weight_PFC_w))\n",
    "#     print(calc_KL_exp2(weight_Re_w))\n",
    "\n",
    "print(scipy.stats.f_oneway(ANOVA_list[0], ANOVA_list[1]))\n",
    "plt.figure()\n",
    "plt.imshow(ANOVA_list[0]-ANOVA_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2):\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.RNNCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.5\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s6_100_2.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 10\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*0.9\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    dividenum = int(np.array(feature).shape[0]/2)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:dividenum,0,0],traj[:dividenum,0,1])\n",
    "    plt.plot(traj[dividenum:,0,0],traj[dividenum:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    HPC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    PFC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    Re_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "#     MakeAnimation(feature[:dividenum, 0], feature[:dividenum, 1], feature[dividenum:, 0], feature[dividenum:, 1], data_limit)\n",
    "\n",
    "    plot_distance_bet2traj(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(HPC_dis)\n",
    "    plt.plot(PFC_dis)\n",
    "    plt.plot(Re_dis)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "#             traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation2(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.01):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def distance_bet2traj_ave(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]-1):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        average = np.linalg.norm(traj1[i]-traj2[i-1]) + np.linalg.norm(traj1[i]-traj2[i]) + np.linalg.norm(traj1[i]-traj2[i+1])\n",
    "        average = np.linalg.norm(traj1[i-1]-traj2[i]) + np.linalg.norm(traj1[i]-traj2[i]) + np.linalg.norm(traj1[i+1]-traj2[i])\n",
    "        average = average/6\n",
    "        result.append(average)\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.2 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.2 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < 0.1 and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > 0.1 and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            print(start,end)\n",
    "        start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < 0.1 and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > 0.1 and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            print(start,end)\n",
    "            start = int(k)\n",
    "        \n",
    "    states_list.append(states[start:])\n",
    "    \n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for i in range(len(states_list)):\n",
    "        result.append(states_list[i][-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s7_100_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_161_s5_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s6_100_1_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H2v121_s9_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s2_100_1_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_H121_s3_100_2.pth'\n",
    "#     model_path = \"model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_11311_s6_100_1.pth\"\n",
    "    model_path = 'model/R20_H/ReModel_L2_interRNNrand_OUT1_121H_s5_100_3_epoch90.pth'\n",
    "\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "\n",
    "\n",
    "    \n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size)\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size)\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size)                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size)\n",
    "    \n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 20\n",
    "    est_length = 5\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_test()\n",
    "    pattern = 2\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size)\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size)\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size)                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size)\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size)\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size)                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    dividenum = int(np.array(feature).shape[0]/2)\n",
    "    \n",
    "#     MakeAnimation(traj[:dividenum,0,0],traj[:dividenum,0,1], traj[dividenum:,0,0], traj[dividenum:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:dividenum,0,0],traj[:dividenum,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "#     MakeAnimation2(traj[:dividenum,0,0],traj[:dividenum,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:dividenum,0],\"PFCr\")\n",
    "#     MakeAnimation_img(np.array(PFCstate)[dividenum:,0],\"PFCl\")\n",
    "    \n",
    "    fig = plt.figure()\n",
    "#     plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:dividenum,0,0],traj[:dividenum,0,1])\n",
    "#     plt.plot(traj[dividenum:,0,0],traj[dividenum:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    linelist = search_delay(traj[:dividenum,0])\n",
    "    linelist2 = search_delay(traj[dividenum:,0])\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    HPC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    HPC_samedis = plot_distance_bet2traj(np.array(HPCstate)[:dividenum,0],np.array(HPCstate)[dividenum:,0],linelist)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "#     ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "# #   ### for 3d divided plot ###\n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "#     end = 0\n",
    "#     for i in range(5):\n",
    "#         start = end\n",
    "#         end = int(linelist[i*2+1])\n",
    "#         ax3d.plot(feature[start:start+1, 0], feature[start:start+1, 1], feature[start:start+1, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[start+20:start+21, 0], feature[start+20:start+21, 1], feature[start+20:start+21, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[start+40:start+41, 0], feature[start+40:start+41, 1], feature[start+40:start+41, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2], color=colors[i], alpha=0.8)\n",
    "#     plt.show()\n",
    "#     print(linelist)\n",
    "\n",
    "#     plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "#     PFC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "#     PFC_samedis = plot_distance_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate)[dividenum:,0],linelist)\n",
    "\n",
    "#     pca = PCA()\n",
    "#     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "    \n",
    "#     pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "#     plt.show()\n",
    "\n",
    "#     plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "#     Re_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "# #     MakeAnimation(feature[:dividenum, 0], feature[:dividenum, 1], feature[dividenum:, 0], feature[dividenum:, 1], data_limit)\n",
    "\n",
    "#     Re_samedis = plot_distance_bet2traj(Restate[:dividenum],Restate[dividenum:],linelist)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(HPC_dis)\n",
    "#     plt.plot(PFC_dis)\n",
    "#     plt.plot(Re_dis)\n",
    "#     plt.vlines(linelist,0,1)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(HPC_samedis)\n",
    "#     plt.plot(PFC_samedis)\n",
    "#     plt.plot(Re_samedis)\n",
    "#     plt.vlines(linelist,0,3)\n",
    "#     plt.show()\n",
    "    \n",
    "#     Re_noisedisr = plot_distance_bet2traj(Restate[:dividenum],Restate_noise[:],linelist)\n",
    "#     Re_noisedisl = plot_distance_bet2traj(Restate[dividenum:],Restate_noise[:],linelist)\n",
    "#     PFC_noisedisr = plot_distance_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate_noise)[:,0],linelist)\n",
    "#     PFC_noisedisl = plot_distance_bet2traj(np.array(PFCstate)[dividenum:,0],np.array(PFCstate_noise)[:,0],linelist)\n",
    "#     plt.figure()\n",
    "#     plt.plot(Re_noisedisr)\n",
    "#     plt.plot(Re_noisedisl)\n",
    "#     plt.vlines(linelist,0,3)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(PFC_noisedisr)\n",
    "#     plt.plot(PFC_noisedisl)\n",
    "#     plt.vlines(linelist,0,3)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plot_activity_bet2traj(Restate[dividenum:],Restate[:dividenum],linelist)\n",
    "# #     plot_activity_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate)[dividenum:,0],linelist)\n",
    "\n",
    "#     points = np.array(np.where(traj_noise[:,0,1]<0.1)[0]).astype(\"int64\")\n",
    "#     Replot = plt.figure()\n",
    "#     axre2 = Replot.add_subplot(111)\n",
    "#     axre2.imshow(np.corrcoef(np.array(np.array(Restate_noise)[points])))\n",
    "#     axre2.set_title(\"Re\")  \n",
    "    \n",
    "#     pca = PCA()\n",
    "#     dfs = np.array(np.array(Restate_noise)[points])\n",
    "# #     dfs = np.array(np.array(Restate_noise))\n",
    "# #     dfs = np.array(HPCstate)[0:,0]\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)    \n",
    "    \n",
    "# #     delays = pick_delay(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "# #     delays = pick_delay(traj_noise[:,0], np.array(Restate_noise))\n",
    "# #     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise))\n",
    "#     linelist_delay = [0]\n",
    "#     for i in delays:\n",
    "#         print(np.array(i).shape)\n",
    "#         linelist_delay.append(linelist_delay[-1]+len(i))\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(feature[:dividenum, 0], alpha=0.8)\n",
    "#     plt.vlines(linelist_delay,0,3)\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(feature[:dividenum, 1], alpha=0.8)\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(feature[:dividenum, 2], alpha=0.8)\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(feature[:dividenum, 0]+feature[:dividenum, 1]+feature[:dividenum, 2], alpha=0.8)\n",
    "# #     plt.vlines(linelist,0,3)\n",
    "#     plt.show()\n",
    "\n",
    "#     print(np.array(delays[:-1]).shape)\n",
    "#     tskm = TimeSeriesKMeans(n_clusters=3,metric='euclidean',max_iter=300)\n",
    "    \n",
    "#     data_kmeans = match_length(delays[:-1])\n",
    "#     tskm_pred = tskm.fit_predict(np.array(data_kmeans))\n",
    "#     print(tskm_pred)\n",
    "#     tskm_feature = tskm.transform(np.array(data_kmeans))\n",
    "#     print(tskm_feature)\n",
    "\n",
    "#     data = match_length(delays[:-1])\n",
    "#     for k in range(5):\n",
    "#         fig = plt.figure()\n",
    "#         target = k\n",
    "#         for i in range(5):\n",
    "#             plt.plot(distance_bet2traj(data[target][:],data[i][:]))\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(np.array(PFCstate)[:dividenum,0])\n",
    "#     dfs = np.array(np.array(Restate)[:dividenum])\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)    \n",
    "    print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Restate_noise))\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise))\n",
    "    delays = pick_traj(traj[:dividenum,0], np.array(feature)[:])\n",
    "    linelist_delay = [0]\n",
    "    for i in delays:\n",
    "        print(np.array(i).shape)\n",
    "        linelist_delay.append(linelist_delay[-1]+len(i))\n",
    "\n",
    "    print(np.array(delays[:-1]).shape)\n",
    "    tskm = TimeSeriesKMeans(n_clusters=3,metric='euclidean',max_iter=300)\n",
    "    \n",
    "    data_kmeans = match_length(delays[:-1])\n",
    "    tskm_pred = tskm.fit_predict(np.array(data_kmeans))\n",
    "    print(tskm_pred)\n",
    "    tskm_feature = tskm.transform(np.array(data_kmeans))\n",
    "    print(tskm_feature)\n",
    "\n",
    "#     data = match_length(delays[:-1])\n",
    "#     for k in range(5):\n",
    "#         fig = plt.figure()\n",
    "#         target = k\n",
    "#         for i in range(5):\n",
    "#             plt.plot(distance_bet2traj(data[target][:],data[i][:]))\n",
    "# #             plt.plot(distance_bet2traj_ave(data[target][:],data[i][:]))\n",
    "#         plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    for data in delays[1:-1]:\n",
    "        plt.plot(np.array(data)[:,0],alpha=0.5)\n",
    "        print(len(data))\n",
    "\n",
    "\n",
    "#     pick_delay(traj_noise[:,0], Restate_noise)\n",
    "\n",
    "    \n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.plot(np.array(Restate)[:dividenum,i])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:dividenum,0,0])\n",
    "    plt.plot(traj[:dividenum,0,1])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 19 10:54:37 2021\n",
    "\n",
    "@author: munenori\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation2(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_testdata(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_test_1.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter_gate_PFC.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_3D(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.01):\n",
    "   \n",
    "    x = np.loadtxt(\"primal_long131test_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long131test_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # ###  ver2  ###\n",
    "    # orders = []\n",
    "    # order  = np.array([1])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [2])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([2])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [3])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([3])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [4])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([4])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [1])\n",
    "    # orders.append(order) \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    \n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    \n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "#                 target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "                target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.0001):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN_noise(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_RNN_noise, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+10\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_noised = hiddens[1][0] + torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        PFC_noised = hiddens[0][0] + torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        Re_noised = hiddens[2] + torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_input = torch.cat([PFC_noised,HPC_noised],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, Re_noised)\n",
    "        HPC_input = torch.cat([input,Re_noised],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([HPC_noised,Re_noised],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "class MyLSTM_vHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_vHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.vHPC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.vHPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.vHPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[3][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        vHPC_input = hiddens[1][0]\n",
    "        vHPC_hidden = self.vHPC(vHPC_input,hiddens[2])\n",
    "        PFC_input = torch.cat([hiddens[2][0],hiddens[3][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, vHPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,vHPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "class MyLSTM_feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_feedforward, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "\n",
    "class MyLSTM_feedforward_Thalamus2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_feedforward_Thalamus2, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.hidden_size_THinh = hidden_size\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_PFC+self.hidden_size_HPC+self.hidden_size_THinh, self.hidden_size_Re)\n",
    "        self.THinh = nn.Linear(self.hidden_size_Re, self.hidden_size_THinh)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.ReLU = nn.ReLU()\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0],hiddens[3]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        THinh_input = hiddens[2]\n",
    "        THinh_hidden = self.ReLU(self.THinh(THinh_input))\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden,THinh_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh))\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh)*const)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re,self.hidden_size_THinh]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*v\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s'+str(num)+'_100_2_2.pth'\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s2_100_1_2.pth'\n",
    "    model_path = 'model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s2_100_3_epoch180.pth'\n",
    "#     model_path = 'model/R20_H_stopinit_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s2_100_3_epoch10.pth'\n",
    "#     model_path = 'model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s3_100_1_epoch145.pth'\n",
    "#     model_path = 'model/R20_H_uniHPC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_3_epoch190.pth'\n",
    "#     model_path = 'model/R20_uniPFC_H/ReModel_L2_interRNNrand_OUT1_uniPFC_121H_s5_100_2_epoch85.pth'\n",
    "#     model_path = 'model/R20_uniHPC_H/ReModel_L2_interRNNrand_OUT1_121H_s2_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_H_transfer2B/ReModel_L2_interRNNrand_OUT1_transfers14_121_s2_100_2_epoch60.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s4_100_3_epoch190.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s4_100_1_epoch100.pth'\n",
    "#     model_path = 'model_test/R20_H_retrainv2_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s9_100_2_epoch215.pth'\n",
    "#     model_path = 'model/R20_feedReinhReLU_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s8_100_1_epoch150.pth'\n",
    "\n",
    "\n",
    "    sparse = 1\n",
    "    delay_length = 2\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "\n",
    "    # train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "#     test_x = mkOwnDataSet(test_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_feedforward_Thalamus2(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "    \n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2+10):\n",
    "#             if output.tolist()[0][1]<0.05:\n",
    "#                 hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    # MakeAnimation2(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    # MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    # MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    # MakeAnimation_img(np.array(Restate),\"Re\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "    # MakeAnimation_data(pltdata[:,0,0],pltdata[:,0,1],data_limit)\n",
    "\n",
    "    # for n, p in rnn.named_parameters():\n",
    "    #         if n == \"PFC.weight_ih\":\n",
    "    #             PFC_w = np.array(p.data)\n",
    "    #         if n == \"HPC.weight_ih\":\n",
    "    #             HPC_w = np.array(p.data)\n",
    "    #         if n == \"Re.weight_ih\":\n",
    "    #             Re_w = np.array(p.data)\n",
    "                \n",
    "    # # for n, p in rnn.named_parameters():\n",
    "    # #         if n == \"PFC.weight_hh\":\n",
    "    # #             PFC_w = np.array(p.data)\n",
    "    # #         if n == \"HPC.weight_hh\":\n",
    "    # #             HPC_w = np.array(p.data)\n",
    "    # #         if n == \"Re.weight_hh\":\n",
    "    # #             Re_w = np.array(p.data)\n",
    "                \n",
    "    # fig2 = plt.figure()\n",
    "    # ax1 = fig2.add_subplot(131)\n",
    "    # ax2 = fig2.add_subplot(132)\n",
    "    # axre = fig2.add_subplot(133)\n",
    "    \n",
    "    # ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    # ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    # axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    # ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    # ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    # axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "\n",
    "    \n",
    "    # fig3 = plt.figure()\n",
    "    # ax3 = fig3.add_subplot(131)\n",
    "    # ax4 = fig3.add_subplot(132)\n",
    "    # axre2 = fig3.add_subplot(133)\n",
    "    # ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0]))\n",
    "    # ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0]))\n",
    "    # axre2.imshow(np.corrcoef(np.array(Restate)))\n",
    "    # ax3.set_title(\"PFC\")   \n",
    "    # ax4.set_title(\"HPC\")  \n",
    "    # axre2.set_title(\"Re\")  \n",
    "    \n",
    "    # Replot = plt.figure()\n",
    "    # axre2 = Replot.add_subplot(111)\n",
    "    # axre2.imshow(np.corrcoef(np.array(Restate)))\n",
    "    # axre2.set_title(\"Re\")  \n",
    "    \n",
    "#     pca = PCA()\n",
    "#     # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "#     # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "# #     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "    # print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    # print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    # print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    # pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    # #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "    # plt.scatter(feature[0, 0], feature[0, 1], c=\"r\", alpha=0.8)\n",
    "    # plt.grid()\n",
    "    # plt.xlabel(\"PC1\")\n",
    "    # plt.ylabel(\"PC2\")\n",
    "    # for i in range(np.min([200,data_limit+k])):\n",
    "    #     plt.annotate(i,(feature[i, 0], feature[i, 1]))\n",
    "    # plt.show()\n",
    "    \n",
    "    # # MakeAnimation_attracter(feature[:, 0], feature[:, 1])\n",
    "    \n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.3)\n",
    "    \n",
    "    # fig_place = plt.figure()\n",
    "    # place3d = Axes3D(fig_place)\n",
    "    # place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,0])\n",
    "    \n",
    "    # fig4 = plt.figure(figsize=(10,5))\n",
    "    # ax5 = fig4.add_subplot(311)\n",
    "    # ax6 = fig4.add_subplot(312)\n",
    "    # axRe3 = fig4.add_subplot(313)\n",
    "    # #ax5.plot(np.array(PFCstate)[:,0,pred==1])\n",
    "    # ax5.imshow(np.array(PFCstate)[:200,0,:].T)\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(HPCstate)[:,0],axis=1))\n",
    "    # ax6.imshow(np.array(HPCstate)[:200,0,:].T)\n",
    "    # axRe3.imshow(np.array(Restate)[:200,:].T)\n",
    "    # ax5.set_title(\"PFC\")   \n",
    "    # ax6.set_title(\"HPC\")  \n",
    "    # axRe3.set_title(\"Re\") \n",
    "    # print(pred==0)\n",
    "    \n",
    "    # # fig5 = plt.figure(figsize=(5,5))\n",
    "    # # plt.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # # plt.show()\n",
    "    # #MakeAnimation_attracter(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    \n",
    "    \n",
    "    # fig6 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:200,0,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:200,0,0:].T),np.min(np.array(Gate_states)[:,0,0:].T),np.average(np.array(Gate_states)[:,0,0:].T))\n",
    "    # plt.show()\n",
    "    # fig7 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:200,1,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:200,1,0:].T),np.min(np.array(Gate_states)[:,1,0:].T),np.average(np.array(Gate_states)[:,1,0:].T))\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,14])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,34])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,54])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,74])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,13])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,33])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,53])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,73])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.plot(np.array(HPCstate)[:200,0,:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    #np.save(\"right_traj.npy\",dfs)\n",
    "    #np.save(\"left_traj.npy\",dfs)\n",
    "    \n",
    "    # fig5 = plt.figure()\n",
    "    # plt.hist(PFC_w[PFC_w.nonzero()],bins=400,range=(-2,2))\n",
    "    # fig6 = plt.figure()\n",
    "    # plt.hist(HPC_w[HPC_w.nonzero()],bins=400,range=(-2,2))    \n",
    "    # fig7 = plt.figure()\n",
    "    # plt.hist(Re_w[Re_w.nonzero()],bins=400,range=(-2,2))   \n",
    "    \n",
    "    \n",
    "    # pca = PCA()\n",
    "    # dfs = Re_w\n",
    "    # pca.fit(dfs)\n",
    "    # feature = pca.transform(dfs)\n",
    "    # pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    # plt.grid()\n",
    "    # plt.xlabel(\"PC1\")\n",
    "    # plt.ylabel(\"PC2\")\n",
    "\n",
    "    # plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    \n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "    if bifur.shape[0] == 0:\n",
    "        pass\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "    print(bifur)\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    datalen = 120\n",
    "    print(np.corrcoef(np.abs(traj[:datalen*1,0,1]-traj[datalen*2:datalen*3,0,1]),np.abs(feature[:datalen*1,0]-feature[datalen*2:datalen*3,0]))[0,1])\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "    delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,0,0:20]-np.array(Gate_states)[:,0,20:40])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,0,0:20])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], feature[:])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "    bifur = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        for data in delays[:-1]:\n",
    "#             avedata = moving_average(data[:,0+i])\n",
    "#             plt.plot(avedata[2:-2],alpha=0.5)\n",
    "#             plt.plot(data[:,0+i]-avedata[2:-2],alpha=0.5)\n",
    "            plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(data)[:,0+i]-np.array(delays[1:-1][0])[:,0+i],alpha=0.5)\n",
    "#             plt.plot(np.log(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data),len(avedata))\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         delays = delays[1:-1]\n",
    "#         plt.plot(np.array(delays)[,:,0+i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "# #     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "    for i in range(3):\n",
    "        data_len = 1000\n",
    "        delays_samelen = []\n",
    "        result = 0\n",
    "        for data in delays[1:-1]:\n",
    "            data_len = np.min([data_len,len(data)])\n",
    "        for data in delays[1:-1]:\n",
    "            delays_samelen.append(data[:data_len])\n",
    "        delays_samelen = np.array(delays_samelen)\n",
    "        for k in range(data_len):\n",
    "            result += np.var(delays_samelen[:,k,i])\n",
    "        result /= data_len\n",
    "        print(result)\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    PFCfeature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[0:,0]\n",
    "    dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    Refeature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "#     plt.figure()\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0],alpha=0.5)\n",
    "#         plt.plot(traj_noise[:,0,1],alpha=0.5)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:],alpha=0.3)\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:],alpha=0.3)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[2:-2,i])[:],alpha=0.3)\n",
    "#             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[:,i])[4:-4],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,0+i],\"o\",alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,1,0+i],\"o\",alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "            plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.array(PFCfeature)[:,0],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCfeature)[:,0]-moving_average(np.array(PFCfeature)[2:-2,0]),alpha=0.5)\n",
    "#             plt.plot(np.array(Refeature)[:,1],alpha=0.5)\n",
    "#             plt.plot(np.array(Refeature)[:,1]-moving_average(np.array(Refeature)[:,1])[2:-2],alpha=0.5)\n",
    "\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     fig1 = fig.add_subplot(111)\n",
    "#     fig1.hist(np.array(Gate_states)[:,1,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig1 = fig.add_subplot(111)\n",
    "    hist = np.histogram(np.array(Gate_states)[:,1,0:20].ravel(),bins=30,range=(-0.1,1.1),density=True)\n",
    "    print(hist)\n",
    "    plt.plot(hist[1][3:-2],hist[0][2:-2])\n",
    "    plt.show()\n",
    "    \n",
    "    beta = scipy.stats.beta.fit(hist[0][2:-2])\n",
    "    print(beta)\n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "#     pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(feature[:240, 0], feature[:240, 1], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    features = []\n",
    "    for i in range(1):\n",
    "        features.append(main(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "    \n",
    "class MyLSTM_RNN_uniHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = hiddens[0][0]\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN_uniPFCHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFCHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = hiddens[0][0]\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniHPC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyLSTM_feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_feedforward, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "\n",
    "class MyLSTM_feedforward_Thalamus2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_feedforward_Thalamus2, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.hidden_size_THinh = hidden_size\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_PFC+self.hidden_size_HPC+self.hidden_size_THinh, self.hidden_size_Re)\n",
    "        self.THinh = nn.Linear(self.hidden_size_Re, self.hidden_size_THinh)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.ReLU = nn.ReLU()\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0],hiddens[3]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        THinh_input = hiddens[2]\n",
    "        THinh_hidden = self.ReLU(self.THinh(THinh_input))\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden,THinh_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh))\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh)*const)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re,self.hidden_size_THinh]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward_Thalamus2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,0],color=colors[-1])\n",
    "#     plt.plot(traj_noise[:,0,0],color=colors[-2])\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]))[0,1]\n",
    "    PFC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:,2],2))\n",
    "    PFC_d = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),PFC_diff)[0,1]\n",
    "    PFC_diff2 = np.sum(np.abs(np.array(PFCstate)[:,0]-np.array(PFCstate_noise)[:,0]),axis=1)\n",
    "    PFC_e = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),PFC_diff2)[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    HPC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:,2],2))\n",
    "    HPC_d = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff)[0,1]\n",
    "    HPC_diff2 = np.sum(np.abs(np.array(HPCstate)[:,0]-np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "    HPC_e = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff2)[0,1]\n",
    "    print(HPC_e)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,3]-feature[100:,3]))\n",
    "#     plt.plot(np.abs(feature[:100,4]-feature[100:,4]))\n",
    "#     plt.plot(np.abs(feature[:100,5]-feature[100:,5]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     Re_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]\n",
    "#     Re_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]\n",
    "#     Re_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,0])-moving_average(feature[100:,0])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,1])-moving_average(feature[100:,1])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,2])-moving_average(feature[100:,2])))\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "####################### Fluc(frac) and coherence part #############################\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[40:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    delaysB = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "    PCAnum = 0\n",
    "    data = feature[:,PCAnum]\n",
    "    movingA = moving_average(data)\n",
    "    fracA = data - movingA[2:-2]\n",
    "    print(math.dist(data,movingA[2:-2]))\n",
    "    frac_amp = math.dist(data,movingA[2:-2])\n",
    "    \n",
    "#     frac_amp = 0\n",
    "#     for i in range(20):\n",
    "#         data = np.array(HPCstate)[:,0,i]\n",
    "#         movingA = moving_average(data)\n",
    "#         fracA = data - movingA[2:-2]\n",
    "#         frac_amp += math.dist(data,movingA[2:-2])\n",
    "#     frac_amp = frac_amp/20\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     fig1 = fig.add_subplot(111)\n",
    "#     fig1.hist(np.array(Gate_states)[:,0,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     fig1.hist(np.array(Gate_states)[:,1,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     plt.show()\n",
    "\n",
    "#     hist = np.histogram(np.array(Gate_states)[:,0,0:20].ravel(),bins=30,range=(-0.1,1.1),density=True)\n",
    "#     data = np.array([np.clip(hist[1][3:-2],0,1),hist[0][2:-2]]).T\n",
    "    data = np.array(Gate_states)[:,0,0:20].ravel()\n",
    "    try:\n",
    "        beta_PFC = scipy.stats.beta.fit(data, floc=0)\n",
    "        print(beta_PFC)\n",
    "        beta_param = np.average([beta_PFC[0],beta_PFC[1]])\n",
    "    except Exception:\n",
    "        print(\"Error: maybe takes negative a or b\")\n",
    "        beta_param = 0.5\n",
    "        \n",
    "#     data = np.array(Gate_states)[:,1,0:20].ravel()\n",
    "#     try:\n",
    "#         beta_HPC = scipy.stats.beta.fit(data)\n",
    "#         print(beta_HPC)\n",
    "#     except Exception:\n",
    "#         print(\"Error: maybe takes negative a or b\")\n",
    "        \n",
    "\n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(HPCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     Refeature = pca.transform(dfs)\n",
    "\n",
    "#     shift = 2\n",
    "#     seglen = 60\n",
    "        \n",
    "#     coherence_diff_list = []\n",
    "#     for i in range(20):\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "#             freqs,times,sx1 = signal.stft(data,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx3 = signal.stft(data,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "# #             plt.figure()\n",
    "# #             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "# #             xsp = sx1*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "# #             xsp = sx2*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "# #             degree = np.degrees(np.angle(xsp))\n",
    "# #             print(degree.shape)\n",
    "# #             plt.figure()\n",
    "# #             plt.plot(degree)\n",
    "\n",
    "# #             plt.figure()\n",
    "# #             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "#             coherence_diff_list.append(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "    \n",
    "    \n",
    "    return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, np.sum(coherence_diff_list)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "#     return 0,0,0,0,beta_param\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    good_points = [[],[]]\n",
    "    bad_points = [[],[]]\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "#             path = 'model/R20_H_bigbatch/'\n",
    "            path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "#             path = 'model/R20_H_stopinit_bigbatch/'\n",
    "#             path = 'model/R20FF_H_bigbatch/'\n",
    "#             path = 'model/R20_feedReinhReLU_H_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "            if i+1 == 4 and num+1 == 3:\n",
    "                continue\n",
    "            if i+1 == 5 and num+1 == 2:\n",
    "                continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "                if int(model.split(\"epoch\")[-1].split(\".\")[0])>194:\n",
    "                    continue\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])<19:\n",
    "#                     continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,frac = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#                 ratio_list_max.append(HPC_max)\n",
    "#                 ratio_list_max.append(frac)\n",
    "                ratio_list_max.append(PFC_max)\n",
    "#                 correlation_fig.plot(PFC_max,HPC_max,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"r\")\n",
    "    #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "        #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "                print(PFC_max,HPC_max)\n",
    "                print(\"dist:\"+str(frac))\n",
    "#                 if good_flag != True and model in good_list:\n",
    "#                     good_flag = True\n",
    "#                     first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#     #                 first_goodmodel[1] = ratio_list[-1]\n",
    "#                     first_goodmodel[1] = ratio_list_max[-1]\n",
    "                if model in good_list:\n",
    "                    good_points[0].append(ratio_list_max[-1]) \n",
    "                    good_points[1].append(int(model.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "                else:\n",
    "                    bad_points[0].append(ratio_list_max[-1]) \n",
    "                    bad_points[1].append(int(model.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "    correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "    correlation_fig.errorbar(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),yerr=np.sqrt(np.var(np.array(allratio_list), axis=0)), color=\"b\", alpha=0.3)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "#     np.save(\"ReFFInhReLU_HPCave.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"ReFFInhReLU_HPCvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "    np.save(\"uniHPC_PFCmax_good.npy\",np.array(good_points))\n",
    "    np.save(\"uniHPC_PFCmax_bad.npy\",np.array(bad_points))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################  Compare!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!   #############################################\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "class MyLSTM_comp(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_comp, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        hidden1 = self.LSTM1(input, hiddens[0])\n",
    "        hidden2 = self.LSTM2(hidden1[0], hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.01, torch.rand(self.batch_size, self.hidden_size)*0.01]\n",
    "        return [hidden,hidden]  \n",
    "\n",
    "class MyLSTM_PFCHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_PFCHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re = hiddens[0][0]\n",
    "        HPC_input = torch.cat([input,Re],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        return [PFC_hidden,HPC_hidden]\n",
    "    \n",
    "    \n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "    \n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 30\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_cue18_s5_100_1_2.pth'\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_cue13_s9_100_1.pth'\n",
    "    # model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_2_epoch150.pth'\n",
    "#     model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_3_epoch195.pth'\n",
    "#     model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_1_epoch195.pth'\n",
    "#     model_path = 'model/R20_cue_131_1to3/ReModel_L2_interRNNrand_OUT1_cue7_131_1to3_s4_100_1_epoch175.pth'\n",
    "    model_path = model\n",
    "    # model_path = 'model/v4_2Model_MTRNN2_cue_9.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    sparse = 1\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_PFCHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    # hidden = rnn.initHidden()\n",
    "    data_limit = 120\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "#     for k in range(data.shape[0]*8):\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             if np.any(cue_point==k+data_limit):\n",
    "#                 output = torch.cat([output,torch.ones(10,1)],axis=1)\n",
    "#             else:\n",
    "#                 output = torch.cat([output,torch.zeros(10,1)],axis=1)\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "#     fig = plt.figure()\n",
    "#     print(pltdata.shape)\n",
    "#     plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "#     plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "#     plt.show()\n",
    "#     MakeAnimation2(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    # MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    # MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    # MakeAnimation_img(np.array(Restate),\"Re\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "    \n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#     for k in range(data.shape[0]*8):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             if np.any(cue_point_noise==k+data_limit):\n",
    "#                 output = torch.cat([output,torch.ones(10,1)],axis=1)\n",
    "#             else:\n",
    "#                 output = torch.cat([output,torch.zeros(10,1)],axis=1)\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:,0,0],traj[:,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "# #     plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,0])\n",
    "#     plt.plot(traj_noise[:,0,0])\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "    HPC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:,2],2))\n",
    "    HPC_d = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff)[0,1]\n",
    "    HPC_diff2 = np.sum(np.abs(np.array(HPCstate)[:,0]-np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "    HPC_e = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff2)[0,1]\n",
    "    print(HPC_e)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),HPC_e\n",
    "#     print(traj[:,0,1],traj_noise[:,0,1],np.abs(traj[:,0,1]-traj_noise[:,0,1]))\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/compare30_131/*s10_100_1_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "    \n",
    "#     for i in range(5):\n",
    "# #         path = 'model/compare30_cue_131/'\n",
    "#         path = 'model/PFCHPC30_H/'\n",
    "#         model_list = glob.glob(path+'*s'+str(i+6)+'_100_2_*epoch*.pth')\n",
    "#         model_list = sorted(model_list)\n",
    "#         model_list = sorted(model_list,key=len,reverse=False)\n",
    "#         ratio_list = []\n",
    "#         ratio_list_max = []\n",
    "#         with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "#             good_list = f.read().splitlines()\n",
    "#         first_goodmodel = [0,0]\n",
    "#         good_flag = False\n",
    "#         k=0\n",
    "#         for model in model_list:\n",
    "#             print(model)\n",
    "# #             PFC,HPC = main(model)\n",
    "#             PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "# #             ratio_list.append(PFC/HPC)\n",
    "#             ratio_list.append(np.abs(PFC-HPC))\n",
    "# #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#             ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "# #             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "# #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "#     #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#             print(PFC_max,HPC_max)\n",
    "#             if good_flag != True and model in good_list:\n",
    "#                 good_flag = True\n",
    "#                 first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "# #                 first_goodmodel[1] = ratio_list[-1]\n",
    "#                 first_goodmodel[1] = ratio_list_max[-1]\n",
    "#             k+=1\n",
    "# #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "# #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "# #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "# #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "        \n",
    "#         ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "# #         ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#         correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#         if good_flag == True:\n",
    "#             correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            \n",
    "    allratio_list = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "#             path = 'model/compare30_H_bigbatch/'\n",
    "            path = 'model/PFCHPC30_H_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "    #         good_list = []\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "                if int(model.split(\"epoch\")[-1].split(\".\")[0])>199:\n",
    "                    continue\n",
    "    #             PFC,HPC = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "                ratio_list_max.append(HPC_max)\n",
    "    #             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"r\")\n",
    "    #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "        #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "                print(PFC_max,HPC_max)\n",
    "                if good_flag != True and model in good_list:\n",
    "                    good_flag = True\n",
    "                    first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #                 first_goodmodel[1] = ratio_list[-1]\n",
    "                    first_goodmodel[1] = ratio_list_max[-1]\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "    correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "    np.save(\"PFCHPC_HPCmaxave.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "    np.save(\"PFCHPC_HPCmaxvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### あとち　PFCHPCのPFCのcriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 600\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length+10):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "    delays = pick_traj(traj[:,0], feature[:])\n",
    "#     bifur = np.array([])\n",
    "#     for i in range(3):\n",
    "#         plt.figure()\n",
    "#         for data in delays[1:-1]:\n",
    "#             plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "# #     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "    totalresult = 0\n",
    "    for i in range(3):\n",
    "        data_len = 1000\n",
    "        delays_samelen = []\n",
    "        result = 0\n",
    "        for data in delays[1:-1]:\n",
    "            data_len = np.min([data_len,len(data)])\n",
    "        for data in delays[1:-1]:\n",
    "            delays_samelen.append(data[:data_len])\n",
    "        delays_samelen = np.array(delays_samelen)\n",
    "        for k in range(data_len):\n",
    "            result += np.var(delays_samelen[:,k,i])\n",
    "        result /= data_len\n",
    "#         print(result)\n",
    "        totalresult += result\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "    return totalresult\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    for i in range(10):\n",
    "        path = 'model/R20_H_bigbatch/'\n",
    "#         path = 'model/R20_H_uniPFC_bigbatch/'\n",
    "        model_list = glob.glob(path+'*s'+str(i+1)+'_100_3_*epoch*.pth')\n",
    "        model_list = sorted(model_list)\n",
    "        model_list = sorted(model_list,key=len,reverse=False)\n",
    "        var_list = []\n",
    "#         with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "#             good_list = f.read().splitlines()\n",
    "#         good_list = []\n",
    "        first_goodmodel = [0,0]\n",
    "        good_flag = False\n",
    "        k=0\n",
    "        for model in model_list:\n",
    "            print(model)\n",
    "#             PFC,HPC = main(model)\n",
    "            var_list.append(main(model))\n",
    "        correlation_fig.plot(var_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_v4_2_NN2r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_testdata(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_test_1.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter_v420_PFC.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def MakeAnimation_3D(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re = hiddens[0][0]\n",
    "        HPC_input = torch.cat([input,Re],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden]\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 30\n",
    "    batch_size = 10\n",
    "    data_length = 200\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/v4_2Model_inter_long_s10.pth'\n",
    "    model_path = 'model/PFCHPC30_H/v4_3_121_s3_100_1_epoch170.pth'\n",
    "    # model_path = 'model/PFCHPC_131/v4_3_131_s8_100_1_epoch150.pth'\n",
    "    # model_path = 'model/PFCHPC_30_131/v4_3_N30_131_s3_100_2_epoch85.pth'\n",
    "    filename = \"primal_long\"\n",
    "    \n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "    \n",
    "    pattern = 2\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 2\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*1):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "#             print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    # MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "                \n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(121)\n",
    "    ax2 = fig2.add_subplot(122)\n",
    "    \n",
    "#     ax1.imshow(PFC_inw,cmap=\"coolwarm\",vmin=-3,vmax=3)\n",
    "#     ax2.imshow(HPC_inw,cmap=\"coolwarm\",vmin=-3,vmax=3)\n",
    "#     ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "#     ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    ax1.imshow(PFC_inw,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_inw,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_inw),np.min(PFC_inw)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_inw),np.min(HPC_inw)))\n",
    "    \n",
    "    \n",
    "    fig3 = plt.figure()\n",
    "    ax3 = fig3.add_subplot(121)\n",
    "    ax4 = fig3.add_subplot(122)\n",
    "    ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0]))\n",
    "    ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0]))\n",
    "    ax3.set_title(\"PFC\")   \n",
    "    ax4.set_title(\"HPC\")  \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    for i in range(200):\n",
    "        plt.annotate(i,(feature[i, 0], feature[i, 1]))\n",
    "    plt.show()\n",
    "    \n",
    "    #MakeAnimation_attracter(feature[:, 0], feature[:, 1])\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.3)\n",
    "    \n",
    "#     fig_place = plt.figure()\n",
    "#     place3d = Axes3D(fig_place)\n",
    "#     place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,0])\n",
    "    \n",
    "    fig4 = plt.figure(figsize=(10,5))\n",
    "    ax5 = fig4.add_subplot(211)\n",
    "    ax6 = fig4.add_subplot(212)\n",
    "    #ax5.plot(np.array(PFCstate)[:,0,pred==1])\n",
    "    ax5.imshow(np.array(PFCstate)[:,0,:].T)\n",
    "    # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1))\n",
    "    # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # ax5.plot(np.average(np.array(HPCstate)[:,0],axis=1))\n",
    "    ax6.imshow(np.array(HPCstate)[:,0,:].T)\n",
    "    ax5.set_title(\"PFC\")   \n",
    "    ax6.set_title(\"HPC\")  \n",
    "    print(pred==0)\n",
    "    \n",
    "    # fig5 = plt.figure(figsize=(5,5))\n",
    "    # plt.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # plt.show()\n",
    "    #MakeAnimation_attracter(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    \n",
    "    \n",
    "    # fig6 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:,0,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:,0,0:].T),np.min(np.array(Gate_states)[:,0,0:].T),np.average(np.array(Gate_states)[:,0,0:].T))\n",
    "    # plt.show()\n",
    "    # fig7 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:,1,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:,1,0:].T),np.min(np.array(Gate_states)[:,1,0:].T),np.average(np.array(Gate_states)[:,1,0:].T))\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,14])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,34])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,54])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,74])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,13])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,33])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,53])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,73])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        plt.plot(traj[:,0,0])\n",
    "        plt.plot(np.array(HPCstate)[:,0,i])\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.plot(np.array(HPCstate)[:200,0,:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    #np.save(\"right_traj.npy\",dfs)\n",
    "    #np.save(\"left_traj.npy\",dfs)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 600\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length+10):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "    delays = pick_traj(traj[:,0], feature[:])\n",
    "#     bifur = np.array([])\n",
    "#     for i in range(3):\n",
    "#         plt.figure()\n",
    "#         for data in delays[1:-1]:\n",
    "#             plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "# #     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "    totalresult = 0\n",
    "    for i in range(3):\n",
    "        data_len = 1000\n",
    "        delays_samelen = []\n",
    "        result = 0\n",
    "        for data in delays[1:-1]:\n",
    "            data_len = np.min([data_len,len(data)])\n",
    "        for data in delays[1:-1]:\n",
    "            delays_samelen.append(data[:data_len])\n",
    "        delays_samelen = np.array(delays_samelen)\n",
    "        for k in range(data_len):\n",
    "            result += np.var(delays_samelen[:,k,i])\n",
    "        result /= data_len\n",
    "#         print(result)\n",
    "        totalresult += result\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "    return totalresult\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    foraverage = []\n",
    "    for k in range(1):\n",
    "        for i in range(10):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniPFC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(k+3)+'_*epoch1??.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            \n",
    "#             if i == 3 and k == 2:\n",
    "#                 continue\n",
    "#             if i == 4 and k == 1:\n",
    "#                 continue\n",
    "            \n",
    "            var_list = []\n",
    "    #         with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "    #             good_list = f.read().splitlines()\n",
    "    #         good_list = []\n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "    #             PFC,HPC = main(model)\n",
    "                var_list.append(main(model))\n",
    "            correlation_fig.plot(var_list)\n",
    "            foraverage.append(var_list)\n",
    "            print(foraverage)\n",
    "    np.array(foraverage)\n",
    "    plt.figure()\n",
    "    plt.plot(np.mean(foraverage,axis=0))\n",
    "#     np.save(\"uniPFCave.npy\",np.mean(foraverage,axis=0))\n",
    "#     np.save(\"uniPFCvar.npy\",np.var(foraverage,axis=0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "a = np.load(\"Re_PFCmaxave.npy\")[2:-1]\n",
    "a_err = np.sqrt(np.load(\"Re_PFCmaxvar.npy\"))[2:-1]\n",
    "b = np.load(\"uniPFC_PFCmaxave.npy\")[2:-1]\n",
    "b_err = np.sqrt(np.load(\"uniPFC_PFCmaxvar.npy\"))[2:-1]\n",
    "# a = np.load(\"RePFCave.npy\")\n",
    "# a_err = np.load(\"RePFCvar.npy\")\n",
    "# b = np.load(\"uniPFCave.npy\")\n",
    "# b_err = np.load(\"uniPFCvar.npy\")\n",
    "x = np.arange(0,a.size*5,5)\n",
    "\n",
    "model_LR_a = linregress(x,a)\n",
    "model_LR_b = linregress(x,b)\n",
    "# model_LR_a = linregress(x,1-a)\n",
    "# model_LR_b = linregress(x,1-b)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,a,\"o\")\n",
    "plt.errorbar(x,a,yerr=a_err, fmt=\"o\", color=\"b\", alpha=0.3)\n",
    "plt.plot(x,b,\"o\",color=\"green\")\n",
    "plt.errorbar(x,b,yerr=b_err, fmt=\"o\", color=\"green\", alpha=0.3)\n",
    "plt.plot(x,model_LR_a.intercept + model_LR_a.slope*x,color=\"C0\")\n",
    "plt.plot(x,model_LR_b.intercept + model_LR_b.slope*x,color=\"C2\")\n",
    "plt.show()\n",
    "print(np.corrcoef(x,a),np.corrcoef(x,b))\n",
    "print(st.f_oneway(np.array(a),np.array(b)))\n",
    "\n",
    "a = np.load(\"Re_HPCmaxave.npy\")[2:-1]\n",
    "a_err = np.sqrt(np.load(\"Re_HPCmaxvar.npy\"))[2:-1]\n",
    "b = np.load(\"UniHPC_HPCmaxave.npy\")[2:-1]\n",
    "b_err = np.sqrt(np.load(\"UniHPC_HPCmaxvar.npy\"))[2:-1]\n",
    "# a = np.load(\"RePFCave.npy\")\n",
    "# a_err = np.load(\"RePFCvar.npy\")\n",
    "# b = np.load(\"uniPFCave.npy\")\n",
    "# b_err = np.load(\"uniPFCvar.npy\")\n",
    "x = np.arange(0,a.size*5,5)\n",
    "\n",
    "model_LR_a = linregress(x,a)\n",
    "model_LR_b = linregress(x,b)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,a,\"o\")\n",
    "plt.errorbar(x,a,yerr=a_err, fmt=\"o\", color=\"b\", alpha=0.3)\n",
    "plt.plot(x,b,\"o\")\n",
    "plt.errorbar(x,b,yerr=b_err, fmt=\"o\", color=\"orange\", alpha=0.3)\n",
    "plt.plot(x,model_LR_a.intercept + model_LR_a.slope*x,color=\"C0\")\n",
    "plt.plot(x,model_LR_b.intercept + model_LR_b.slope*x,color=\"C1\")\n",
    "plt.show()\n",
    "print(np.corrcoef(x,a),np.corrcoef(x,b))\n",
    "print(st.f_oneway(np.array(a),np.array(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########    Eigenvalue and PFC/HPCcorrelation check   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "#     ###  ver1's test  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,1],color=colors[-1])\n",
    "#     plt.plot(traj_noise[:,0,1],color=colors[-2])\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0])))\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1])))\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,0]-feature[data_limit:,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,1]-feature[data_limit:,1]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,2]-feature[data_limit:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,0]-feature[data_limit:,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,1]-feature[data_limit:,1]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,2]-feature[data_limit:,2]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     Re_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]\n",
    "#     Re_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]\n",
    "#     Re_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,0])-moving_average(feature[100:,0])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,1])-moving_average(feature[100:,1])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,2])-moving_average(feature[100:,2])))\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "    \n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "# #     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "# #     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "# #     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "# #     fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "#     a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "#     a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "#     fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "#     b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "#     b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "# #     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "#     Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "#     c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "#     c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "#     Re_uw,Re_uv = LA.eig(Re_w[:,20:])\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "#     print(np.count_nonzero(Re_uw.real>0))\n",
    "#     print(np.count_nonzero(Re_uw.imag==0))\n",
    "#     print(np.count_nonzero((Re_uw.imag==0)*(Re_uw.real>0)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20])\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "    \n",
    "    HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,2:],[(0,0),(0,0)]))\n",
    "\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "#     HPC_allw = HPC_inw[0:20]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "    PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "    Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20]\n",
    "#     Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "    all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "        \n",
    "#     if model_path in test_list_B:\n",
    "# #         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         PCA_list_B = np.concatenate((PCA_list_B,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#     else:\n",
    "#         PCA_list_A = np.concatenate((PCA_list_A,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "       \n",
    "    \n",
    "    return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.min([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),np.mean(abs(all_uw))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "\n",
    "    total_ratio_list = np.array([])\n",
    "    total_ratio_list_max = np.array([])\n",
    "    total_eigen_list = np.array([])\n",
    "    allratio_list = []\n",
    "    good_points = []\n",
    "    failed_points = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniPFC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            eigen_list = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "    #         good_list = []\n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "    #             PFC,HPC = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,eigen = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "    #             ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list.append(np.abs(PFC))\n",
    "                ratio_list.append(np.abs(HPC_max))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "    #             ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "                ratio_list_max.append(np.abs(PFC_max))\n",
    "                eigen_list.append(eigen)\n",
    "    #             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "    #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "        #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "                print(PFC_max,HPC_max,eigen)\n",
    "                if good_flag != True and model in good_list:\n",
    "                    good_flag = True\n",
    "                    first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #                 first_goodmodel[1] = ratio_list[-1]\n",
    "                    first_goodmodel[1] = ratio_list_max[-1]\n",
    "\n",
    "                if model in good_list:\n",
    "    #                 correlation_fig.plot(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"b\")\n",
    "#                     correlation_fig.plot(np.array(ratio_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"b\")\n",
    "    #                 correlation_fig.text(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),np.array(ratio_list_max[-1]),\"o\",color=\"b\",alpha=0.3)\n",
    "                    correlation_fig.plot(0,np.array(ratio_list_max[-1]),\"o\",color=\"b\",alpha=0.3)\n",
    "                    good_points.append(np.array(ratio_list_max[-1]))\n",
    "\n",
    "\n",
    "                else:\n",
    "    #                 correlation_fig.plot(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"r\")\n",
    "#                     correlation_fig.plot(np.array(ratio_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"r\")\n",
    "    #                 correlation_fig.text(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),np.array(ratio_list_max[-1]),\"o\",color=\"r\",alpha=0.3)\n",
    "                    correlation_fig.plot(1,np.array(ratio_list_max[-1]),\"o\",color=\"r\",alpha=0.3)\n",
    "                    failed_points.append(np.array(ratio_list_max[-1]))\n",
    "\n",
    "\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "    #         ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "    #         ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "    #         correlation_fig.plot(np.array(eigen_list),np.array(ratio_list_max),\"o\",color=\"C{}\".format(i))\n",
    "    #         if good_flag == True:\n",
    "    #             correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "#             print(np.corrcoef(np.array(ratio_list),np.array(ratio_list_max)))\n",
    "            total_ratio_list = np.append(total_ratio_list,np.array(ratio_list))\n",
    "            total_ratio_list_max = np.append(total_ratio_list_max,np.array(ratio_list_max))\n",
    "            total_eigen_list = np.append(total_eigen_list,np.array(eigen_list))\n",
    "            allratio_list.append(ratio_list_max)\n",
    "#     np.save(\"UniPFC_PFCminave.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"UniPFC_PFCminvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "#     print(np.corrcoef(np.array(total_eigen_list),np.array(total_ratio_list_max)))\n",
    "    print(scipy.stats.f_oneway(good_points, failed_points))\n",
    "    print(st.ttest_ind(good_points, failed_points,equal_var=False))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Eigenvalue vs PFCcorrelation. interesting activity  #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "#     ###  ver1's test  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,1],color=colors[-1])\n",
    "#     plt.plot(traj_noise[:,0,1],color=colors[-2])\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0])))\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1])))\n",
    "    print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,0]-feature[data_limit:,0]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,1]-feature[data_limit:,1]))\n",
    "#     plt.plot(np.abs(feature[:data_limit,2]-feature[data_limit:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "    plt.plot(np.abs(feature[:data_limit,0]-feature[data_limit:,0]))\n",
    "    plt.plot(np.abs(feature[:data_limit,1]-feature[data_limit:,1]))\n",
    "    plt.plot(np.abs(feature[:data_limit,2]-feature[data_limit:,2]))\n",
    "    plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     Re_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]\n",
    "#     Re_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]\n",
    "#     Re_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,0])-moving_average(feature[100:,0])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,1])-moving_average(feature[100:,1])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,2])-moving_average(feature[100:,2])))\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "    \n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "# #     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "# #     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "# #     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "# #     fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "#     a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "#     a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "#     fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "#     b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "#     b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "# #     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "#     Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "#     c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "#     c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "#     Re_uw,Re_uv = LA.eig(Re_w[:,20:])\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "#     print(np.count_nonzero(Re_uw.real>0))\n",
    "#     print(np.count_nonzero(Re_uw.imag==0))\n",
    "#     print(np.count_nonzero((Re_uw.imag==0)*(Re_uw.real>0)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20])\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "    \n",
    "    HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,2:],[(0,0),(0,0)]))\n",
    "\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "#     HPC_allw = HPC_inw[0:20]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "    PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "    Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20]\n",
    "#     Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "    all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "        \n",
    "#     if model_path in test_list_B:\n",
    "# #         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         PCA_list_B = np.concatenate((PCA_list_B,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#     else:\n",
    "#         PCA_list_A = np.concatenate((PCA_list_A,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "       \n",
    "    \n",
    "    return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),np.mean(abs(all_uw))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "\n",
    "    total_ratio_list = np.array([])\n",
    "    total_ratio_list_max = np.array([])\n",
    "    total_eigen_list = np.array([])\n",
    "    for i in range(1):\n",
    "        path = 'model/R20_H_bigbatch/'\n",
    "#         path = 'model/R20_H_uniPFC_bigbatch/'\n",
    "        model_list = glob.glob(path+'*s'+str(i+3)+'_100_3_*epoch*.pth')\n",
    "        model_list = sorted(model_list)\n",
    "        model_list = sorted(model_list,key=len,reverse=False)\n",
    "        ratio_list = []\n",
    "        ratio_list_max = []\n",
    "        eigen_list = []\n",
    "        with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "            good_list = f.read().splitlines()\n",
    "#         good_list = []\n",
    "        first_goodmodel = [0,0]\n",
    "        good_flag = False\n",
    "        k=0\n",
    "        for model in model_list:\n",
    "            print(model)\n",
    "#             PFC,HPC = main(model)\n",
    "            PFC,HPC,PFC_max,HPC_max,eigen = main(model)\n",
    "#             ratio_list.append(PFC/HPC)\n",
    "#             ratio_list.append(np.abs(PFC-HPC))\n",
    "#             ratio_list.append(np.abs(PFC))\n",
    "            ratio_list.append(np.abs(HPC_max))\n",
    "#             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#             ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "            ratio_list_max.append(np.abs(PFC_max))\n",
    "            eigen_list.append(eigen)\n",
    "#             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "#             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "    #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "            print(PFC_max,HPC_max,eigen)\n",
    "            if good_flag != True and model in good_list:\n",
    "                good_flag = True\n",
    "                first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#                 first_goodmodel[1] = ratio_list[-1]\n",
    "                first_goodmodel[1] = ratio_list_max[-1]\n",
    "    \n",
    "            if model in good_list:\n",
    "                correlation_fig.plot(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"r\")\n",
    "#                 correlation_fig.plot(np.array(ratio_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"r\")\n",
    "                correlation_fig.text(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "            else:\n",
    "                correlation_fig.plot(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"b\")\n",
    "#                 correlation_fig.plot(np.array(ratio_list[-1]),np.array(ratio_list_max[-1]),\"o\",color=\"b\")\n",
    "                correlation_fig.text(np.array(eigen_list[-1]),np.array(ratio_list_max[-1]),model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "\n",
    "                                     \n",
    "            k+=1\n",
    "#         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "#         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "#         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "#         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "        \n",
    "#         ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#         ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#         correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#         correlation_fig.plot(np.array(eigen_list),np.array(ratio_list_max),\"o\",color=\"C{}\".format(i))\n",
    "#         if good_flag == True:\n",
    "#             correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "        print(np.corrcoef(np.array(ratio_list),np.array(ratio_list_max)))\n",
    "        total_ratio_list = np.append(total_ratio_list,np.array(ratio_list))\n",
    "        total_ratio_list_max = np.append(total_ratio_list_max,np.array(ratio_list_max))\n",
    "        total_eigen_list = np.append(total_eigen_list,np.array(eigen_list))\n",
    "    print(np.corrcoef(np.array(total_eigen_list),np.array(total_ratio_list_max)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_?.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "model_list = glob.glob('model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s*_100_*_epoch*.pth')\n",
    "# model_list = glob.glob('model/R20_H_stopinit_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s*_100_*_epoch1??.pth')\n",
    "# model_list = glob.glob('model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s*_100_*_epoch1??.pth')\n",
    "# model_list = glob.glob('model_test/4_2/*.pth')\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"model/R20_H_bigbatch/good_list.txt\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "    \n",
    "# with open(\"attract_contfail_test_list2.txt\") as f:\n",
    "with open(\"attract_contfail_list_add_test.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "# with open(\"attract_contgood_test_list.txt\") as f:\n",
    "with open(\"attract_contgood_list_add_test.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "    \n",
    "test_list_A_selected = []\n",
    "test_list_B_selected = []\n",
    "test_list_A_limited = []\n",
    "test_list_B_limited = []\n",
    "\n",
    "for model_path in model_list:\n",
    "    if model_path in test_list_A:\n",
    "        test_list_A_selected.append(model_path)\n",
    "    if model_path in test_list_B:\n",
    "        test_list_B_selected.append(model_path)            \n",
    "\n",
    "# if len(test_list_A_selected) > len(test_list_B_selected):\n",
    "#     random_num = np.random.randint(0,len(test_list_A_selected),len(test_list_B_selected))\n",
    "#     for i in random_num:\n",
    "#         test_list_A_limited.append(test_list_A_selected[i])\n",
    "#     test_list_B_limited = test_list_B_selected\n",
    "# else:\n",
    "#     random_num = np.random.randint(0,len(test_list_B_selected),len(test_list_A_selected))\n",
    "#     for i in random_num:\n",
    "#         test_list_B_limited.append(test_list_B_selected[i])\n",
    "#     test_list_A_limited = test_list_A_selected\n",
    "\n",
    "limited_number = 0\n",
    "if limited_number > 0:\n",
    "    random_num = np.random.randint(0,len(test_list_A_selected),limited_number)\n",
    "    for i in random_num:\n",
    "        test_list_A_limited.append(test_list_A_selected[i])\n",
    "    random_num = np.random.randint(0,len(test_list_B_selected),limited_number)\n",
    "    for i in random_num:\n",
    "        test_list_B_limited.append(test_list_B_selected[i])\n",
    "else:\n",
    "    test_list_A_limited = test_list_A_selected\n",
    "    test_list_B_limited = test_list_B_selected\n",
    "\n",
    "    \n",
    "print(len(test_list_A_limited),len(test_list_B_limited))\n",
    "    \n",
    "# test_list = glob.glob('model/R20/*s1*_100_2*.pth')\n",
    "# test_list = glob.glob('model/R20_cont/*OUT1*s*_100_*.pth')\n",
    "# test_list = glob.glob('model_test/4_2/*.pth')\n",
    "test_list = model_list\n",
    "# test_list = lines\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# target = [11,12,-2]\n",
    "# target = [21,22,23]\n",
    "# target = [-7, -2]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "\n",
    "target_list = model_list[:]\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(111)\n",
    "test_colors = []\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "PCA_list_A = np.array([[0,1,2,3,4]])\n",
    "PCA_list_B = np.array([[0,1,2,3,4]])\n",
    "\n",
    "stat_list_A = []\n",
    "stat_list_B = []\n",
    "\n",
    "stat_list_xy_A = [np.array([0]),np.array([0])]\n",
    "stat_list_xy_B = [np.array([0]),np.array([0])]\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "    \n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "# #     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "# #     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "# #     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "# #     fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "#     a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "#     a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "#     fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "#     b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "#     b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "# #     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "#     Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "#     c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "#     c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "#     Re_uw,Re_uv = LA.eig(Re_w[:,20:])\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "#     print(np.count_nonzero(Re_uw.real>0))\n",
    "#     print(np.count_nonzero(Re_uw.imag==0))\n",
    "#     print(np.count_nonzero((Re_uw.imag==0)*(Re_uw.real>0)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20])\n",
    "#     print(PFC_inuw,PFC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=testcolor,zorder=2)\n",
    "#     else :\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=color,alpha=0.01,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(PFC_inuw.real[k],PFC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(PFC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(PFC_inuw.real>0))\n",
    "#     print(np.count_nonzero(PFC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((PFC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "#     print(HPC_inuw,HPC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "# #     elif num < 40:\n",
    "# #         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=\"b\",alpha=1)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(HPC_inuw.real[k],HPC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(HPC_inuw.real>0))\n",
    "#     print(np.count_nonzero(HPC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "#     HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,2:],[(0,0),(0,0)]))\n",
    "#     HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,:2],[(0,0),(0,18)]))\n",
    "#     print(HPC_uw,HPC_uv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     print(np.count_nonzero(HPC_uw.real>0))\n",
    "#     print(np.count_nonzero(HPC_uw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_uw.imag==0)*(HPC_uw.real>0)))\n",
    "\n",
    "# #     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "# #     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "# #     HPC_allw = HPC_inw[0:20]\n",
    "# #     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "# #     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = (PFC_w[0:20,:20]+PFC_inw[0:20])*(PFC_w[40:60,:20]+PFC_inw[40:60])\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw2 = (PFC_w[0:20,20:]+PFC_inw[0:20])*(PFC_w[40:60,20:]+PFC_inw[40:60])\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "    Re_allw  = Re_w[:,0:20]\n",
    "#     Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2)\n",
    "    all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(Re_inw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * Re_allw2 + PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw * Re_allw2 + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw * Re_allw * HPC_allw + PFC_allw2 * Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw @ Re_allw @ HPC_allw + PFC_allw2 @ Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(np.pad(Out_w[:,:],[(0,18),(0,0)]))\n",
    "#     all_uw,all_uv = LA.eig(Out_w[:,:]@(HPC_w[0:20,:2]*HPC_w[40:60,:2]))\n",
    "#     all_uw,all_uv = LA.eig(np.pad(HPC_w[20:40,:2],[(0,0),(0,18)]))\n",
    "#     all_uw,all_uv = LA.eig(np.pad(HPC_w[60:,:2],[(0,0),(0,18)]))\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[20:40])\n",
    "# #     print(HPC_inuw,HPC_inuv)\n",
    "\n",
    "    if int(model_path.split(\"epoch\")[-1].split(\".\")[0]) < 70:\n",
    "        continue\n",
    "\n",
    "    if model_path in good_list:\n",
    "        testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "        testcolor = \"b\"\n",
    "        test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=testcolor,alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(0,np.average(abs(all_uw)),\"o\",color=testcolor,alpha=0.3,zorder=1)\n",
    "        fig_eigenval.plot(int(model_path.split(\"epoch\")[-1].split(\".\")[0]),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         print(model_path,testcolor,np.average(abs(all_uw)))\n",
    "        stat_list_A.append(np.average((abs(all_uw))))\n",
    "#         print(all_uw)\n",
    "#         print(all_uv.T)\n",
    "#         print(np.count_nonzero(all_uw.real>0))\n",
    "#         print(np.count_nonzero(all_uw.imag==0))\n",
    "#         print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "#         print(np.average(abs(all_uw)))\n",
    "#         for k in range(20):\n",
    "#             fig_eigenval.text(all_uw.real[k],all_uw.imag[k],str(model_path.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "    else:\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(1,np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "        fig_eigenval.plot(int(model_path.split(\"epoch\")[-1].split(\".\")[0]),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "\n",
    "        stat_list_B.append(np.average((abs(all_uw))))\n",
    "        print(model_path,np.average(abs(all_uw)))\n",
    "        \n",
    "        \n",
    "# ## Eigenvalue first100 and last100 ##\n",
    "\n",
    "#     if int(model_path.split(\"epoch\")[-1].split(\".\")[0])<100:\n",
    "#         testnum+=1\n",
    "# #         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         testcolor = \"k\"\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=testcolor,alpha=0.1,zorder=2)\n",
    "# #         fig_eigenval.plot(0,np.average(abs(all_uw)),\"o\",color=testcolor,alpha=0.3,zorder=1)\n",
    "# #         fig_eigenval.plot(int(model_path.split(\"epoch\")[-1].split(\".\")[0]),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "#         print(model_path,testcolor,np.average(abs(all_uw)))\n",
    "#         stat_list_A.append(np.average((abs(all_uw))))\n",
    "# #         print(all_uw)\n",
    "# #         print(all_uv.T)\n",
    "# #         print(np.count_nonzero(all_uw.real>0))\n",
    "# #         print(np.count_nonzero(all_uw.imag==0))\n",
    "# #         print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "# #         print(np.average(abs(all_uw)))\n",
    "# #         for k in range(20):\n",
    "# #             fig_eigenval.text(all_uw.real[k],all_uw.imag[k],str(model_path.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "#     elif int(model_path.split(\"epoch\")[-1].split(\".\")[0])>100:\n",
    "# #         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"c\",alpha=0.1,zorder=1)\n",
    "# #         fig_eigenval.plot(1,np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "# #         fig_eigenval.plot(int(model_path.split(\"epoch\")[-1].split(\".\")[0]),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "\n",
    "#         stat_list_B.append(np.average((abs(all_uw))))\n",
    "#         print(model_path,np.average(abs(all_uw)))\n",
    "\n",
    "        \n",
    "#     if model_path in test_list_A_limited:\n",
    "# #         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "# #         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [0],\"o\", color = \"r\", alpha=0.1)\n",
    "# #         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "# #         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.zeros(20),all_uw.imag,\"o\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(0,np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "# #         fig_eigenval.plot(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],\"o\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.max(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.max(np.abs(all_uw.real)),np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "# #         print(model_path,\"bad\")\n",
    "# #         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "# #         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#         PCA_list_A = np.concatenate((PCA_list_A,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#         stat_list_A.append(np.sort((abs(all_uw))))\n",
    "# #         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.array(all_uw.real))\n",
    "# #         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.abs(all_uw.imag))\n",
    "# #         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],abs(all_uw))\n",
    "# #         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],all_uw.imag[np.where(all_uw.imag>0)])\n",
    "# #         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],abs(all_uw)[np.where(all_uw.imag>0)])\n",
    "#         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.average(abs(all_uw)))\n",
    "#         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],np.max(abs(all_uw)))\n",
    "# #         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],np.average(abs(all_uw))/np.max(abs(all_uw)))\n",
    "# #         fig_eigenval.text(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],str(model_path.split(\"s\")[-1]))\n",
    "# #         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(0,np.average(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "#     if model_path in test_list_B_limited:\n",
    "# #         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "# #         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [1],\"o\", color = \"b\", alpha=0.1)\n",
    "# #         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))],[np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "# #         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "# #         fig_eigenval.plot(np.ones(20),all_uw.imag,\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(1,np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "# #         fig_eigenval.plot(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "# #         fig_eigenval.plot(np.max(np.abs(all_uw.real)),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "# #         print(model_path,\"good\")\n",
    "# #         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "# #         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#         PCA_list_B = np.concatenate((PCA_list_B,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#         stat_list_B.append(np.sort((abs(all_uw))))\n",
    "# #         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],all_uw.real)\n",
    "# #         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],np.abs(all_uw.imag))\n",
    "# #         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],abs(all_uw))\n",
    "# #         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],abs(all_uw.imag[np.where(all_uw.imag>0)]))\n",
    "# #         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],abs(all_uw)[np.where(all_uw.imag>0)])\n",
    "#         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],np.average(abs(all_uw)))\n",
    "#         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],np.max(abs(all_uw)))\n",
    "# #         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],np.average(abs(all_uw))/np.max(abs(all_uw)))\n",
    "# #         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(1,np.average(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "        \n",
    "        \n",
    "# #     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(all_uw.real>0))\n",
    "#     print(np.count_nonzero(all_uw.imag==0))\n",
    "#     print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "    \n",
    "    \n",
    "#     PCA_list = np.concatenate((PCA_list,[[a1,a2,c2]]),axis=0)\n",
    "#     print(a1-a2)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# # # print(PCA_list[1:])\n",
    "# PCA_list = np.concatenate((PCA_list_A[1:],PCA_list_B[1:]),axis=0)\n",
    "# length = PCA_list_A[1:].shape[0]\n",
    "# pca = PCA()\n",
    "# dfs = PCA_list\n",
    "# pca.fit(dfs)\n",
    "# feature = pca.transform(dfs)\n",
    "# # print(length,feature)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(feature[:length, 0], feature[:length, 1], color=\"r\",alpha=0.2)\n",
    "# plt.scatter(feature[length:, 0], feature[length:, 1], color=\"b\",alpha=0.2)\n",
    "# #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# # for i,n in enumerate(target_list):\n",
    "# #     plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "\n",
    "# fig3d = plt.figure()\n",
    "# ax3d = Axes3D(fig3d)\n",
    "# ax3d.plot(feature[:length, 0], feature[:length, 1], feature[:length, 2], \"o\", alpha=0.1)\n",
    "# ax3d.plot(feature[length:, 0], feature[length:, 1], feature[length:, 2], \"o\", alpha=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# gradient = np.array(test_colors)\n",
    "# gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(gradient, cmap=plt.cm.jet)\n",
    "# ax.set_axis_off()\n",
    "\n",
    "fig_eigenval.tick_params(axis=\"both\",labelsize=28)\n",
    "\n",
    "# print(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T)\n",
    "# st.f_oneway(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T)\n",
    "print(st.f_oneway(np.array(stat_list_A).reshape(-1,1),np.array(stat_list_B).reshape(-1,1)))\n",
    "# st.ttest_ind(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T,equal_var=False)\n",
    "plt.figure()\n",
    "#     plt.boxplot([good_points, bad_points],labels=[\"Good\",\"Bad\"])\n",
    "#     violinplot = plt.violinplot([good_points, bad_points],showmedians=False,showextrema=False)\n",
    "\n",
    "good_points = stat_list_A\n",
    "bad_points = stat_list_B \n",
    "\n",
    "quartile1_good, medians_good, quartile3_good = np.percentile(good_points, [25, 50, 75])\n",
    "#     lower_good,upper_good = adjacent_values(good_points, quartile1_good, quartile3_good)\n",
    "quartile1_bad, medians_bad, quartile3_bad = np.percentile(bad_points, [25, 50, 75])\n",
    "\n",
    "#     plt.vlines(1, quartile1_good, quartile3_good, color='k', linestyle='-', lw=5)\n",
    "#     plt.vlines(1, upper_good,lower_good, color='k', linestyle='-', lw=1)\n",
    "#     plt.scatter([1], [medians_good], marker='o', color='white', s=30, zorder=3)\n",
    "#     plt.vlines(2, quartile1_bad, quartile3_bad, color='k', linestyle='-', lw=5)\n",
    "#     violinplot[\"bodies\"][1].set_facecolor(\"red\")\n",
    "palette = sns.color_palette(\"Pastel1\")\n",
    "my_pal = {0:palette[1],1:palette[0]}\n",
    "my_pal_strip = {0:\"b\",1:\"r\"}\n",
    "sns.stripplot(data=[np.random.choice(good_points,200),np.random.choice(bad_points, 200)],palette=my_pal_strip,zorder=2)\n",
    "sns.violinplot(data=[good_points,bad_points], palette=my_pal,linewidth=2)\n",
    "plt.scatter([0,1], [medians_good,medians_bad], marker='o', color='white', s=50, zorder=3)\n",
    "plt.xticks([0,1],labels=[\"Good\",\"Failed\"])\n",
    "plt.yticks(fontsize=28)\n",
    "plt.xticks(fontsize=28)\n",
    "plt.plot()\n",
    "sns.set_palette(\"tab10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 19 10:54:37 2021\n",
    "\n",
    "@author: munenori\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def correct_traj(traj):\n",
    "    Rightflag = False\n",
    "    Leftflag = False\n",
    "    Pointflag = False\n",
    "    correct_number = 0\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,0] < 0.3 and Pointflag == False:\n",
    "            Leftflag = True\n",
    "            Pointflag = True\n",
    "            if Rightflag == True:\n",
    "                correct_number += 1\n",
    "                Rightflag = False\n",
    "        if traj[i,0] > 0.3 and traj[i,0] < 0.5 and Pointflag == True:\n",
    "            Pointflag = False\n",
    "            \n",
    "        if traj[i,0] > 0.7 and Pointflag == False:\n",
    "            Rightflag = True\n",
    "            Pointflag = True\n",
    "            if Leftflag == True:\n",
    "                correct_number += 1\n",
    "                Leftflag = False\n",
    "        if traj[i,0] < 0.7 and traj[i,0] > 0.5 and Pointflag == True:\n",
    "            Pointflag = False\n",
    "\n",
    "    return correct_number\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation2(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_testdata(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_test_1.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_attracter_gate_PFC.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_3D(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.01):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "#     ###  ver1  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM_comp(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_comp, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        hidden1 = self.LSTM1(input, hiddens[0])\n",
    "        hidden2 = self.LSTM2(hidden1[0], hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.2, torch.rand(self.batch_size, self.hidden_size)*0.2]\n",
    "        return [hidden,hidden]  \n",
    "    \n",
    "class MyLSTM_comp_cue2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_comp_cue2, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size-1, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size+1, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        hidden1 = self.LSTM1(input[:,:2], hiddens[0])\n",
    "        # print(hidden1[0].shape,torch.reshape(input[:,2],(10,1)))\n",
    "        hidden2_input = torch.cat((hidden1[0],torch.reshape(input[:,2],(10,1))),dim=1)\n",
    "        hidden2 = self.LSTM2(hidden2_input, hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.2, torch.rand(self.batch_size, self.hidden_size)*0.2]\n",
    "        # hidden = [torch.tensor(torch.rand(self.batch_size, self.hidden_size)*0.2,retain_graph=True), torch.tensor(torch.rand(self.batch_size, self.hidden_size)*0.2,retain_graph=True)]\n",
    "        return [hidden,hidden]    \n",
    "\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 30\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/compare30_H_bigbatch/Compare30_121H_s8_100_1_epoch120.pth'\n",
    "    model_path = 'model/PFCHPC30_H_bigbatch/v4_3_121_s2_100_2_epoch185.pth'\n",
    "\n",
    "    sparse = 1\n",
    "    \n",
    "    # delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_PFCHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "    # rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    # hidden = rnn.initHidden()\n",
    "    data_limit = 400\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "    for k in range(data.shape[0]*0+10):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    # MakeAnimation2(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    # MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    # MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    # MakeAnimation_img(np.array(Restate),\"Re\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "        if n == \"LSTM1.weight_ih\":\n",
    "            PFC_w = np.array(p.data)\n",
    "        if n == \"LSTM2.weight_ih\":\n",
    "            HPC_w = np.array(p.data)\n",
    "        if n == \"LSTM1.weight_hh\":\n",
    "            PFC_inw = np.array(p.data)\n",
    "        if n == \"LSTM2.weight_hh\":\n",
    "            HPC_inw = np.array(p.data)\n",
    "                \n",
    "                \n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "#     plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "\n",
    "    for i in range(30):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0],alpha=0.5)\n",
    "        plt.plot(traj[:,0,1],alpha=0.5)\n",
    "#         plt.plot(traj_noise[:,0,0],alpha=0.5)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "            plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])[2:],alpha=1)\n",
    "#             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[:,i])[4:-4],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "            plt.plot(np.array(feature)[:,0],alpha=0.5)\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate)[:300,i]),alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate_noise)[:300,i]),alpha=0.5)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     a = np.abs(np.corrcoef(np.array(PFCstate)[:,0].T) - np.corrcoef(np.array(PFCstate_noise)[:,0].T))\n",
    "# #     a = np.abs(np.corrcoef(np.array(Restate)[:].T) - np.corrcoef(np.array(Restate_noise)[:].T))\n",
    "#     plt.imshow(a,cmap=plt.get_cmap(\"Reds\"))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    delays = pick_traj(traj[:,0], np.array(feature)[:])\n",
    "    bifur = np.array([])\n",
    "    for i in range(1):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:120,0,0],alpha=0.5)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for data in delays[:]:\n",
    "#             plt.plot(np.array(data)[:,0+i,0],alpha=0.5)\n",
    "            plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data))\n",
    "#             check_bifur = np.argmax(np.abs(np.array(data)[:,0+i,0] - 0.5))\n",
    "#             bifur = np.append(bifur,data[check_bifur,i,0])\n",
    "#             print(check_bifur,data[check_bifur,i,0])\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             k+=0\n",
    "#             data = PFC_w_a[i]\n",
    "#             plt.plot(data)\n",
    "#             data = PFC_w_b[i]\n",
    "#             plt.plot(data)\n",
    "\n",
    "#     length = 140\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "# #     plt.show()\n",
    "#     neuron_list = []\n",
    "#     neuron_list_Re = []\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons_a = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#         neurons_b = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(40):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_w_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_w_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_w_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_w_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_w_a[i,k],Re_w_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "            \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         i+=0\n",
    "#         neurons_a = np.array(Restate)[:]\n",
    "#         neurons_b = np.array(Restate_noise)[:]\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_inw_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_inw_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_inw_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_inw_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_inw_a[i,k],Re_inw_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list_Re.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    \n",
    "#     pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(feature[:240, 0], feature[:240, 1], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "#     delays = pick_traj(traj[:,0], feature[:])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for data in delays[1:-1]:\n",
    "# #             plt.plot(np.array(data)[:,0+i,0],alpha=0.5)\n",
    "# #             plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(data)[:,0+i]-moving_average(np.array(data)[:,0+i])[2:-2],alpha=0.5)\n",
    "# #             print(len(data))\n",
    "# #             check_bifur = np.argmax(np.abs(np.array(data)[:,0+i,0] - 0.5))\n",
    "# #             bifur = np.append(bifur,data[check_bifur,i,0])\n",
    "# #             print(check_bifur,data[check_bifur,i,0])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "#     print(collections.Counter(neuron_list))\n",
    "#     print(collections.Counter(neuron_list_Re))\n",
    "\n",
    "    data_limit = 120\n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "    HPC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:data_limit*2,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:data_limit*2,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:data_limit*2,2],2))\n",
    "    HPC_d = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),HPC_diff)[0,1]\n",
    "#     HPC_d = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),HPC_diff)[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    print(np.mean([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),HPC_d)\n",
    "#     print(traj[:,0,1],traj_noise[:,0,1],np.abs(traj[:,0,1]-traj_noise[:,0,1]))\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('matplotlib notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 19 10:54:37 2021\n",
    "\n",
    "@author: munenori\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams[\"figure.subplot.left\"] = 0.15\n",
    "\n",
    "#######   for phase?? like?? check   ##########\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation2(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_testdata(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_test_1.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter_gate_PFC.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_3D(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.01):\n",
    "   \n",
    "    x = np.loadtxt(\"primal_long131test_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long131test_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # ###  ver2  ###\n",
    "    # orders = []\n",
    "    # order  = np.array([1])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [2])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([2])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [3])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([3])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [4])\n",
    "    # orders.append(order) \n",
    "    # order  = np.array([4])\n",
    "    # order  = np.append(order,np.zeros(delay_length))\n",
    "    # order = np.append(order, [1])\n",
    "    # orders.append(order) \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    \n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    \n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN_noise(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_RNN_noise, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+10\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_noised = hiddens[1][0] + torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        PFC_noised = hiddens[0][0] + torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        Re_noised = hiddens[2] + torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_input = torch.cat([PFC_noised,HPC_noised],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, Re_noised)\n",
    "        HPC_input = torch.cat([input,Re_noised],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([HPC_noised,Re_noised],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "class MyLSTM_vHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_vHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.vHPC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.vHPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.vHPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[3][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        vHPC_input = hiddens[1][0]\n",
    "        vHPC_hidden = self.vHPC(vHPC_input,hiddens[2])\n",
    "        PFC_input = torch.cat([hiddens[2][0],hiddens[3][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, vHPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,vHPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "class MyLSTM_feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse):\n",
    "        super(MyLSTM_feedforward, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "    \n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*v\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s'+str(num)+'_100_2_2.pth'\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s2_100_1_2.pth'\n",
    "#     model_path = 'model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s6_100_3_epoch130.pth'\n",
    "    model_path = 'model/R20_H_stopinit_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s7_100_1_epoch195.pth'\n",
    "#     model_path = 'model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s10_100_2_epoch170.pth'\n",
    "#     model_path = 'model/R20_H_uniHPC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_2_epoch160.pth'\n",
    "#     model_path = 'model/R20_uniPFC_H/ReModel_L2_interRNNrand_OUT1_uniPFC_121H_s5_100_2_epoch85.pth'\n",
    "#     model_path = 'model/R20_uniHPC_H/ReModel_L2_interRNNrand_OUT1_121H_s2_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_H_transfer2B/ReModel_L2_interRNNrand_OUT1_transfers14_121_s2_100_2_epoch60.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s4_100_3_epoch190.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s8_100_1_epoch180.pth'\n",
    "\n",
    "\n",
    "    sparse = 1\n",
    "    delay_length = 2\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "\n",
    "    # train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "    test_x = mkOwnDataSet(test_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "    \n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 600\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    for k in range(data.shape[0]*0+10):\n",
    "#             if output.tolist()[0][1]<0.05:\n",
    "#                 hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             print(output)\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    HPCfeature = pca.transform(dfs)\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    datalen = 120\n",
    "    print(np.corrcoef(np.abs(traj[:datalen*1,0,1]-traj[datalen*2:datalen*3,0,1]),np.abs(feature[:datalen*1,0]-feature[datalen*2:datalen*3,0]))[0,1])\n",
    "    \n",
    "    delaysA = pick_delay(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delaysA = pick_delay(traj[:,0], np.array(HPCfeature)[:])\n",
    "    delaysB = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "    PCAnum = 0\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        for k,data in enumerate(delaysA[1:-1]):\n",
    "#             plt.plot(data[:,i])\n",
    "#             plt.plot(np.array(delaysB[1+k])[:,0])\n",
    "            movingA = moving_average(data[:,i])\n",
    "            movingB = moving_average(np.array(delaysB[1+k])[:,PCAnum])\n",
    "            fracA = data[:,i] - movingA[2:-2]\n",
    "            fracB = np.array(delaysB[1+k])[:,PCAnum]- movingB[2:-2]\n",
    "#             print(np.corrcoef(fracA,fracB)[0,1])\n",
    "            fracA[np.abs(fracA)<0.001] = 0\n",
    "            print(\"No\"+str(k))\n",
    "            for t in range(8):\n",
    "#                 print(np.corrcoef(np.sign(fracA)[:-3],np.sign(fracB)[k:k-3])[0,1])\n",
    "                print(math.dist(np.sign(fracA)[4:-4],np.sign(fracB)[t:t-8]))\n",
    "#             print(data.shape)\n",
    "        plt.plot((fracA))\n",
    "        plt.plot((fracB))\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "    data_limit = 120\n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:data_limit,0,0]-traj[data_limit:data_limit*2,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:data_limit*2,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:data_limit*2,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:data_limit*2,2]))[0,1]\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "    HPC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:data_limit*2,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:data_limit*2,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:data_limit*2,2],2))\n",
    "    HPC_d = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),HPC_diff)[0,1]\n",
    "#     HPC_d = np.corrcoef(np.abs(traj[:data_limit,0,1]-traj[data_limit:data_limit*2,0,1]),HPC_diff)[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    print(np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),HPC_d)\n",
    "        \n",
    "                              \n",
    "if __name__ == '__main__':\n",
    "    features = []\n",
    "    for i in range(1):\n",
    "        features.append(main(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########## stft include ######################\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 19 10:54:37 2021\n",
    "\n",
    "@author: munenori\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams[\"figure.subplot.left\"] = 0.15\n",
    "\n",
    "import numpy as np\n",
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# import time\n",
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.animation as animation\n",
    "# import sklearn \n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.cluster import KMeans\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# import pandas as pd\n",
    "from scipy.fft import fft \n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s'+str(num)+'_100_2_2.pth'\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s2_100_1_2.pth'\n",
    "    model_path = 'model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s2_100_3_epoch150.pth'\n",
    "#     model_path = 'model/R20_H_stopinit_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s3_100_1_epoch295.pth'\n",
    "#     model_path = 'model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s10_100_2_epoch170.pth'\n",
    "#     model_path = 'model/R20_H_uniHPC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_2_epoch160.pth'\n",
    "#     model_path = 'model/R20_uniPFC_H/ReModel_L2_interRNNrand_OUT1_uniPFC_121H_s5_100_2_epoch85.pth'\n",
    "#     model_path = 'model/R20_uniHPC_H/ReModel_L2_interRNNrand_OUT1_121H_s2_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_H_transfer2B/ReModel_L2_interRNNrand_OUT1_transfers14_121_s2_100_2_epoch60.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s4_100_3_epoch190.pth'\n",
    "#     model_path = 'model/R20FF_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s8_100_1_epoch180.pth'\n",
    "\n",
    "    model_path_noise = 'model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s2_100_3_epoch180.pth'\n",
    "\n",
    "\n",
    "    sparse = 1\n",
    "    delay_length = 2\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "\n",
    "    # train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "#     test_x = mkOwnDataSet(test_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size, sparse)\n",
    "    \n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    pattern = 4\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()                \n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "\n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 40\n",
    "    est_length = 2\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length+10):\n",
    "#             if output.tolist()[0][1]<0.05:\n",
    "#                 hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             print(output)\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    rnn.load_state_dict(torch.load(model_path_noise))\n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length+10):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # MakeAnimation2(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    # MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    # MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    # MakeAnimation_img(np.array(Restate),\"Re\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "    # MakeAnimation_data(pltdata[:,0,0],pltdata[:,0,1],data_limit)\n",
    "\n",
    "    # for n, p in rnn.named_parameters():\n",
    "    #         if n == \"PFC.weight_ih\":\n",
    "    #             PFC_w = np.array(p.data)\n",
    "    #         if n == \"HPC.weight_ih\":\n",
    "    #             HPC_w = np.array(p.data)\n",
    "    #         if n == \"Re.weight_ih\":\n",
    "    #             Re_w = np.array(p.data)\n",
    "                \n",
    "    # # for n, p in rnn.named_parameters():\n",
    "    # #         if n == \"PFC.weight_hh\":\n",
    "    # #             PFC_w = np.array(p.data)\n",
    "    # #         if n == \"HPC.weight_hh\":\n",
    "    # #             HPC_w = np.array(p.data)\n",
    "    # #         if n == \"Re.weight_hh\":\n",
    "    # #             Re_w = np.array(p.data)\n",
    "                \n",
    "    # fig2 = plt.figure()\n",
    "    # ax1 = fig2.add_subplot(131)\n",
    "    # ax2 = fig2.add_subplot(132)\n",
    "    # axre = fig2.add_subplot(133)\n",
    "    \n",
    "    # ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    # ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    # axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    # ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    # ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    # axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "\n",
    "    \n",
    "    # fig3 = plt.figure()\n",
    "    # ax3 = fig3.add_subplot(131)\n",
    "    # ax4 = fig3.add_subplot(132)\n",
    "    # axre2 = fig3.add_subplot(133)\n",
    "    # ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0]))\n",
    "    # ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0]))\n",
    "    # axre2.imshow(np.corrcoef(np.array(Restate)))\n",
    "    # ax3.set_title(\"PFC\")   \n",
    "    # ax4.set_title(\"HPC\")  \n",
    "    # axre2.set_title(\"Re\")  \n",
    "    \n",
    "    # Replot = plt.figure()\n",
    "    # axre2 = Replot.add_subplot(111)\n",
    "    # axre2.imshow(np.corrcoef(np.array(Restate)))\n",
    "    # axre2.set_title(\"Re\")  \n",
    "    \n",
    "#     pca = PCA()\n",
    "#     # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "#     # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "# #     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "    # print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    # print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    # print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    # pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    # #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "    # plt.scatter(feature[0, 0], feature[0, 1], c=\"r\", alpha=0.8)\n",
    "    # plt.grid()\n",
    "    # plt.xlabel(\"PC1\")\n",
    "    # plt.ylabel(\"PC2\")\n",
    "    # for i in range(np.min([200,data_limit+k])):\n",
    "    #     plt.annotate(i,(feature[i, 0], feature[i, 1]))\n",
    "    # plt.show()\n",
    "    \n",
    "    # # MakeAnimation_attracter(feature[:, 0], feature[:, 1])\n",
    "    \n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.3)\n",
    "    \n",
    "    # fig_place = plt.figure()\n",
    "    # place3d = Axes3D(fig_place)\n",
    "    # place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,0])\n",
    "    \n",
    "    # fig4 = plt.figure(figsize=(10,5))\n",
    "    # ax5 = fig4.add_subplot(311)\n",
    "    # ax6 = fig4.add_subplot(312)\n",
    "    # axRe3 = fig4.add_subplot(313)\n",
    "    # #ax5.plot(np.array(PFCstate)[:,0,pred==1])\n",
    "    # ax5.imshow(np.array(PFCstate)[:200,0,:].T)\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(HPCstate)[:,0],axis=1))\n",
    "    # ax6.imshow(np.array(HPCstate)[:200,0,:].T)\n",
    "    # axRe3.imshow(np.array(Restate)[:200,:].T)\n",
    "    # ax5.set_title(\"PFC\")   \n",
    "    # ax6.set_title(\"HPC\")  \n",
    "    # axRe3.set_title(\"Re\") \n",
    "    # print(pred==0)\n",
    "    \n",
    "    # # fig5 = plt.figure(figsize=(5,5))\n",
    "    # # plt.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # # plt.show()\n",
    "    # #MakeAnimation_attracter(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    \n",
    "    \n",
    "    # fig6 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:200,0,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:200,0,0:].T),np.min(np.array(Gate_states)[:,0,0:].T),np.average(np.array(Gate_states)[:,0,0:].T))\n",
    "    # plt.show()\n",
    "    # fig7 = plt.figure(figsize=(10,20))\n",
    "    # plt.imshow(np.array(Gate_states)[:200,1,0:].T)\n",
    "    # print(np.max(np.array(Gate_states)[:200,1,0:].T),np.min(np.array(Gate_states)[:,1,0:].T),np.average(np.array(Gate_states)[:,1,0:].T))\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,14])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,34])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,54])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,74])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure()\n",
    "    # plt.plot(np.array(Gate_states)[:,1,13])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,33])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,53])\n",
    "    # plt.plot(np.array(Gate_states)[:,1,73])\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.plot(np.array(HPCstate)[:200,0,:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    #np.save(\"right_traj.npy\",dfs)\n",
    "    #np.save(\"left_traj.npy\",dfs)\n",
    "    \n",
    "    # fig5 = plt.figure()\n",
    "    # plt.hist(PFC_w[PFC_w.nonzero()],bins=400,range=(-2,2))\n",
    "    # fig6 = plt.figure()\n",
    "    # plt.hist(HPC_w[HPC_w.nonzero()],bins=400,range=(-2,2))    \n",
    "    # fig7 = plt.figure()\n",
    "    # plt.hist(Re_w[Re_w.nonzero()],bins=400,range=(-2,2))   \n",
    "    \n",
    "    \n",
    "    # pca = PCA()\n",
    "    # dfs = Re_w\n",
    "    # pca.fit(dfs)\n",
    "    # feature = pca.transform(dfs)\n",
    "    # pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    # plt.grid()\n",
    "    # plt.xlabel(\"PC1\")\n",
    "    # plt.ylabel(\"PC2\")\n",
    "\n",
    "    # plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,0])\n",
    "#     plt.plot(traj[:,0,1])\n",
    "    \n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "    if bifur.shape[0] == 0:\n",
    "        pass\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "    print(bifur)\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    datalen = 120\n",
    "#     print(np.corrcoef(np.abs(traj[:datalen*1,0,1]-traj[datalen*2:datalen*3,0,1]),np.abs(feature[:datalen*1,0]-feature[datalen*2:datalen*3,0]))[0,1])\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "    delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,0,0:20]-np.array(Gate_states)[:,0,20:40])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,0,0:20])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], feature[:])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "    bifur = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        for data in delays[1:-1]:\n",
    "            avedata = moving_average(data[:,0+i])\n",
    "#             plt.plot(avedata[2:-2],alpha=0.5)\n",
    "            plt.plot(data[:,0+i]-avedata[2:-2],alpha=0.5)\n",
    "#             plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(data)[:,0+i]-np.array(delays[1:-1][0])[:,0+i],alpha=0.5)\n",
    "#             plt.plot(np.log(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data),len(avedata))\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         delays = delays[1:-1]\n",
    "#         plt.plot(np.array(delays)[,:,0+i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "# #     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "    for i in range(3):\n",
    "        data_len = 1000\n",
    "        delays_samelen = []\n",
    "        result = 0\n",
    "        for data in delays[1:-1]:\n",
    "            data_len = np.min([data_len,len(data)])\n",
    "        for data in delays[1:-1]:\n",
    "            delays_samelen.append(data[:data_len])\n",
    "        delays_samelen = np.array(delays_samelen)\n",
    "        for k in range(data_len):\n",
    "            result += np.var(delays_samelen[:,k,i])\n",
    "        result /= data_len\n",
    "        print(result)\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    PFCfeature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[0:,0]\n",
    "    dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    Refeature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "#     plt.figure()\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0],alpha=0.5)\n",
    "#         plt.plot(traj_noise[:,0,1],alpha=0.5)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:data_len,k,i],alpha=0.8)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:],alpha=0.3)\n",
    "            plt.plot(np.array(HPCstate)[:data_len,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:data_len],alpha=0.8)\n",
    "#             plt.plot(np.array(PFCstate)[:data_len,k,i],alpha=0.8)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:],alpha=0.3)\n",
    "#             plt.plot(np.array(PFCstate)[:data_len,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:data_len],alpha=0.8)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[2:-2,i])[:],alpha=0.3)\n",
    "#             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[:,i])[4:-4],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,0+i],\"o\",alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,1,0+i],\"o\",alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.array(PFCfeature)[:data_len,1],alpha=0.8)\n",
    "#             plt.plot(np.array(PFCfeature)[:,0]-moving_average(np.array(PFCfeature)[2:-2,0]),alpha=0.5)\n",
    "#             plt.plot(np.array(Refeature)[:data_len,0],alpha=0.8)\n",
    "#             plt.plot(np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2],alpha=0.5)\n",
    "            plt.plot(np.array(Refeature)[:data_len,0]-moving_average(np.array(Refeature)[:data_len,0])[2:-2],alpha=0.8)\n",
    "\n",
    "\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "        plt.yticks(fontsize=26)\n",
    "        plt.xticks(fontsize=26)    \n",
    "        \n",
    "#     fig = plt.figure()\n",
    "#     fig1 = fig.add_subplot(111)\n",
    "#     fig1.hist(np.array(Gate_states)[:,1,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "#     dfs = np.array(Restate)[0:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "#     pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(feature[:240, 0], feature[:240, 1], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate_noise)[0:]\n",
    "    pca.fit(dfs)\n",
    "    Refeature_noise = pca.transform(dfs)\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    \n",
    "########### FFT Zone ######################    \n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Restate)[:,i]\n",
    "# #             data_filt = data\n",
    "# #             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "# #             data_filt = np.array(Restate)[:,i]-moving_average(np.array(Restate)[2:-2,i])[:]\n",
    "#             data_filt = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "#             fourier = fft(data_filt)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*1\n",
    "#             plt.plot(freq,np.abs(fourier))\n",
    "# #             angle = np.angle(fourier)\n",
    "# #             angle[np.abs(fourier)<0.01] = 0\n",
    "# #             plt.plot(np.degrees(angle),\"o\")\n",
    "            \n",
    "# #             data = np.array(Restate_noise)[:,i]\n",
    "# # #             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "# #             data_filt = data\n",
    "# #             fourier = fft(data_filt)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(np.log(np.abs(freq)),np.log(np.abs(fourier) ** 2),\"o\")\n",
    "# # #             plt.plot(np.degrees(np.angle(fourier)))\n",
    "\n",
    "#             data = np.array(PFCstate)[:,k,i]\n",
    "#             data_filt = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "#             fourier = fft(data_filt)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*1\n",
    "#             plt.plot(freq,np.abs(fourier))\n",
    "# #             angle = np.angle(fourier)\n",
    "# #             angle[np.abs(fourier)<1] = 0\n",
    "# #             plt.plot(np.degrees(angle),\"o\")\n",
    "\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(PFCstate)[:,k,i]\n",
    "#             data_filt = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "#             fourier = fft(data_filt)\n",
    "#             plt.plot(np.degrees(np.angle(fourier)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "    shift = 2\n",
    "    seglen = 40\n",
    "        \n",
    "\n",
    "########### scipy.spectrogram ver ######################\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(PFCstate)[:,k,i]\n",
    "#             data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx1 = signal.spectrogram(data,fs=1,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum',mode=\"psd\")\n",
    "#             plt.pcolormesh(times,freqs, (sx1))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(Restate)[:,i]\n",
    "#             data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "# #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx2 = signal.spectrogram(data,fs=1,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum',mode=\"psd\")\n",
    "#             plt.pcolormesh(times,freqs,(sx2))\n",
    "# #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(Restate)[:,i]\n",
    "#             data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "# #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx3 = signal.spectrogram(data,fs=1,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum',mode=\"psd\")\n",
    "#             plt.pcolormesh(times,freqs,(sx3))\n",
    "# #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(Restate)[:,i]\n",
    "#             data1 = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "#             data2 = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "#             freqs,sx3 = signal.coherence(data1,data2,fs=1,nperseg=seglen,noverlap=seglen-shift,detrend=False)\n",
    "#             plt.plot(freqs,(sx3))\n",
    "# #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             plt.pcolormesh(times,freqs,(xsp))\n",
    "# #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "# # ########### scipy.stft ver ######################\n",
    "#     for i in range(20):\n",
    "# #         plt.figure()\n",
    "# #         for k in range(1):\n",
    "# # #             data = np.array(PFCstate)[:,k,i]\n",
    "# #             data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "# # #             fourier = np.fft.fft(data)\n",
    "# # #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# # #             plt.plot(freq,fourier)\n",
    "# #             freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "# #             plt.pcolormesh(times,freqs, np.array(np.abs(sx1)**2))\n",
    "# # #             print(np.max((np.abs(sx1)**2)))\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "# #         plt.figure()\n",
    "# #         for k in range(1):\n",
    "# # #             data = np.array(Restate)[:,i]\n",
    "# #             data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "# # #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# # #             fourier = np.fft.fft(data)\n",
    "# # #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# # #             plt.plot(freq,fourier)\n",
    "# #             freqs,times,sx2 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "# #             plt.pcolormesh(times,freqs,np.array(np.abs(sx2)**2))\n",
    "# # #             print(np.max((np.abs(sx2)**2)))\n",
    "# # #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "# # #         plt.figure()\n",
    "# # #         for k in range(1):\n",
    "# # # #             data = np.array(Restate)[:,i]\n",
    "# # #             data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "# # # #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# # # #             fourier = np.fft.fft(data)\n",
    "# # # #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# # # #             plt.plot(freq,fourier)\n",
    "# # #             freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "# # #             plt.pcolormesh(times,freqs,(sx3))\n",
    "# # # #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "# # #         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "# # #         plt.figure()\n",
    "# # #         for k in range(1):\n",
    "# # # #             data = np.array(Restate)[:,i]\n",
    "# # #             data1 = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "# # #             data2 = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "# # #             freqs,sx3 = signal.coherence(data1,data2,fs=1,nperseg=seglen,noverlap=seglen-shift,detrend=False)\n",
    "# # #             plt.plot(freqs,(sx3))\n",
    "# # # #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "# # #         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "# #         plt.figure()\n",
    "# #         for k in range(1):\n",
    "# #             xsp = sx1*np.conjugate(sx2)\n",
    "# # #             plt.pcolormesh(times,freqs,np.abs(xsp))\n",
    "# # #             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "# #             plt.pcolormesh(times,freqs,np.log(np.abs(xsp)**2))\n",
    "# #             print(np.max(np.log10(np.abs(xsp))))\n",
    "# # #             plt.pcolormesh(times,freqs,np.array(coherence))\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "        \n",
    "        \n",
    "#         for k in range(1):\n",
    "#             data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "#             freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "# #             plt.figure()\n",
    "# #             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "# #             xsp = sx1*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "# #             xsp = sx2*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "# #             degree = np.degrees(np.angle(xsp))\n",
    "# #             print(degree.shape)\n",
    "# #             plt.figure()\n",
    "# #             plt.plot(degree)\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "#             print(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "            \n",
    "\n",
    "\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Refeature_noise)[:,0]-moving_average(np.array(Refeature_noise)[:,0])[2:-2]\n",
    "#             freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(PFCstate_noise)[:,k,i]-moving_average(np.array(PFCstate_noise)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(HPCstate_noise)[:,k,i]-moving_average(np.array(HPCstate_noise)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "# #             xsp = sx1*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence)) \n",
    "            \n",
    "# #             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "#             print(data.shape,freqs,times)\n",
    "#             print(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    features = []\n",
    "    for i in range(1):\n",
    "        features.append(main(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniHPC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 480\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    Refeature = pca.transform(dfs)\n",
    "\n",
    "    shift = 2\n",
    "    seglen = 60\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.array(PFCstate)[:,0,2]-moving_average(np.array(PFCstate)[2:-2,0,2])[:])\n",
    "    plt.plot([40,120,160,240,280,360,400,480],np.zeros(8),\"o\",color=\"k\",alpha=0.3)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2])\n",
    "    plt.plot([40,120,160,240,280,360,400,480],np.zeros(8),\"o\",color=\"k\",alpha=0.3)\n",
    "        \n",
    "    coherence_diff_list = []\n",
    "    for i in range(20):\n",
    "        for k in range(1):\n",
    "            data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "            freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "            xsp = sx1*np.conjugate(sx2)\n",
    "            coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "            plt.figure()\n",
    "            plt.pcolormesh(times,freqs,coherence)\n",
    "            plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "            print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx3)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "#             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "#             xsp = sx2*np.conjugate(sx3)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "#             degree = np.degrees(np.angle(xsp))\n",
    "#             print(degree.shape)\n",
    "#             plt.figure()\n",
    "#             plt.plot(degree)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            coherence_diff_list.append(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "            plt.plot([40,120,160,240,280,360,400,480],np.zeros(8),\"o\",color=\"k\",alpha=0.3)\n",
    "    \n",
    "    \n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "    return 0,0,0,0, np.sum(coherence_diff_list)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    for num in range(1):\n",
    "        for i in range(1):\n",
    "#             path = 'model/R20_H_bigbatch/'\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+3)+'_100_'+str(num+1)+'_*epoch150.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "                if int(model.split(\"epoch\")[-1].split(\".\")[0])>299:\n",
    "                    continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,frac = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#                 ratio_list_max.append(HPC_max)\n",
    "                ratio_list_max.append(frac)\n",
    "#                 ratio_list_max.append(PFC_max)\n",
    "#                 correlation_fig.plot(PFC_max,HPC_max,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"r\")\n",
    "    #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "        #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "                print(PFC_max,HPC_max)\n",
    "                print(\"dist:\"+str(frac))\n",
    "                if good_flag != True and model in good_list:\n",
    "                    good_flag = True\n",
    "                    first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #                 first_goodmodel[1] = ratio_list[-1]\n",
    "                    first_goodmodel[1] = ratio_list_max[-1]\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "    correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "#     np.save(\"Re_frac.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"UniHPC_HPCmaxvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########    Checker of Activity difference and grad   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniHPC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.0001):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "def culc_grad(data):\n",
    "    datalen = len(data)\n",
    "    grad_list = np.array([])\n",
    "    pre_value = data[0]\n",
    "    for i in range(datalen):\n",
    "        grad = np.abs(data[i] - pre_value)\n",
    "        grad_list = np.append(grad_list,grad)\n",
    "        pre_value = data[i]\n",
    "        \n",
    "    return grad_list\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "    PFC_activity = np.abs(feature[:data_limit,1]-feature[data_limit:,1])\n",
    "#     PFC_activity = np.abs(moving_average(feature[:data_limit,0])-moving_average(feature[data_limit:,0]))\n",
    "#     PFC_activity = np.abs((feature[:data_limit,0]-moving_average(feature[:data_limit,0])[2:-2])-(feature[data_limit:,0]-moving_average(feature[data_limit:,0])[2:-2]))\n",
    "#     PFC_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(feature[:data_limit,0],color=\"b\")\n",
    "#     plt.plot(feature[data_limit:,0],color=\"r\")\n",
    "#     plt.plot(moving_average(feature[:data_limit,0]),\":\",color=\"b\")\n",
    "#     plt.plot(moving_average(feature[data_limit:,0]),\":\",color=\"r\")\n",
    "#     plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     HPC_activity = np.abs(feature[:data_limit,0]-feature[data_limit:,0])\n",
    "    HPC_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    Re_activity = np.abs(feature[:data_limit,0]-feature[data_limit:,0])\n",
    "#     Re_activity = np.abs(moving_average(feature[:data_limit,0])-moving_average(feature[data_limit:,0]))\n",
    "#     Re_activity = np.abs((feature[:data_limit,0]-moving_average(feature[:data_limit,0])[2:-2])-(feature[data_limit:,0]-moving_average(feature[data_limit:,0])[2:-2]))\n",
    "#     Re_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(feature[:data_limit,0],color=\"b\")\n",
    "#     plt.plot(feature[data_limit:,0],color=\"r\")\n",
    "#     plt.plot(moving_average(feature[:data_limit,0]),\":\",color=\"b\")\n",
    "#     plt.plot(moving_average(feature[data_limit:,0]),\":\",color=\"r\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    return PFC_activity, HPC_activity, Re_activity\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, np.sum(coherence_diff_list)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allRe_list = []\n",
    "    allHPC_list = []\n",
    "    allPFC_list = []\n",
    "    for num in range(3):\n",
    "        for i in range(1):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            Re_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "#                 if model in good_list:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     continue\n",
    "                print(model)\n",
    "                if int(model.split(\"epoch\")[-1].split(\".\")[0])>299:\n",
    "                    continue\n",
    "                PFC_activity, HPC_activity, Re_activity = main(model)\n",
    "                allRe_list.append(Re_activity)\n",
    "                allHPC_list.append(HPC_activity)\n",
    "                allPFC_list.append(PFC_activity)\n",
    "\n",
    "                k+=1\n",
    "#             correlation_fig.plot(Re_activity,color=\"C{}\".format(i))\n",
    "    allRe_list = np.array(allRe_list)\n",
    "    allHPC_list = np.array(allHPC_list)\n",
    "    allPFC_list = np.array(allPFC_list)\n",
    "    print(allRe_list.shape)\n",
    "    correlation_fig.plot(np.mean(allRe_list,axis=0).T,color=\"C0\")\n",
    "    correlation_fig.errorbar(np.arange(allRe_list.shape[1]),np.mean(allRe_list,axis=0).T,yerr=np.sqrt(np.var(allRe_list,axis=0).T), color=\"C0\", alpha=0.3)\n",
    "#     correlation_fig.plot(np.mean(allHPC_list,axis=0).T,color=\"C1\")\n",
    "#     correlation_fig.errorbar(np.arange(allHPC_list.shape[1]),np.mean(allHPC_list,axis=0).T,yerr=np.sqrt(np.var(allHPC_list,axis=0).T), color=\"C1\", alpha=0.3)\n",
    "#     correlation_fig.plot(np.mean(allPFC_list,axis=0).T,color=\"C2\")\n",
    "#     correlation_fig.errorbar(np.arange(allPFC_list.shape[1]),np.mean(allPFC_list,axis=0).T,yerr=np.sqrt(np.var(allPFC_list,axis=0).T), color=\"C2\", alpha=0.3)\n",
    "\n",
    "#             allratio_list.append(np.array(ratio_list_max))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########  Coherence and Beta Anova  #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 480\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    Refeature = pca.transform(dfs)\n",
    "\n",
    "    shift = 2\n",
    "    seglen = 60\n",
    "        \n",
    "    coherence_diff_list = []\n",
    "    for i in range(20):\n",
    "        for k in range(1):\n",
    "            data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "            freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "#             print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "            xsp = sx1*np.conjugate(sx3)\n",
    "            coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "#             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "#             xsp = sx2*np.conjugate(sx3)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "#             degree = np.degrees(np.angle(xsp))\n",
    "#             print(degree.shape)\n",
    "#             plt.figure()\n",
    "#             plt.plot(degree)\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            coherence_diff_list.append(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "    \n",
    "    \n",
    "    ######### beta params #############\n",
    "    data = np.array(Gate_states)[:,0,0:20].ravel()\n",
    "    try:\n",
    "        beta_PFC = scipy.stats.beta.fit(data, floc=0)\n",
    "        print(beta_PFC)\n",
    "        beta_param = np.mean([beta_PFC[0],beta_PFC[1]])\n",
    "    except Exception:\n",
    "        print(\"Error: maybe takes negative a or b\")\n",
    "        beta_param = 0.5\n",
    "    \n",
    "    \n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return 0,0,0,0, np.sum(coherence_diff_list)\n",
    "    return 0,0,0,0, beta_param\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    good_points = []\n",
    "    bad_points = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "            path = 'model/R20_H_stopinit_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch???.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            goodmodel_list = []\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])<199:\n",
    "#                     continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,frac = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#                 ratio_list_max.append(HPC_max)\n",
    "                ratio_list_max.append(frac)\n",
    "#                 ratio_list_max.append(PFC_max)\n",
    "#                 correlation_fig.plot(PFC_max,HPC_max,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),frac,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),frac,\"o\",color=\"r\")\n",
    "                if model in good_list:\n",
    "                    goodmodel_list.append(k)\n",
    "#                     good_points.append(frac)\n",
    "                else:\n",
    "#                     bad_points.append(frac)\n",
    "                    pass\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "            \n",
    "            length = len(ratio_list_max)\n",
    "            print(goodmodel_list)\n",
    "            ratio_list_max = np.array(ratio_list_max)\n",
    "#             ratio_list_max = ratio_list_max/np.median(ratio_list_max)\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "            for l in range(length):\n",
    "                if np.any(np.array(goodmodel_list)==l):\n",
    "                    correlation_fig.plot(0,ratio_list_max[l],\"o\",color=\"b\", alpha=0.3)\n",
    "                    good_points.append(ratio_list_max[l])\n",
    "                else:\n",
    "                    correlation_fig.plot(1,ratio_list_max[l],\"o\",color=\"r\", alpha=0.3)\n",
    "                    bad_points.append(ratio_list_max[l])\n",
    "                \n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "#     correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "#     np.save(\"Re_frac.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"UniHPC_HPCmaxvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "    print(scipy.stats.f_oneway(good_points, bad_points))\n",
    "    \n",
    "    print(st.ttest_ind(good_points, bad_points,equal_var=False))\n",
    "    plt.figure()\n",
    "    plt.boxplot([good_points, bad_points],labels=[\"Good\",\"Bad\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w = torch.clone(p.data)\n",
    "                   \n",
    "    return np.array(HPC_w)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    allratio_list = []\n",
    "    w_list = []\n",
    "    w_input = []\n",
    "    w_cell = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "#             path = 'model/R20_H_bigbatch/'\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch1??.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "\n",
    "            for model in model_list:\n",
    "#                 if model in good_list:\n",
    "#                     print(model)\n",
    "#                 else:\n",
    "#                     continue\n",
    "                weight = main(model)\n",
    "                w_list.append(np.array(weight))\n",
    "                w_input.append(np.mean(np.abs(weight)[0:20,2:]))\n",
    "                w_cell.append(np.mean(np.abs(weight)[40:60,2:]))\n",
    "#                 w_input.append(np.mean(np.abs(weight)[0:20,20:]))\n",
    "#                 w_cell.append(np.mean(np.abs(weight)[40:60,20:]))\n",
    "    plt.imshow(np.mean(w_list,axis=0),cmap=\"coolwarm\")\n",
    "#     print(np.mean(np.mean(w_list,axis=0)[0:20,2:]),np.mean(np.mean(w_list,axis=0)[40:60,2:]))\n",
    "    print(np.mean(w_input),np.mean(w_cell))\n",
    "    print(scipy.stats.f_oneway(w_input, w_cell))\n",
    "    print(st.ttest_ind(w_input, w_cell,equal_var=False))\n",
    "    plt.figure()\n",
    "    plt.plot(np.zeros(len(w_input)),w_input,\"o\")\n",
    "    plt.plot(np.ones(len(w_cell)),w_cell,\"o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  Coherence and Beta Anova  #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy as hier\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "\n",
    "#     correlation_matrix_HPC = np.corrcoef(np.array(HPCstate)[:,0])\n",
    "    correlation_matrix_PFC = np.corrcoef(np.array(PFCstate)[:,0])\n",
    "    \n",
    "    dend = hier.linkage(np.array(PFCstate)[:,0])\n",
    "    clusters = hier.fcluster(dend,0.6,criterion=\"distance\")\n",
    "    print(np.max(clusters))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.figure()\n",
    "#     hier.dendrogram(dend)\n",
    "#     plt.imshow(correlation_matrix_PFC,vmax=1,vmin=-1)\n",
    "    \n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "    all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "\n",
    "\n",
    "#     pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[0:,0]\n",
    "# #     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "    \n",
    "#     delaysB = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "#     PCAnum = 0\n",
    "#     data = feature[:,PCAnum]\n",
    "#     movingA = moving_average(data)\n",
    "#     fracA = data - movingA[2:-2]\n",
    "#     print(math.dist(data,movingA[2:-2]))\n",
    "#     frac_amp = math.dist(data,movingA[2:-2])\n",
    "    \n",
    "\n",
    "    \n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return 0,0,0,0, np.sum(coherence_diff_list)\n",
    "#     return np.mean(abs(all_uw)), np.var(correlation_matrix_HPC)\n",
    "#     return np.mean(abs(all_uw)), np.var(correlation_matrix_PFC)\n",
    "    return np.mean(abs(all_uw)), np.max(clusters)\n",
    "#     return np.mean(abs(all_uw)), frac_amp\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    good_points = []\n",
    "    bad_points = []\n",
    "    for num in range(3):\n",
    "        for i in range(1):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+9)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            eigen_list = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            goodmodel_list = []\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])<199:\n",
    "#                     continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                eigen_mean,corr_var = main(model)\n",
    "\n",
    "                ratio_list_max.append(corr_var)\n",
    "                eigen_list.append(eigen_mean)\n",
    "#                 correlation_fig.plot(eigen_mean,corr_var,\"o\")\n",
    "\n",
    "                k+=1\n",
    "\n",
    "            ratio_list_max = np.array(ratio_list_max)\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "            correlation_fig.plot(eigen_list,ratio_list_max,\"o\")\n",
    "            print(scipy.stats.pearsonr(eigen_list,ratio_list_max))\n",
    "#     correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "#     np.save(\"Re_frac.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"UniHPC_HPCmaxvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  Coherence and Beta Anova  #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.0001):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 480\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    Refeature = pca.transform(dfs)\n",
    "\n",
    "    shift = 2\n",
    "    seglen = 60\n",
    "        \n",
    "    coherence_diff_list = []\n",
    "    for i in range(20):\n",
    "        for k in range(1):\n",
    "            data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "            freqs,times,sx1 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "            freqs,times,sx3 = signal.stft(data,fs=1,window=\"tukey\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "#             print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "            xsp = sx1*np.conjugate(sx3)\n",
    "            coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "#             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "#             xsp = sx2*np.conjugate(sx3)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "#             plt.figure()\n",
    "#             plt.pcolormesh(times,freqs,coherence)\n",
    "#             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "#             degree = np.degrees(np.angle(xsp))\n",
    "#             print(degree.shape)\n",
    "#             plt.figure()\n",
    "#             plt.plot(degree)\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            coherence_diff_list.append(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "    \n",
    "    \n",
    "#     ######### beta params #############\n",
    "#     data = np.array(Gate_states)[:,0,0:20].ravel()\n",
    "#     try:\n",
    "#         beta_PFC = scipy.stats.beta.fit(data, floc=0)\n",
    "#         print(beta_PFC)\n",
    "#         beta_param = np.mean([beta_PFC[0],beta_PFC[1]])\n",
    "#     except Exception:\n",
    "#         print(\"Error: maybe takes negative a or b\")\n",
    "#         beta_param = 0.5\n",
    "    \n",
    "    all_uw,all_uv = LA.eig(Re_inw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "    \n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "    return 0,0,0,0, np.sum(coherence_diff_list), np.mean(abs(all_uw))\n",
    "#     return 0,0,0,0, beta_param\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    good_points = []\n",
    "    bad_points = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            eigen_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            goodmodel_list = []\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])<199:\n",
    "#                     continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,frac,eigen = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#                 ratio_list_max.append(HPC_max)\n",
    "                ratio_list_max.append(frac)\n",
    "#                 ratio_list_max.append(PFC_max)\n",
    "                eigen_list.append(eigen)\n",
    "#                 correlation_fig.plot(PFC_max,HPC_max,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),frac,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(int(model.split(\"epoch\")[-1].split(\".\")[0]),frac,\"o\",color=\"r\")\n",
    "                if model in good_list:\n",
    "                    goodmodel_list.append(k)\n",
    "#                     good_points.append(frac)\n",
    "                else:\n",
    "#                     bad_points.append(frac)\n",
    "                    pass\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "            \n",
    "            length = len(ratio_list_max)\n",
    "            print(goodmodel_list)\n",
    "            ratio_list_max = np.array(ratio_list_max)\n",
    "#             ratio_list_max = ratio_list_max/np.median(ratio_list_max)\n",
    "#             correlation_fig.plot(eigen_list,np.array(ratio_list_max),\"o\",color=\"C{}\".format(i))\n",
    "            for l in range(length):\n",
    "                if np.any(np.array(goodmodel_list)==l):\n",
    "                    correlation_fig.plot(eigen_list[l],ratio_list_max[l],\"o\",color=\"b\", alpha=0.3)\n",
    "                    good_points.append(ratio_list_max[l])\n",
    "                else:\n",
    "                    correlation_fig.plot(eigen_list[l],ratio_list_max[l],\"o\",color=\"r\", alpha=0.3)\n",
    "                    bad_points.append(ratio_list_max[l])\n",
    "                \n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "#     correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "#     np.save(\"Re_frac.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"UniHPC_HPCmaxvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "    print(scipy.stats.f_oneway(good_points, bad_points))\n",
    "    \n",
    "    print(st.ttest_ind(good_points, bad_points,equal_var=False))\n",
    "    plt.figure()\n",
    "    plt.boxplot([good_points, bad_points],labels=[\"Good\",\"Bad\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert PCA or low-pass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########   Insert PCA or low-pass data  #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniHPC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "                target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "#                 target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyLSTM_feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_feedforward, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "\n",
    "class MyLSTM_feedforward_Thalamus2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_feedforward_Thalamus2, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.hidden_size_THinh = hidden_size\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_PFC+self.hidden_size_HPC+self.hidden_size_THinh, self.hidden_size_Re)\n",
    "        self.THinh = nn.Linear(self.hidden_size_Re, self.hidden_size_THinh)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.ReLU = nn.ReLU()\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0],hiddens[3]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        THinh_input = hiddens[2]\n",
    "        THinh_hidden = self.ReLU(self.THinh(THinh_input))\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden,THinh_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh))\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        THinh_hidden = self.ReLU(torch.rand(self.batch_size, self.hidden_size_THinh)*const)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden,THinh_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re,self.hidden_size_THinh]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    \n",
    "    \n",
    "def correct_traj(traj):\n",
    "    Rightflag = False\n",
    "    Leftflag = False\n",
    "    Pointflag = False\n",
    "    extreme = 0.5\n",
    "    extreme_point = 0\n",
    "    point_list = []\n",
    "    for i in range(traj.shape[0]):\n",
    "        if np.abs(traj[i,0]-0.5) > 0.1:\n",
    "            if traj[i,1] < 0.4:\n",
    "                Pointflag = True\n",
    "                if extreme > traj[i,1]:\n",
    "                    extreme = traj[i,1]\n",
    "                    point = i\n",
    "            if traj[i,1] > 0.4 and traj[i,1] < 0.5 and Pointflag == True:\n",
    "                Pointflag = False\n",
    "                extreme = 0.5\n",
    "                point_list.append(point)\n",
    "\n",
    "            if traj[i,1] > 0.6:\n",
    "                Pointflag = True\n",
    "                if extreme < traj[i,1]:\n",
    "                    extreme = traj[i,1]\n",
    "                    point = i\n",
    "            if traj[i,1] < 0.6 and traj[i,1] > 0.5 and Pointflag == True:\n",
    "                Pointflag = False\n",
    "                extreme = 0.5\n",
    "                point_list.append(point)\n",
    "\n",
    "    return point_list\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(9)/9\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "def moving_average_test(data):\n",
    "    y = np.ones(9)/9\n",
    "    mean_seq = np.convolve(data, y, mode=\"same\")\n",
    "    return mean_seq   \n",
    "\n",
    "def moving_average_grad(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y, mode=\"same\")\n",
    "    result = (np.clip(mean_seq[-3] + (mean_seq[-3]-mean_seq[-4]) + (mean_seq[-2]-mean_seq[-3]*5/4),-1,1) + mean_seq[-1]*5/3)/2\n",
    "#     result = (np.clip(mean_seq[-3] + (mean_seq[-3]-mean_seq[-4])*2,-1,1) + mean_seq[-1]*5/3)/2\n",
    "#     print(np.clip(mean_seq[-3] + (mean_seq[-3]-mean_seq[-4]) + (mean_seq[-2]-mean_seq[-3]*5/4),-1,1), mean_seq[-1]*5/3)\n",
    "    return np.append(mean_seq,result)    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward_Thalamus2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 160\n",
    "    est_length = 1\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "########### For PCA or high-pass insert!!! #################\n",
    "\n",
    "    PCA_size = 4\n",
    "    pca = PCA(n_components=PCA_size)\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(PCA_size)]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(PCA_size)]))\n",
    "    \n",
    "    recovered = pca.inverse_transform(feature[:])\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Restate_noise2 = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "    data_limit = 50\n",
    "    rest = 42\n",
    "    for k in range(data_limit):\n",
    "#             for cell in range(20):\n",
    "#                     print(hidden[2][0][cell+0],np.array(Restate)[int(delays[Delaynum])+Delaytime,cell+0]-moving_average(np.array(Restate)[:,cell+0])[4+int(delays[Delaynum])+Delaytime])\n",
    "#                     hidden[2][0][cell+8] = np.average(np.array(Restate_noise)[-6:,cell+8])\n",
    "#                     hidden[2][0][cell+8] = np.average(np.array(Restate)[k-5+data_limit:k+5+data_limit,cell+8])\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[4+k]\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[4+int(delays[Delaynum])+Delaytime]\n",
    "#                     hidden[2][0][cell+0] = np.array(Restate)[startpoint+Delaytime,cell+0]-moving_average(np.array(Restate)[:,cell+0])[4+startpoint+Delaytime]\n",
    "#                 hidden[2][0][cell+0] = np.array(Restate)[k,cell+0] - moving_average(np.array(Restate)[:,cell+0])[4+k]\n",
    "            if k > 60:\n",
    "                for cell in range(20):\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate_noise)[:,cell+0])[-3]*5/3\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate_noise)[:,cell+0])[-5]\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[k+4]\n",
    "#                     hidden[2][0][cell+0] = moving_average_test(np.array(Restate_noise)[:,cell+0])[-1]*9/5\n",
    "#                     hidden[2][0][cell+0] = moving_average_grad(np.array(Restate_noise)[:,cell+0])[-1]*1\n",
    "#                     hidden[2][0][cell+0] = np.array(Restate_noise)[-1,cell+0] - 0.3*moving_average(np.array(Restate_noise)[:,cell+0])[-5]\n",
    "                    hidden[2][0][cell+0] = np.array(Restate_noise)[-1,cell+0] - 0.25*moving_average_grad(np.array(Restate_noise)[:,cell+0])[-1]\n",
    "#                     hidden[2][0][cell+0] = np.array(Restate)[k,cell+0] - 1.0*moving_average(np.array(Restate)[:,cell+0])[k+4]*1\n",
    "#                     hidden[2][0][cell+0] = np.array(recovered)[k,cell+0]\n",
    "#                     hidden[0][0][0][cell+0] = np.array(recovered)[k,cell+0]\n",
    "#                     pass\n",
    "            #print(data[k].shape)\n",
    "            Restate_noise2.append(hidden[2][0].tolist())\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length+rest):\n",
    "            for cell in range(20):\n",
    "#                 hidden[2][0][cell+0] = moving_average(np.array(Restate_noise)[:,cell+0])[-3]*5/3\n",
    "#                 hidden[2][0][cell+0] = moving_average(np.array(Restate_noise)[:,cell+0])[-5]\n",
    "#                 hidden[2][0][cell+0] = moving_average_test(np.array(Restate_noise)[:,cell+0])[-1]*9/5\n",
    "#                 hidden[2][0][cell+0] = moving_average_grad(np.array(Restate_noise)[:,cell+0])[-1]*1\n",
    "#                 hidden[2][0][cell+0] = np.array(Restate_noise)[-1,cell+0] - 0.3*moving_average(np.array(Restate_noise)[:,cell+0])[-5]*1\n",
    "                hidden[2][0][cell+0] = np.array(Restate_noise)[-1,cell+0] - 0.25*moving_average_grad(np.array(Restate_noise)[:,cell+0])[-1]\n",
    "#                 hidden[0][0][0][cell+0] = np.array(recovered)[k+data_limit,cell+0]\n",
    "#                 pass\n",
    "                \n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            Restate_noise2.append(hidden[2][0].tolist())\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "#     traj_dif_b = distance_bet2traj(traj[:,0],traj_noise[:,0])\n",
    "# #     print(traj_dif_b)\n",
    "#     traj_dif = np.sum(traj_dif_b)\n",
    "    \n",
    "    data = traj\n",
    "    ex_points = correct_traj(data[:,0])\n",
    "#     print(ex_points)\n",
    "\n",
    "    data = traj_noise\n",
    "    ex_points_noise = correct_traj(data[:,0])\n",
    "#     print(ex_points)\n",
    "    \n",
    "#     print(traj[ex_points[-1]]-traj_noise[ex_points_noise[-1]])\n",
    "    var_ex = np.linalg.norm(traj[ex_points[-1]][0]-traj_noise[ex_points_noise[-1]][0])\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0],\"--\",color=\"C2\",alpha=0.6)\n",
    "    plt.plot(traj[:,0,1],\"--\",color=\"C3\",alpha=0.6)\n",
    "    plt.plot(traj_noise[:,0,0],color=\"C2\",alpha=0.9)\n",
    "    plt.plot(traj_noise[:,0,1],color=\"C3\",alpha=0.9)\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "\n",
    "    PFC_corrlist = np.array([])\n",
    "    HPC_corrlist = np.array([])\n",
    "    cross_corrlist = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0])\n",
    "        plt.plot(traj_noise[:,0,0])\n",
    "#         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "    #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "            plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "            plt.plot(np.array(Restate_noise2)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[:,i])[2:-2],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "#                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "#                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "#                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "# #     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "#     print(dfs.shape)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "#     print(\"PFC correlation\")\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "# #     PFC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "# #     PFC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "# #     PFC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "# #     PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]))[0,1]\n",
    "# #     PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]))[0,1]\n",
    "# #     PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]))[0,1]\n",
    "#     PFC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:,2],2))\n",
    "#     PFC_d = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),PFC_diff)[0,1]\n",
    "#     PFC_diff2 = np.sum(np.abs(np.array(PFCstate)[:,0]-np.array(PFCstate_noise)[:,0]),axis=1)\n",
    "#     PFC_e = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),PFC_diff2)[0,1]\n",
    "    \n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# #     plt.show()\n",
    "\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "# #     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "# #     plt.show()\n",
    "\n",
    "# #     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(PFCstate)[:,0]\n",
    "# #     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "#     print(dfs.shape)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "#     print(\"HPC correlation\")\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "#     HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "#     HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "# #     HPC_a = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "# #     HPC_b = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "# #     HPC_c = np.corrcoef(np.abs(traj[:,0,1]-traj_noise[:,0,1]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "#     HPC_diff = np.sqrt(np.power(feature[:data_limit,0]-feature[data_limit:,0],2) + np.power(feature[:data_limit,1]-feature[data_limit:,1],2) + np.power(feature[:data_limit,2]-feature[data_limit:,2],2))\n",
    "#     HPC_d = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff)[0,1]\n",
    "#     HPC_diff2 = np.sum(np.abs(np.array(HPCstate)[:,0]-np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "#     HPC_e = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),HPC_diff2)[0,1]\n",
    "#     print(HPC_e)\n",
    "    \n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,3]-feature[100:,3]))\n",
    "# #     plt.plot(np.abs(feature[:100,4]-feature[100:,4]))\n",
    "# #     plt.plot(np.abs(feature[:100,5]-feature[100:,5]))\n",
    "# #     plt.show()\n",
    "    \n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "# #     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "# #     plt.show()\n",
    "\n",
    "# #     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "# #     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "\n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(PFCstate)[:,0]\n",
    "# #     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "#     print(dfs.shape)\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)\n",
    "#     print(\"Re correlation\")\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "# #     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "# #     Re_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]\n",
    "# #     Re_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]\n",
    "# #     Re_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]\n",
    "    \n",
    "# #     plt.figure()\n",
    "# # #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# # #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# # #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# # #     plt.plot(np.abs(moving_average(feature[:100,0])-moving_average(feature[100:,0])))\n",
    "# # #     plt.plot(np.abs(moving_average(feature[:100,1])-moving_average(feature[100:,1])))\n",
    "# # #     plt.plot(np.abs(moving_average(feature[:100,2])-moving_average(feature[100:,2])))\n",
    "# #     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "# #     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "# #     plt.show()\n",
    "\n",
    "\n",
    "####################### Fluc(frac) and coherence part #############################\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(HPCstate)[40:,0]\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    delaysB = pick_delay(traj[:,0], feature[:])\n",
    "\n",
    "#     PCAnum = 0\n",
    "#     data = feature[:,PCAnum]\n",
    "#     movingA = moving_average(data)\n",
    "#     fracA = data - movingA[2:-2]\n",
    "#     print(math.dist(data,movingA[2:-2]))\n",
    "#     frac_amp = math.dist(data,movingA[2:-2])\n",
    "    \n",
    "#     frac_amp = 0\n",
    "#     for i in range(20):\n",
    "#         data = np.array(HPCstate)[:,0,i]\n",
    "#         movingA = moving_average(data)\n",
    "#         fracA = data - movingA[2:-2]\n",
    "#         frac_amp += math.dist(data,movingA[2:-2])\n",
    "#     frac_amp = frac_amp/20\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     fig1 = fig.add_subplot(111)\n",
    "#     fig1.hist(np.array(Gate_states)[:,0,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     fig1.hist(np.array(Gate_states)[:,1,0:20].ravel(),bins=30,range=(-0.1,1.1),alpha=0.5,density=True)\n",
    "#     plt.show()\n",
    "\n",
    "#     hist = np.histogram(np.array(Gate_states)[:,0,0:20].ravel(),bins=30,range=(-0.1,1.1),density=True)\n",
    "#     data = np.array([np.clip(hist[1][3:-2],0,1),hist[0][2:-2]]).T\n",
    "    data = np.array(Gate_states)[:,0,0:20].ravel()\n",
    "    try:\n",
    "        beta_PFC = scipy.stats.beta.fit(data, floc=0)\n",
    "        print(beta_PFC)\n",
    "        beta_param = np.average([beta_PFC[0],beta_PFC[1]])\n",
    "    except Exception:\n",
    "        print(\"Error: maybe takes negative a or b\")\n",
    "        beta_param = 0.5\n",
    "        \n",
    "#     data = np.array(Gate_states)[:,1,0:20].ravel()\n",
    "#     try:\n",
    "#         beta_HPC = scipy.stats.beta.fit(data)\n",
    "#         print(beta_HPC)\n",
    "#     except Exception:\n",
    "#         print(\"Error: maybe takes negative a or b\")\n",
    "        \n",
    "\n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(HPCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "#     pca.fit(dfs)\n",
    "#     Refeature = pca.transform(dfs)\n",
    "\n",
    "#     shift = 2\n",
    "#     seglen = 60\n",
    "        \n",
    "#     coherence_diff_list = []\n",
    "#     for i in range(20):\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Refeature)[:,0]-moving_average(np.array(Refeature)[:,0])[2:-2]\n",
    "#             freqs,times,sx1 = signal.stft(data,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(PFCstate)[:,k,i]-moving_average(np.array(PFCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx2 = signal.stft(data*1,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "#             data = np.array(HPCstate)[:,k,i]-moving_average(np.array(HPCstate)[2:-2,k,i])[:]\n",
    "#             freqs,times,sx3 = signal.stft(data,fs=1,window=\"boxcar\",nperseg=seglen,noverlap=seglen-shift,detrend=False,boundary=None)\n",
    "            \n",
    "#             xsp = sx1*np.conjugate(sx2)\n",
    "#             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx2))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-PFC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "            \n",
    "# #             plt.figure()\n",
    "# #             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "            \n",
    "# #             xsp = sx1*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx1)*np.abs(sx3))            \n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"Re-HPC neuron#\"+str(i+1))\n",
    "# #             print(np.max(coherence),np.min(coherence))\n",
    "\n",
    "            \n",
    "# #             xsp = sx2*np.conjugate(sx3)\n",
    "# #             coherence = (np.abs(xsp)**2)/(np.abs(sx2)*np.abs(sx3))\n",
    "# #             plt.figure()\n",
    "# #             plt.pcolormesh(times,freqs,coherence)\n",
    "# #             plt.title(\"PFC-HPC neuron#\"+str(i+1))\n",
    "            \n",
    "# #             degree = np.degrees(np.angle(xsp))\n",
    "# #             print(degree.shape)\n",
    "# #             plt.figure()\n",
    "# #             plt.plot(degree)\n",
    "\n",
    "# #             plt.figure()\n",
    "# #             plt.plot(times, np.sum(coherence.T,axis=1))\n",
    "#             coherence_diff_list.append(np.max(np.sum(coherence.T,axis=1))-np.min(np.sum(coherence.T,axis=1)))\n",
    "    \n",
    "    \n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c]),frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, np.sum(coherence_diff_list)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "    return 0,0,0,0,traj_dif\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allratio_list = []\n",
    "    good_points = [[],[]]\n",
    "    bad_points = [[],[]]\n",
    "    for num in range(1):\n",
    "        for i in range(1):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "#             path = 'model/R20_H_stopinit_bigbatch/'\n",
    "#             path = 'model/R20FF_H_bigbatch/'\n",
    "#             path = 'model/R20_feedReinhReLU_H_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+6)+'_100_'+str(num+4)+'_*epoch200.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            ratio_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])>194:\n",
    "#                     continue\n",
    "#                 if int(model.split(\"epoch\")[-1].split(\".\")[0])<19:\n",
    "#                     continue\n",
    "    #             PFC,HPC = main(model)\n",
    "#                 PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "                PFC,HPC,PFC_max,HPC_max,frac = main(model)\n",
    "    #             ratio_list.append(PFC/HPC)\n",
    "                ratio_list.append(np.abs(PFC-HPC))\n",
    "    #             ratio_list_max.append(PFC_max/HPC_max)\n",
    "#                 ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#                 ratio_list_max.append(HPC_max)\n",
    "                ratio_list_max.append(frac)\n",
    "#                 ratio_list_max.append(PFC_max)\n",
    "#                 correlation_fig.plot(PFC_max,HPC_max,\"o\")\n",
    "#                 if model in good_list:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"b\")\n",
    "#                 else:\n",
    "#                     correlation_fig.plot(PFC_max,HPC_max,\"o\",color=\"r\")\n",
    "    #             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "    #             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "        #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "                print(PFC_max,HPC_max)\n",
    "                print(\"dist:\"+str(frac))\n",
    "#                 if good_flag != True and model in good_list:\n",
    "#                     good_flag = True\n",
    "#                     first_goodmodel[0] = int(model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#     #                 first_goodmodel[1] = ratio_list[-1]\n",
    "#                     first_goodmodel[1] = ratio_list_max[-1]\n",
    "                if model in good_list:\n",
    "                    good_points[0].append(ratio_list_max[-1]) \n",
    "                    good_points[1].append(int(model.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "                else:\n",
    "                    bad_points[0].append(ratio_list_max[-1]) \n",
    "                    bad_points[1].append(int(model.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "                k+=1\n",
    "    #         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "    #         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "    #         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "    #         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "\n",
    "#             ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "#             ratio_list_max = moving_average(ratio_list_max)[4:-2]\n",
    "#             correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max),color=\"C{}\".format(i))\n",
    "#             if good_flag == True:\n",
    "#                 correlation_fig.plot(first_goodmodel[0],first_goodmodel[1],\"o\",color=\"C{}\".format(i))\n",
    "            allratio_list.append(np.array(ratio_list_max))\n",
    "    correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),color=\"b\")\n",
    "    correlation_fig.errorbar(np.arange(0,len(ratio_list_max)*5,5),np.average(np.array(allratio_list), axis=0),yerr=np.sqrt(np.var(np.array(allratio_list), axis=0)), color=\"b\", alpha=0.3)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "#     np.save(\"ReFFInhReLU_HPCave.npy\",np.mean(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"ReFFInhReLU_HPCvar.npy\",np.var(np.array(allratio_list),axis=0))\n",
    "#     np.save(\"uniHPC_PFCmax_good.npy\",np.array(good_points))\n",
    "#     np.save(\"uniHPC_PFCmax_bad.npy\",np.array(bad_points))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
