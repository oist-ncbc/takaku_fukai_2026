{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import os\n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.01):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+10\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "#         nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "#         nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "#         nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "#         nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.5\n",
    "        var = 0.5\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*const, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0\n",
    "        var = 1\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "\n",
    "class MyLSTM_feedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_feedforward, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+10\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.Linear(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input)\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "\n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main(num):\n",
    "    training_size = 200\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/ReModeltest_30reset3addlong_estref_L2_interRNNrand_Reinh_AddRe_OUT5_131_s'+str(num)+'_100_4.pth'\n",
    "    model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s'+str(num)+'_100_1_2_3.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s3_100_3.pth'\n",
    "#     model_path = 'model/ReModeltest_30reset3addlong_L2_interRNNrand_Reinh_AddRe_OUT5_131_s10_100_1.pth'\n",
    "#     model_path = 'model/ReModeltest_30addlong_interRNNrand_Reinh_AddRe_OUT5_131_s3_100_2.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_long_s7_200_2_1_'+str(num)+'.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_171_s'+str(num)+'_100_1.pth'\n",
    "#     model_path = 'model/ReModel_LSTMrand_noise_long131test_s'+str(num)+'_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s'+str(num)+'_100_4.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_11311_s6_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_Reinh_AddRe_OUT5_H121_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/FeedModel_L2_interRNNrand_AddRe_OUT5_161_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_131_s10_100_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_diffHPC5_long131test_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_HPC5_OUT5_161_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/R+/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s'+str(num)+'_100_2.pth'\n",
    "#     model_path = 'model/R+/ReModel_L2_interRNNrand_AddRe_OUT5_151_s3_100_1_epoch50.pth'\n",
    "#     model_path = 'model/R+/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s3_100_2.pth'\n",
    "#     model_path = 'model/R+2/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s1_100_2_epoch'+str(num*5+125)+'.pth'\n",
    "#     model_path = 'model/R+2/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s1_100_2_epoch170.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s10_100_3_epoch'+str(num*5+150)+'.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s10_100_6_epoch'+str(num*5+100)+'.pth'\n",
    "\n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch105.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s1_100_2_epoch'+str(num*5+150)+'.pth'\n",
    "#     model_path = 'model/H+/ReModel_L2_interRNNrand_AddHPC100_OUT5_151_s7_100_1_epoch'+str(num*5+75)+'.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_Yl_s5_200_4_2000.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s2_100_1.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s1_100_2_TrainOUT_epoch9.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s6_100_1_TrainOUT_epoch'+str(num)+'.pth'\n",
    "#     model_path = 'model/R20_uniPFC/ReModel_L2_interRNNrand_OUT1_uniPFC_151_s1_100_2_epoch'+str(num*5+150)+'.pth'\n",
    "#     model_path = 'model/R20_uniPFC/ReModel_L2_interRNNrand_OUT1_uniPFC_151_s1_100_2_epoch'+str(num*5+150)+'.pth'\n",
    "#     model_path = 'model/R20_feed/FeedModel_L2_interRNNrand_OUT1_151_s6_100_1_epoch'+str(num*5+150)+'.pth'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "    \n",
    "#     train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,5)\n",
    "    \n",
    "\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[:,inputsize:].sub_(p.data[:,inputsize:])\n",
    "\n",
    "    \n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 1\n",
    "    for k in range(data_limit):\n",
    "#             print(data[k].shape)\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(torch.rand(10,2),hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2):\n",
    "#             output += torch.randn(10,2)*0.01\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:100,0,0],traj[:100,0,1])\n",
    "    plt.plot(traj[100:,0,0],traj[100:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], 1)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_w = np.array(p.data)\n",
    "\n",
    "    fig2 = plt.figure(figsize=(10,5))\n",
    "    ax1 = fig2.add_subplot(141)\n",
    "    ax2 = fig2.add_subplot(142)\n",
    "    axre = fig2.add_subplot(143)\n",
    "    axout = fig2.add_subplot(144)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    axout.imshow(Output_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "    axout.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Output_w),np.min(Output_w)))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_w = np.array(p.data)\n",
    "                \n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(131)\n",
    "    ax2 = fig2.add_subplot(132)\n",
    "    axre = fig2.add_subplot(133)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\",vmax=1,vmin=-1)\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))      \n",
    "    \n",
    "    \n",
    "    fig3 = plt.figure()\n",
    "    ax3 = fig3.add_subplot(131)\n",
    "    ax4 = fig3.add_subplot(132)\n",
    "    axre2 = fig3.add_subplot(133)\n",
    "    # ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0].T,np.array(HPCstate)[:,0].T))\n",
    "    # ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0].T,np.array(Restate).T))\n",
    "    # axre2.imshow(np.corrcoef(np.array(PFCstate)[:,0].T,np.array(Restate).T))\n",
    "    ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0]),vmin=-1,vmax=1,cmap=plt.get_cmap(\"seismic\"))\n",
    "    ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0]),vmin=-1,vmax=1,cmap=plt.get_cmap(\"seismic\"))\n",
    "    axre2.imshow(np.corrcoef(np.array(Restate)[:]),vmin=-1,vmax=1,cmap=plt.get_cmap(\"seismic\"))\n",
    "    ax3.set_title(\"PFC\")   \n",
    "    ax4.set_title(\"HPC\")  \n",
    "    axre2.set_title(\"Re\")  \n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    HPC_feature = np.copy(feature)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    PFC_feature = np.copy(feature)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "#     dfs = np.array(Restate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    Re_feature = np.copy(feature)\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "#     print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     linelist = search_delay(traj[:,0])\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "#     plt.vlines(linelist,0,1)\n",
    "\n",
    "#     fig2d = plt.figure()\n",
    "#     plt.plot(feature[:200, 0], feature[:200, 1], alpha=0.8)\n",
    "#     plt.plot(feature[0:1, 0], feature[0:1, 1], \"o\", alpha=1)\n",
    "#     plt.show()\n",
    "\n",
    "    cellsize = 20\n",
    "    lyap_exp_list = []\n",
    "#     for i in range(cellsize):\n",
    "#         lyap_exp = nolds.lyap_r(np.array(Restate)[:,i],min_tsep = 30, lag=10)\n",
    "# #         lyap_exp2 = nolds.lyap_e(np.array(Restate)[:,i])\n",
    "# #         lyap_exp = nolds.lyap_r(np.array(PFCstate)[:,0,i],min_tsep = 15, lag=1)\n",
    "# #         lyap_exp = nolds.lyap_r(np.array(PFCstate)[:,0,i],min_tsep = 150, lag=55)\n",
    "#         print(lyap_exp)\n",
    "#         lyap_exp_list.append(lyap_exp)\n",
    "    \n",
    "#     return lyap_exp_list\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,:,0])\n",
    "    # plt.plot(traj[:,:,1])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    features = []\n",
    "    for i in range(10):\n",
    "        features.append(main(i+1))\n",
    "\n",
    "#     fig2d = plt.figure()\n",
    "#     for feature in features:\n",
    "#         plt.plot(feature[:200, 0], feature[:200, 1], alpha=0.2)\n",
    "#         plt.plot(feature[0:1, 0], feature[0:1, 1], \"o\", alpha=1)\n",
    "#     plt.show()\n",
    "\n",
    "#     fig2d = plt.figure()\n",
    "#     for i,feature in enumerate(features):\n",
    "#         plt.plot(np.ones(len(feature))*(i+1), feature, \"o\", alpha=1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.01):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.RNNCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 10\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0\n",
    "        var = 1\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size)*const, torch.ones(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        Re_hidden = torch.ones(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def hidden_randinsert(self,hidden):\n",
    "        var = 1\n",
    "        insert = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "#         insert = torch.rand(self.batch_size, self.hidden_size)*var\n",
    "        return [hidden[0],insert,hidden[2]]\n",
    "    \n",
    "class MyLSTM_3lay(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_3lay, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input,hiddens[2])\n",
    "        PFC_input = hiddens[2][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        vHPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s'+str(num)+'_100_3.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s1_100_3_plus_'+str(num)+'.pth'\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_1.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path)\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "        return\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 20\n",
    "    for k in range(data_limit):\n",
    "#             print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(torch.rand(10,2),hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    hidden = rnn.hidden_randinsert(hidden)\n",
    "    for k in range(data.shape[0]*4):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:100,0,0],traj[:100,0,1])\n",
    "    plt.plot(traj[100:,0,0],traj[100:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "#     for n, p in rnn.named_parameters():\n",
    "#             if n == \"PFC.weight_ih\":\n",
    "#                 PFC_w = np.array(p.data)\n",
    "#             if n == \"HPC.weight_ih\":\n",
    "#                 HPC_w = np.array(p.data)\n",
    "#             if n == \"Re.weight_ih\":\n",
    "#                 Re_w = np.array(p.data)\n",
    "\n",
    "#     fig2 = plt.figure()\n",
    "#     ax1 = fig2.add_subplot(131)\n",
    "#     ax2 = fig2.add_subplot(132)\n",
    "#     axre = fig2.add_subplot(133)\n",
    "    \n",
    "#     ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "#     ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "#     axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "#     ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "#     ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "#     axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_w = np.array(p.data)\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(131)\n",
    "    ax2 = fig2.add_subplot(132)\n",
    "    axre = fig2.add_subplot(133)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w),np.min(Re_w)))                \n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for i in range(10):\n",
    "        main(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(num):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 200\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "#     model_path = 'model/ReModel_mixRNN_long_s'+str(num)+'_200_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNN_Yl_s5_200_5_2000.pth'\n",
    "    filename = \"primal_Y_long\"\n",
    "    print(model_path)\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 200\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*1):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "    filename = \"primal_long\"\n",
    "    print(model_path)\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    hidden = rnn.initHidden()\n",
    "            \n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*1):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    print(feature[200:])\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:200, 0], feature[:200, 1], feature[:200, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    ax3d.plot(feature[200:, 0], feature[200:, 1], feature[200:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "#     ax3d.plot(moving_average(feature[:, 0]), moving_average(feature[:, 1]), moving_average(feature[:, 2]), alpha=0.8)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(Restate)[:,i])\n",
    "#         plt.show()\n",
    "    \n",
    "#     moving_feature = np.concatenate(([moving_average(feature[:, 0])], [moving_average(feature[:, 1])], [moving_average(feature[:, 2])]),axis=0).T\n",
    "#     print(moving_feature.shape)\n",
    "#     plot_distance(feature,moving_feature)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(overlap_coefficient(moving_feature,feature))\n",
    "#     plt.plot(moving_average(overlap_coefficient(moving_feature,feature)))\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for i in range(1):\n",
    "        main(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distance(list_a,list_b):\n",
    "    result = []\n",
    "    for point in list_b:\n",
    "        dis_list = []\n",
    "        for target in list_a:\n",
    "            dis_list.append(np.linalg.norm(point[:3] - target[:3]))\n",
    "        result.append(np.min(dis_list))\n",
    "    return np.array(result)\n",
    "\n",
    "def overlap_coefficient(list_a,list_b):\n",
    "    threshold = 0.025\n",
    "    #Aの各点からBにある任意の点の最小距離を計算\n",
    "    distance = check_distance(list_a,list_b)\n",
    "    \n",
    "    #集合Aの要素数を取得\n",
    "    num_listA = len(list_a)\n",
    "    return distance\n",
    "\n",
    "def plot_distance(data1,data2):\n",
    "    r = data1\n",
    "    l = data2\n",
    "    \n",
    "    overlap=overlap_coefficient(r,l)\n",
    "\n",
    "    plt.figure()\n",
    "#     plt.ylim(0,1)\n",
    "    plt.plot(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s9_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "        # if n == \"PFC.weight_ih\":\n",
    "        #     p.data[hidden_size:,hidden_size:].sub_(p.data[hidden_size:,hidden_size:])\n",
    "        if n == \"HPC.weight_ih\":\n",
    "            p.data[:,inputsize:].sub_(p.data[:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 100\n",
    "    ynum = 100\n",
    "    initx = 0.2\n",
    "    endx = 0.8\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    place = np.zeros((hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    data_limit = 20\n",
    "    for y in range(ynum+1):\n",
    "        for x in range(xnum+1):\n",
    "            hidden = rnn.initHidden()\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            for k in range(data_limit):\n",
    "                    #print(data[k].shape)\n",
    "                    output,hidden = rnn(point,hidden)\n",
    "            for n in range(hidden_size):\n",
    "                place[n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "                grid[n].append([initx+widex*x,widey*y,hidden[1][0].tolist()[0][n]])\n",
    "                \n",
    "    grid = np.array(grid)\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[i],cmap='jet',origin='lower',interpolation='bilinear', vmin=0)\n",
    "        plt.show()\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(grid[i,:,0],grid[i,:,1],grid[i,:,2])\n",
    "#         plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        x = np.arange(initx, endx+widex, widex)\n",
    "        y = np.arange(inity, endy+widey, widey)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = place[i]\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(x, y, z, cmap='jet')\n",
    "        plt.show()\n",
    "    \n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#init ari\n",
    "\n",
    "\n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        ims.append([img])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         # if n == \"PFC.weight_ih\":\n",
    "#         #     p.data[hidden_size:,hidden_size:].sub_(p.data[hidden_size:,hidden_size:])\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[hidden_size:,inputsize:].sub_(p.data[hidden_size:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 20\n",
    "    ynum = 20\n",
    "    initx = 0\n",
    "    endx = 1\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    data_limit = 100\n",
    "    place = np.zeros((data_limit,hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    \n",
    "    x_list = np.array(range(xnum+1))\n",
    "    y_list = np.array(range(ynum+1))\n",
    "    np.random.shuffle(y_list)\n",
    "    for y in y_list:\n",
    "        np.random.shuffle(x_list)\n",
    "        for x in x_list:\n",
    "            hidden = rnn.initHidden()\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            for k in range(data_limit):\n",
    "                    #print(data[k].shape)\n",
    "                    output,hidden = rnn(point,hidden)\n",
    "                    for n in range(hidden_size):\n",
    "                        place[k][n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[0][i],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        plt.show()\n",
    "        \n",
    "        MakeAnimation_img(place[:,i],\"test!!!\"+str(i))\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#init nashi\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long_s5_200_1.pth'\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "        if n == \"HPC.weight_ih\":\n",
    "            p.data[:,inputsize:].sub_(p.data[:,inputsize:])\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    xnum = 50\n",
    "    ynum = 50\n",
    "    initx = 0.2\n",
    "    endx = 0.8\n",
    "    widex = (endx-initx)/xnum\n",
    "    \n",
    "    inity = 0.0\n",
    "    endy = 0.6\n",
    "    widey = (endy-inity)/ynum\n",
    "    \n",
    "    place = np.zeros((hidden_size,xnum+1,ynum+1))\n",
    "    grid = [[] for i in range(hidden_size)]\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    y_list = np.array(range(ynum+1))\n",
    "    np.random.shuffle(y_list)\n",
    "    for y in y_list:\n",
    "        x_list = np.array(range(xnum+1))\n",
    "        np.random.shuffle(x_list)\n",
    "        for x in x_list:\n",
    "            #if y % 2 == 0: x = xnum - x\n",
    "            point = torch.tensor([[initx+widex*x,widey*y] for i in range(batch_size)])\n",
    "            output,hidden = rnn(point,hidden)\n",
    "            for n in range(hidden_size):\n",
    "                place[n][y][x] = hidden[1][0].tolist()[0][n]\n",
    "                grid[n].append([initx+widex*x,widey*y,hidden[1][0].tolist()[0][n]])\n",
    "                \n",
    "    grid = np.array(grid)\n",
    "    for i in range(hidden_size):\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(place[i],cmap='jet',origin='lower',interpolation='bilinear')\n",
    "        plt.show()\n",
    "        \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(grid[i,:,0],grid[i,:,1],grid[i,:,2])\n",
    "#         plt.show()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        x = np.arange(initx, endx+widex, widex)\n",
    "        y = np.arange(inity, endy+widey, widey)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "        z = place[i]\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.plot_surface(x, y, z, cmap='jet')\n",
    "        plt.show()\n",
    "    \n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal_long_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 200\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "\n",
    "    target = [40,60]\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[target[0]:target[1],0:20]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[target[0]:target[1],inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)[0:20,0:20]\n",
    "                Re_w /= np.max(Re_w)\n",
    "                \n",
    "    fig = plt.figure()\n",
    "    G = nx.from_numpy_matrix(np.matrix(PFC_w), create_using=nx.DiGraph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    nx.draw(G, layout)\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(121)\n",
    "    ax2 = fig2.add_subplot(122)\n",
    "    \n",
    "    ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    Renode = [(\"Re\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(PFCnode, bipartite=0)\n",
    "    A.add_nodes_from(HPCnode, bipartite=1)\n",
    "    A.add_nodes_from(Renode, bipartite=2)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if PFC_w[i,k]>0:\n",
    "                A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "            if Re_w[i,k]>0:\n",
    "                A.add_edge(Renode[i],PFCnode[k],weight=Re_w[i,k])\n",
    "    pos = {}\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(PFCnode))\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    pos.update((node, (3, index)) for index, node in enumerate(Renode))\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.eigenvector_centrality(A,weight=True)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(np.count_nonzero(PFC_w>0.3, axis=0),np.count_nonzero(HPC_w>0.3, axis=0),np.count_nonzero(Re_w>0.3, axis=0))\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    PFC2node = [(\"Re\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(PFCnode, bipartite=0)\n",
    "    A.add_nodes_from(HPCnode, bipartite=1)\n",
    "    A.add_nodes_from(Renode, bipartite=2)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if HPC_w[i,k]>0.5:\n",
    "                A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "            if PFC_w[i,k]>0.5:\n",
    "                A.add_edge(PFC2node[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(PFCnode))\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(HPCnode))\n",
    "    pos.update((node, (3, index)) for index, node in enumerate(PFC2node))\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.eigenvector_centrality(A,weight=True)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    B = nx.Graph()\n",
    "    PFCnode = [(\"PFC\"+str(i)) for i in range(20)]\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    B.add_nodes_from(PFCnode, bipartite=0)\n",
    "    B.add_nodes_from(HPCnode, bipartite=1)\n",
    "    for i in range(20):\n",
    "        for k in range(20):\n",
    "            if PFC_w[i,k]<0.8:\n",
    "                B.add_edge(PFCnode[i],HPCnode[k],weight=0)\n",
    "            else:\n",
    "                B.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "    bottom_nodes, top_nodes = bipartite.sets(B)\n",
    "    pos = {}\n",
    "    pos.update((node, (2, index)) for index, node in enumerate(bottom_nodes))\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(top_nodes))\n",
    "    print(pos)\n",
    "    edges,weights = zip(*nx.get_edge_attributes(B,'weight').items())\n",
    "    nx.draw(B, pos=pos, node_color='b', edgelist=edges, edge_color=weights, width=1.0, edge_cmap=plt.cm.Reds)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/v4_2Model_0_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 100\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*3):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            #print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(HPCnode, bipartite=0)\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(PFCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(PFCnode))\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(HPCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(HPCnode))\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s1_100_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                    pos.update({PFCnode[i]: (t+1, i)})\n",
    "                    pos.update({HPCnode[k]: (t, k)})\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "                    pos.update({HPCnode[i]: (t+1, i)})\n",
    "                    pos.update({PFCnode[k]: (t, k)})\n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.Graph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    initnode = 12\n",
    "    nodelinks = [HPCnode[initnode]]\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5 and HPCnode[k] in nodelinks:\n",
    "                    A.add_edge(PFCnode[i],HPCnode[k],weight=PFC_w[i,k])\n",
    "                    pos.update({PFCnode[i]: (t+1, i)})\n",
    "                    pos.update({HPCnode[k]: (t, k)})\n",
    "                    nodelinks.append(PFCnode[i])\n",
    "                if HPC and HPC_w[i,k]>0.5 and PFCnode[k] in nodelinks:\n",
    "                    A.add_edge(HPCnode[i],PFCnode[k],weight=HPC_w[i,k])\n",
    "                    pos.update({HPCnode[i]: (t+1, i)})\n",
    "                    pos.update({PFCnode[k]: (t, k)})\n",
    "                    nodelinks.append(HPCnode[i])\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal0_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal0_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/v4_2Model_0_3.pth'\n",
    "\n",
    "    train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden()\n",
    "    data_limit = 100\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*3):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            #print(output)\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)[0:20,:]\n",
    "                PFC_w /= np.max(PFC_w)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)[0:20,inputsize:]\n",
    "                HPC_w /= np.max(HPC_w)\n",
    "    \n",
    "    plt.figure()\n",
    "    A = nx.DiGraph()\n",
    "    HPCnode = [(\"HPC\"+str(i)) for i in range(20)]\n",
    "    A.add_nodes_from(HPCnode, bipartite=0)\n",
    "    pos = {}\n",
    "    pos.update((node, (1, index)) for index, node in enumerate(HPCnode))\n",
    "    for t in range(1,10):\n",
    "        if t % 2 == 1:\n",
    "            PFCnode = [(\"PFC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(PFCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(PFCnode))\n",
    "            PFC = True\n",
    "            HPC = False\n",
    "        else:\n",
    "            HPCnode = [(\"HPC\"+str((t//2)*20+i)) for i in range(20)]\n",
    "            A.add_nodes_from(HPCnode, bipartite=t+1)\n",
    "            pos.update((node, (t+1, index)) for index, node in enumerate(HPCnode))\n",
    "            HPC = True\n",
    "            PFC = False\n",
    "        for i in range(20):\n",
    "            for k in range(20):\n",
    "                if PFC and PFC_w[i,k]>0.5:\n",
    "                    A.add_edge(HPCnode[k],PFCnode[i],weight=PFC_w[i,k])\n",
    "                if HPC and HPC_w[i,k]>0.5:\n",
    "                    A.add_edge(PFCnode[k],HPCnode[i],weight=HPC_w[i,k])\n",
    "    sourcenode = 'HPC12'\n",
    "    targetnode = PFCnode[14]\n",
    "#     links = list(nx.shortest_path(A,target=targetnode).keys())\n",
    "    links = list(nx.shortest_path(A,source=sourcenode).keys())\n",
    "    for node in list(A.nodes(data=False)):\n",
    "        if node not in links:\n",
    "            A.remove_node(node)\n",
    "            pos.pop(node)\n",
    "    \n",
    "    \n",
    "    edges,weights = zip(*nx.get_edge_attributes(A,'weight').items())\n",
    "    measures = nx.degree_centrality(A)\n",
    "    nx.draw(A, pos=pos, nodelist=list(measures.keys()), node_color=list(measures.values()),  edgelist=edges, edge_color=weights, edge_cmap=plt.cm.Reds, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s4_100_4.pth')\n",
    "# model_list = glob.glob('model/R+/ReModel_L2_interRNNrand_AddRe_OUT5_151_s3_100_*.pth')\n",
    "# model_list = glob.glob('model/R+2/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s1_100_1_epoch*.pth')\n",
    "model_list = glob.glob('model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s*_100_1_epoch190.pth')\n",
    "# model_list = glob.glob('model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s*_100_1_epoch190.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [4,5]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list[:]\n",
    "\n",
    "weight_list_Re = []\n",
    "weight_list_PFC = []\n",
    "\n",
    "for model_path in target_list:\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "\n",
    "#     fig1.hist(PFC_w[PFC_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)\n",
    "#     fig1.hist(PFC_inw[PFC_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)  \n",
    "#     fig2.hist(HPC_inw[HPC_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True)  \n",
    "#     fig3.hist(Re_w[Re_w.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True) \n",
    "#     fig3.hist(Re_inw[Re_inw.nonzero()],bins=40,range=(-4,4),alpha=0.5,density=True) \n",
    "    \n",
    "    print(PFC_w[PFC_w.nonzero()])\n",
    "#     fig1.hist(PFC_w[PFC_w.nonzero()],bins=40,alpha=0.5,density=True)\n",
    "    fig1.hist(PFC_inw[PFC_inw.nonzero()],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w.nonzero()],bins=40,alpha=0.5,density=True)  \n",
    "    fig2.hist(HPC_inw[HPC_inw.nonzero()],bins=40,alpha=0.5,density=True)  \n",
    "#     fig2.hist(np.append(HPC_w[HPC_w.nonzero()],HPC_inw[HPC_inw.nonzero()]),bins=40,alpha=0.5,density=True)\n",
    "#     fig3.hist(Re_w[Re_w.nonzero()],bins=40,alpha=0.5,density=True) \n",
    "    fig3.hist(Re_inw[Re_inw.nonzero()],bins=40,alpha=0.5,density=True) \n",
    "#     fig3.hist(Re_inw,bins=40,alpha=0.5,density=True) \n",
    "#     fig3.hist(OUT_w[OUT_w.nonzero()],bins=40,alpha=0.5,density=True) \n",
    "\n",
    "    \n",
    "#     fig1.hist(PFC_b[PFC_b.nonzero()],bins=20,alpha=0.5,density=False)\n",
    "#     fig1.hist(PFC_inb[PFC_inb.nonzero()],bins=10,alpha=0.5,density=False)\n",
    "#     fig2.hist(HPC_b[HPC_b.nonzero()],bins=20,alpha=0.5,density=False)  \n",
    "#     fig2.hist(HPC_inb[HPC_inb.nonzero()],bins=10,alpha=0.5,density=False)  \n",
    "#     fig3.hist(Re_b[Re_b.nonzero()],bins=20,alpha=0.5,density=False) \n",
    "#     fig3.hist(Re_inb[Re_inb.nonzero()],bins=10,alpha=0.5,density=False) \n",
    "\n",
    "    weight_list_Re.append(Re_inw)\n",
    "    weight_list_PFC.append(PFC_w)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(-weight_list_PFC[0]+weight_list_PFC[1],cmap=\"coolwarm\")\n",
    "# plt.figure()\n",
    "# plt.imshow(-weight_list_PFC[1]+weight_list_PFC[2],cmap=\"coolwarm\")\n",
    "# plt.figure()\n",
    "# plt.imshow(-weight_list_Re[0]+weight_list_Re[2],cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s4_100_1*.pth')\n",
    "# model_list = glob.glob('model/R20_H_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s7_100_3_epoch*.pth')\n",
    "model_list = glob.glob('model/R20_H_uniPFC_bigbatch/ReModel_L2_interRNNrand_OUT1_121_s1_100_1_epoch*.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len)\n",
    "\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [19,22]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(121)\n",
    "fig_wcorr_eigen = fig_eigen.add_subplot(122)\n",
    "\n",
    "target_list = model_list[1:]\n",
    "PCA_list = np.array([[0,1,2]])\n",
    "\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "    print(model_path)\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "#     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "    PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "#     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "    fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "#     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "    a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "    a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "#     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "#     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "#     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "    HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "    HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "#     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "#     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "#     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "    fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "    b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "    b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "#     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "#     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "    Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "    Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "    Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "    fig3.plot((make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "#     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "    c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "    c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "    Re_inuw,Re_inuv = LA.eig(Re_inw)\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20]*PFC_inw[i+40:i+60])\n",
    "#     print(PFC_inuw,PFC_inuv)\n",
    "#     fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=color)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(PFC_inuw.real[k],PFC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(PFC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(PFC_inuw.real>0))\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "#     print(HPC_inuw,HPC_inuv)\n",
    "#     fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=color)\n",
    "    fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=color)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(HPC_inuw.real[k],HPC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "    print(np.count_nonzero(HPC_inuw.real>0))\n",
    "    print(np.count_nonzero(HPC_inuw.imag==0))\n",
    "    print(np.count_nonzero((HPC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[a1,a2,c2]]),axis=0)\n",
    "    print(a1-a2)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "    fig_wcorr_eigen.plot(np.mean(np.abs(PFC_inw)),np.mean(np.abs(PFC_inuw)),\"o\",color=color)\n",
    "\n",
    "# # print(PCA_list[1:])\n",
    "# pca = PCA()\n",
    "# dfs = PCA_list[1:]\n",
    "# pca.fit(dfs)\n",
    "# feature = pca.transform(dfs)\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "# #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# for i,n in enumerate(target_list):\n",
    "#     plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "# fig3d = plt.figure()\n",
    "# ax3d = Axes3D(fig3d)\n",
    "# ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "#     print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long_s*_200_?.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "# NGlist_name = np.array([\"s3_100_4\",\"s1_100_3\",\"s9_100_2\",\"s4_100_1\"])\n",
    "NGlist = np.array([])\n",
    "\n",
    "# for NG in NGlist_name:\n",
    "#     for i, n in enumerate(model_list):\n",
    "#         if n[-12:-4] == NG:\n",
    "#             NGlist = np.append(NGlist,int(i))\n",
    "# print(NGlist)\n",
    "    \n",
    "# target = [2,4,7,8,9]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "PCA_list = np.array([np.ones(4)])\n",
    "\n",
    "for model_path in target_list:\n",
    "    print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "    PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=40,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=20,density=True)\n",
    "    a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]))\n",
    "    a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]))\n",
    "    PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=40,density=True)\n",
    "    PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=20,density=True)\n",
    "    a3 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]))\n",
    "    a4 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]))\n",
    "\n",
    "    HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=40,density=True)\n",
    "    HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=20,density=True)\n",
    "    b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]))\n",
    "    b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]))\n",
    "    HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=40,density=True)\n",
    "    HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=20,density=True)\n",
    "    b3 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]))\n",
    "    b4 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]))\n",
    "\n",
    "\n",
    "    Re_w_hist = np.histogram(Re_w[Re_w>0],bins=40,density=True)\n",
    "    Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=20,density=True)\n",
    "    c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]))\n",
    "    c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]))\n",
    "    Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=40,density=True)\n",
    "    Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "    c3 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]))\n",
    "    c4 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]))\n",
    "    \n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b>0]),bins=20,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb>0]),bins=10,density=True)\n",
    "#     a1 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a2 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b<0]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb<0]),bins=40,density=True)\n",
    "#     a3 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a4 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[a2,b2,a4,b4]]),axis=0)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# print(PCA_list[1:])\n",
    "pca = PCA()\n",
    "dfs = PCA_list[1:]\n",
    "pca.fit(dfs)\n",
    "feature = pca.transform(dfs)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(feature[i, 0], feature[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(dfs[:, 2], dfs[:, 3], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"a4\")\n",
    "plt.ylabel(\"b4\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-12:],(dfs[i, 2], dfs[i, 3]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(dfs[i, 2], dfs[i, 3], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    ax3d.plot(feature[[i], 0], feature[[i], 1], feature[[i], 2], \"o\", color=\"r\",alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn import linear_model\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s*_100_*.pth')\n",
    "model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "NGlist_name = np.array([\"s3_100_4\",\"s1_100_3\",\"s9_100_2\",\"s4_100_1\"])\n",
    "# NGlist_name = np.array([])\n",
    "NGlist = np.array([])\n",
    "\n",
    "for NG in NGlist_name:\n",
    "    for i, n in enumerate(model_list):\n",
    "        if n[-12:-4] == NG:\n",
    "            NGlist = np.append(NGlist,int(i))\n",
    "print(NGlist)\n",
    "    \n",
    "# target = [2,4,7,8,9]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "PCA_list = np.array([np.ones(6)])\n",
    "\n",
    "exp_plot = plt.figure()\n",
    "exp_plot1 = exp_plot.add_subplot(111)\n",
    "\n",
    "for model_path in target_list:\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "    \n",
    "    PFC_w_exp = scipy.stats.expon.fit(np.abs(PFC_w[PFC_w>0]))\n",
    "    PFC_inw_exp = scipy.stats.expon.fit(np.abs(PFC_inw[PFC_inw>0]))\n",
    "    a1 = PFC_w_exp[1]\n",
    "    a2 = PFC_inw_exp[1]\n",
    "    PFC_w_exp = scipy.stats.expon.fit(np.abs(PFC_w[PFC_w<0]))\n",
    "    PFC_inw_exp = scipy.stats.expon.fit(np.abs(PFC_inw[PFC_inw<0]))\n",
    "    a3 = PFC_w_exp[1]\n",
    "    a4 = PFC_inw_exp[1]\n",
    "\n",
    "    HPC_w_exp = scipy.stats.expon.fit(np.abs(HPC_w[HPC_w>0]))\n",
    "    HPC_inw_exp = scipy.stats.expon.fit(np.abs(HPC_inw[HPC_inw>0]))\n",
    "    b1 = HPC_w_exp[1]\n",
    "    b2 = HPC_inw_exp[1]\n",
    "    HPC_w_exp = scipy.stats.expon.fit(np.abs(HPC_w[HPC_w<0]))\n",
    "    HPC_inw_exp = scipy.stats.expon.fit(np.abs(HPC_inw[HPC_inw<0]))\n",
    "    b3 = HPC_w_exp[1]\n",
    "    b4 = HPC_inw_exp[1]\n",
    "\n",
    "\n",
    "    Re_w_exp = scipy.stats.expon.fit(np.abs(Re_w[Re_w>0]))\n",
    "    Re_inw_exp = scipy.stats.expon.fit(np.abs(Re_inw[Re_inw>0]))\n",
    "    c1 = Re_w_exp[1]\n",
    "    c2 = Re_inw_exp[1]\n",
    "    Re_w_exp_n = scipy.stats.expon.fit(np.abs(Re_w[Re_w<0]))\n",
    "    Re_inw_exp_n = scipy.stats.expon.fit(np.abs(Re_inw[Re_inw<0]))\n",
    "    c3 = Re_w_exp_n[1]\n",
    "    c4 = Re_inw_exp_n[1]\n",
    "    \n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b>0]),bins=20,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb>0]),bins=10,density=True)\n",
    "#     a1 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a2 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "#     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b<0]),bins=80,density=True)\n",
    "#     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb<0]),bins=40,density=True)\n",
    "#     a3 = regression(make_bins(PFC_b_hist[1]),np.log(PFC_b_hist[0]))\n",
    "#     a4 = regression(make_bins(PFC_inb_hist[1]),np.log(PFC_inb_hist[0]))\n",
    "    \n",
    "    PCA_list = np.concatenate((PCA_list,[[b2,b4,a2,a4,c2,c4]]),axis=0)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "    xvalues = np.linspace(0,2,100)\n",
    "    pdf1 = scipy.stats.expon.pdf(xvalues,Re_inw_exp[0],Re_inw_exp[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(xvalues,Re_inw_exp_n[0],Re_inw_exp_n[1])\n",
    "    if model_path[-12:-4] == \"s9_100_2\":\n",
    "        exp_plot1.plot(pdf1,c=\"r\",alpha=1)\n",
    "        exp_plot1.plot(pdf2,c=\"r\",alpha=1)\n",
    "    elif model_path[-12:-4] == \"s4_100_1\":\n",
    "        exp_plot1.plot(pdf1,c=\"g\",alpha=1)\n",
    "        exp_plot1.plot(pdf2,c=\"g\",alpha=1)\n",
    "    else:\n",
    "        exp_plot1.plot(pdf1,c=\"b\",alpha=0.01)\n",
    "\n",
    "# print(PCA_list[1:])\n",
    "pca = PCA()\n",
    "dfs = PCA_list[1:]\n",
    "pca.fit(dfs)\n",
    "feature = pca.transform(dfs)\n",
    "\n",
    "print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "'+str(sparse)+'\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-15:],(feature[i, 0], feature[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(feature[i, 0], feature[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(dfs[:, 0], dfs[:, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"a4\")\n",
    "plt.ylabel(\"b4\")\n",
    "for i,n in enumerate(target_list):\n",
    "    plt.annotate(n[-15:],(dfs[i, 0], dfs[i, 1]))\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    plt.scatter(dfs[i, 0], dfs[i, 1], color=\"r\", alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], \"o\", alpha=0.8)\n",
    "for i in NGlist:\n",
    "    i = int(i)\n",
    "    ax3d.plot(feature[[i], 0], feature[[i], 1], feature[[i], 2], \"o\", color=\"r\",alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KL(data1,data2):\n",
    "    x = np.linspace(-2,2,200)\n",
    "    params1 = scipy.stats.norm.fit(data1)\n",
    "    params2 = scipy.stats.norm.fit(data2)\n",
    "    pdf1 = scipy.stats.norm.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.norm.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)\n",
    "\n",
    "def calc_KL_exp(data1,data2):\n",
    "    x = np.linspace(0,2,200)\n",
    "    params1 = scipy.stats.expon.fit(np.abs(data1[data1>=0]))\n",
    "    params2 = scipy.stats.expon.fit(np.abs(data2[data2>=0]))\n",
    "    pdf1 = scipy.stats.expon.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)\n",
    "\n",
    "def calc_KL_exp2(data1):\n",
    "    x = np.linspace(0,2,200)\n",
    "    params1 = scipy.stats.expon.fit(np.abs(data1[data1>=0]))\n",
    "    params2 = scipy.stats.expon.fit(np.abs(data1[data1<=0]))\n",
    "    pdf1 = scipy.stats.expon.pdf(x,params1[0],params1[1])\n",
    "    pdf2 = scipy.stats.expon.pdf(x,params2[0],params2[1])\n",
    "    return scipy.stats.entropy(pdf1,pdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import scipy\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s*_100_2.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "target_list = []\n",
    "\n",
    "ANOVA_list = []\n",
    "\n",
    "# target = [2,4]\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "target_list = model_list\n",
    "\n",
    "fig_Re = plt.figure(figsize=(10,5))\n",
    "for i,model_path in enumerate(target_list):\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "                weight_PFC_w = PFC_w[PFC_w.nonzero()]\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "                weight_PFC_inw = PFC_inw[PFC_inw.nonzero()]\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "                weight_HPC_w = HPC_w[HPC_w.nonzero()]\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "                weight_HPC_inw = HPC_inw[HPC_inw.nonzero()]\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "                weight_Re_w = Re_w[Re_w.nonzero()]\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "                weight_Re_inw = Re_inw[Re_inw.nonzero()]\n",
    "    \n",
    "#     plt.plot(np.ones(weight_Re_inw.shape[0])*i,weight_Re_inw,\"o\") \n",
    "    plt.plot(np.ones(weight_Re_w.shape[0])*i,weight_Re_w,\"o\") \n",
    "    ANOVA_list.append(weight_Re_w)\n",
    "    \n",
    "    print(model_path)\n",
    "    \n",
    "#     print(calc_KL(weight_HPC_inw,weight_HPC_w)+calc_KL(weight_PFC_inw,weight_PFC_w)+calc_KL(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL(weight_HPC_w,weight_HPC_inw)+calc_KL(weight_PFC_w,weight_PFC_inw)+calc_KL(weight_Re_w,weight_Re_inw))\n",
    "\n",
    "#     print(calc_KL_exp(weight_HPC_inw,weight_HPC_w))\n",
    "#     print(calc_KL_exp(weight_HPC_w,weight_HPC_inw))\n",
    "#     print(calc_KL_exp(weight_PFC_inw,weight_PFC_w))\n",
    "#     print(calc_KL_exp(weight_PFC_w,weight_PFC_inw))\n",
    "#     print(calc_KL_exp(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL_exp(weight_Re_w,weight_Re_inw))\n",
    "    \n",
    "#     print(calc_KL_exp2(weight_HPC_inw))\n",
    "#     print(calc_KL_exp2(weight_PFC_inw))\n",
    "    print(calc_KL_exp2(weight_Re_inw))\n",
    "#     print(calc_KL_exp2(weight_HPC_w))\n",
    "#     print(calc_KL_exp2(weight_PFC_w))\n",
    "#     print(calc_KL_exp2(weight_Re_w))\n",
    "\n",
    "print(scipy.stats.f_oneway(ANOVA_list[3], ANOVA_list[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import scipy\n",
    "\n",
    "model_list = glob.glob('model/ReModel_interRNN_long131test_s1_100_3_plus_*.pth')\n",
    "print(model_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "target_list = []\n",
    "\n",
    "ANOVA_list = []\n",
    "\n",
    "target = [4,8]\n",
    "for i in target:\n",
    "    target_list.append(model_list[i])\n",
    "\n",
    "# target_list = model_list\n",
    "\n",
    "fig_Re = plt.figure(figsize=(10,5))\n",
    "for i,model_path in enumerate(target_list):\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "                weight_PFC_w = PFC_w\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "                weight_PFC_inw = PFC_inw\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "                weight_HPC_w = HPC_w\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "                weight_HPC_inw = HPC_inw\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "                weight_Re_w = Re_w\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "                weight_Re_inw = Re_inw\n",
    "    \n",
    "#     plt.plot(np.ones(weight_Re_inw.shape[0])*i,weight_Re_inw,\"o\") \n",
    "    plt.plot(np.ones(weight_Re_w.shape[0])*i,weight_Re_w,\"o\") \n",
    "    ANOVA_list.append(weight_Re_inw)\n",
    "    \n",
    "    print(model_path)\n",
    "    \n",
    "#     print(calc_KL(weight_HPC_inw,weight_HPC_w)+calc_KL(weight_PFC_inw,weight_PFC_w)+calc_KL(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL(weight_HPC_w,weight_HPC_inw)+calc_KL(weight_PFC_w,weight_PFC_inw)+calc_KL(weight_Re_w,weight_Re_inw))\n",
    "\n",
    "#     print(calc_KL_exp(weight_HPC_inw,weight_HPC_w))\n",
    "#     print(calc_KL_exp(weight_HPC_w,weight_HPC_inw))\n",
    "#     print(calc_KL_exp(weight_PFC_inw,weight_PFC_w))\n",
    "#     print(calc_KL_exp(weight_PFC_w,weight_PFC_inw))\n",
    "#     print(calc_KL_exp(weight_Re_inw,weight_Re_w))\n",
    "#     print(calc_KL_exp(weight_Re_w,weight_Re_inw))\n",
    "    \n",
    "#     print(calc_KL_exp2(weight_HPC_inw))\n",
    "#     print(calc_KL_exp2(weight_PFC_inw))\n",
    "    print(calc_KL_exp2(weight_Re_inw))\n",
    "#     print(calc_KL_exp2(weight_HPC_w))\n",
    "#     print(calc_KL_exp2(weight_PFC_w))\n",
    "#     print(calc_KL_exp2(weight_Re_w))\n",
    "\n",
    "print(scipy.stats.f_oneway(ANOVA_list[0], ANOVA_list[1]))\n",
    "plt.figure()\n",
    "plt.imshow(ANOVA_list[0]-ANOVA_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2):\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.RNNCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.5\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    model_path = 'model/ReModel_interRNN_long131test_s6_100_2.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet(training_size,filename,data_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 10\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*0.9\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*2):\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "    #MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    dividenum = int(np.array(feature).shape[0]/2)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:dividenum,0,0],traj[:dividenum,0,1])\n",
    "    plt.plot(traj[dividenum:,0,0],traj[dividenum:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    HPC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    PFC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    Re_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "#     MakeAnimation(feature[:dividenum, 0], feature[:dividenum, 1], feature[dividenum:, 0], feature[dividenum:, 1], data_limit)\n",
    "\n",
    "    plot_distance_bet2traj(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(HPC_dis)\n",
    "    plt.plot(PFC_dis)\n",
    "    plt.plot(Re_dis)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "#     order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s7_100_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_161_s5_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s9_100_1_2_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s5_100_4.pth'\n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s5_100_1_epoch125.pth'\n",
    "    \n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 140\n",
    "    est_length = 5\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    dividenum = int(np.array(feature).shape[0]/2)\n",
    "    \n",
    "#     MakeAnimation(traj[:dividenum,0,0],traj[:dividenum,0,1], traj[dividenum:,0,0], traj[dividenum:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:dividenum,0,0],traj[:dividenum,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:dividenum,0],\"PFCr\")\n",
    "#     MakeAnimation_img(np.array(PFCstate)[dividenum:,0],\"PFCl\")\n",
    "#     MakeAnimation_img(np.array(PFCstate_noise)[:,0],\"PFCnoise\")\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:dividenum,0,0],traj[:dividenum,0,1])\n",
    "    plt.plot(traj[dividenum:,0,0],traj[dividenum:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    linelist = search_delay(traj[:dividenum,0])\n",
    "    linelist2 = search_delay(traj[dividenum:,0])\n",
    "    linelist_all = np.append(linelist,linelist2)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(HPCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "    \n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    HPC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    HPC_samedis = plot_distance_bet2traj(np.array(HPCstate)[:dividenum,0],np.array(HPCstate)[dividenum:,0],linelist_all)\n",
    "    \n",
    "    print(linelist,linelist2)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[20:21, 0], feature[20:21, 1], feature[20:21, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[60:61, 0], feature[60:61, 1], feature[60:61, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "#     for i in range(20):\n",
    "#         fig_place = plt.figure()\n",
    "#         place3d = Axes3D(fig_place)\n",
    "#         place3d.plot(traj[:,0,0], traj[:,0,1], np.array(PFCstate)[:,0,i])\n",
    "#         plt.show()\n",
    "\n",
    "#   ### for 3d divided plot ###\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    end = 0\n",
    "    for i in range(3):\n",
    "        start = end\n",
    "        end = int(linelist[i*2+1])\n",
    "        ax3d.plot(feature[start:start+1, 0], feature[start:start+1, 1], feature[start:start+1, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start+20:start+21, 0], feature[start+20:start+21, 1], feature[start+20:start+21, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start+40:start+41, 0], feature[start+40:start+41, 1], feature[start+40:start+41, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2], color=colors[i], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    PFC_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "    PFC_samedis = plot_distance_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate)[dividenum:,0],linelist)\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "    \n",
    "#   ### for 3d divided plot ###\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    end = 0\n",
    "    for i in range(3):\n",
    "        start = end\n",
    "        end = int(linelist[i*2+1])\n",
    "        ax3d.plot(feature[start:start+1, 0], feature[start:start+1, 1], feature[start:start+1, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start+20:start+21, 0], feature[start+20:start+21, 1], feature[start+20:start+21, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start+40:start+41, 0], feature[start+40:start+41, 1], feature[start+40:start+41, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "#         ax3d.plot(feature[start+20:start+21, 0], feature[start+20:start+21, 1], feature[start+20:start+21, 2], \"o\", color=colors[i], alpha=0.8)\n",
    "        ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2], color=colors[i], alpha=0.8)\n",
    "    plt.show()\n",
    "\n",
    "    plot_distance(feature[:dividenum],feature[dividenum:])\n",
    "    Re_dis = overlap_coefficient(feature[:dividenum],feature[dividenum:])\n",
    "    \n",
    "#     MakeAnimation(feature[:dividenum, 0], feature[:dividenum, 1], feature[dividenum:, 0], feature[dividenum:, 1], data_limit)\n",
    "\n",
    "    Re_samedis = plot_distance_bet2traj(Restate[:dividenum],Restate[dividenum:],linelist)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(HPC_dis)\n",
    "    plt.plot(PFC_dis)\n",
    "    plt.plot(Re_dis)\n",
    "    plt.vlines(linelist,0,1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(HPC_samedis)\n",
    "    plt.plot(PFC_samedis)\n",
    "    plt.plot(Re_samedis)\n",
    "    plt.vlines(linelist,0,3)\n",
    "    plt.show()\n",
    "    \n",
    "    Re_noisedisr = plot_distance_bet2traj(Restate[:dividenum],Restate_noise[:],linelist)\n",
    "    Re_noisedisl = plot_distance_bet2traj(Restate[dividenum:],Restate_noise[:],linelist)\n",
    "    PFC_noisedisr = plot_distance_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate_noise)[:,0],linelist)\n",
    "    PFC_noisedisl = plot_distance_bet2traj(np.array(PFCstate)[dividenum:,0],np.array(PFCstate_noise)[:,0],linelist)\n",
    "    plt.figure()\n",
    "    plt.plot(Re_noisedisr)\n",
    "    plt.plot(Re_noisedisl)\n",
    "    plt.vlines(linelist,0,3)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(PFC_noisedisr)\n",
    "    plt.plot(PFC_noisedisl)\n",
    "    plt.vlines(linelist,0,3)\n",
    "    plt.show()\n",
    "    \n",
    "    plot_activity_bet2traj(Restate[dividenum:],Restate[:dividenum],linelist)\n",
    "#     plot_activity_bet2traj(np.array(PFCstate)[:dividenum,0],np.array(PFCstate)[dividenum:,0],linelist)\n",
    "\n",
    "    points = np.array(np.where(traj_noise[:,0,1]<0.05)[0]).astype(\"int64\")\n",
    "    Replot = plt.figure()\n",
    "    axre2 = Replot.add_subplot(111)\n",
    "    axre2.imshow(np.corrcoef(np.array(np.array(Restate_noise)[points])))\n",
    "    axre2.set_title(\"Re\")  \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(np.array(Restate_noise)[points])\n",
    "#     dfs = np.array(np.array(Restate_noise))\n",
    "#     dfs = np.array(HPCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)    \n",
    "    \n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Restate_noise))\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "    delays = pick_traj(traj_noise[:,0], np.array(Restate_noise))\n",
    "    linelist_delay = [0]\n",
    "    for i in delays:\n",
    "        print(np.array(i).shape)\n",
    "        linelist_delay.append(linelist_delay[-1]+len(i))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(feature[:dividenum, 0], alpha=0.8)\n",
    "    plt.vlines(linelist_delay,0,3)\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(feature[:dividenum, 1], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(feature[:dividenum, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(feature[:dividenum, 0]+feature[:dividenum, 1]+feature[:dividenum, 2], alpha=0.8)\n",
    "#     plt.vlines(linelist,0,3)\n",
    "    plt.show()\n",
    "\n",
    "#     print(np.array(delays[:-1]).shape)\n",
    "#     tskm = TimeSeriesKMeans(n_clusters=4,metric='euclidean',max_iter=200)\n",
    "    \n",
    "#     data_kmeans = match_length(delays[:-1])\n",
    "#     tskm_pred = tskm.fit_predict(np.array(data_kmeans))\n",
    "#     print(tskm_pred)\n",
    "#     tskm_feature = tskm.transform(np.array(data_kmeans))\n",
    "#     print(tskm_feature)\n",
    "\n",
    "#     fig = plt.figure()\n",
    "# #     plt.plot(distance_bet2traj(delays[0][:40],delays[1][:40]))\n",
    "# #     plt.plot(distance_bet2traj(delays[0][:40],delays[2][:40]))\n",
    "# #     plt.plot(distance_bet2traj(delays[0][:40],delays[3][:40]))\n",
    "    \n",
    "#     data = match_length(delays[:-1])\n",
    "#     for k in range(6):\n",
    "#         fig = plt.figure()\n",
    "#         target = k\n",
    "#         for i in range(6):\n",
    "#             plt.plot(distance_bet2traj(data[target][:],data[i][:]))\n",
    "#         plt.show()\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "# #     delays = pick_delay(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "# #     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "# #     delays = pick_delay(traj_noise[:,0], np.array(Restate_noise))\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "# #     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise))\n",
    "#     linelist_delay = [0]\n",
    "\n",
    "#     print(np.array(delays[:-1]).shape)\n",
    "#     tskm = TimeSeriesKMeans(n_clusters=4,metric='euclidean',max_iter=200)\n",
    "    \n",
    "#     data_kmeans = match_length(delays[:-1])\n",
    "#     tskm_pred = tskm.fit_predict(np.array(data_kmeans))\n",
    "#     print(tskm_pred)\n",
    "#     tskm_feature = tskm.transform(np.array(data_kmeans))\n",
    "#     print(tskm_feature)\n",
    "\n",
    "#     fig = plt.figure()\n",
    "    \n",
    "#     data = match_length(delays[:-1])\n",
    "#     for k in range(6):\n",
    "#         fig = plt.figure()\n",
    "#         target = k\n",
    "#         for i in range(6):\n",
    "#             plt.plot(distance_bet2traj(data[target][:],data[i][:]))\n",
    "#         plt.show()\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "#     stacked_data = np.array(data)[:,:,0]\n",
    "#     cellsize = 20\n",
    "    \n",
    "#     for i in range(cellsize-1):\n",
    "#         num = int(i+1)\n",
    "#         np.array(data)[:,:,num]\n",
    "#         stacked_data = np.concatenate([stacked_data,np.array(data)[:,:,num]],axis=0)\n",
    "                                      \n",
    "#     pca = PCA()\n",
    "# #     dfs = np.array(data)[:,:,0]\n",
    "#     dfs = stacked_data\n",
    "# #     dfs = np.array(np.array(Restate_noise))\n",
    "# #     dfs = np.array(HPCstate)[0:,0]\n",
    "#     pca.fit(dfs)\n",
    "#     feature = pca.transform(dfs)  \n",
    "#     print(dfs.shape)\n",
    "    \n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "# #     ax3d.plot(feature[:dividenum, 0], feature[:dividenum, 1], feature[:dividenum, 2], alpha=0.8)\n",
    "# #     ax3d.plot(feature[dividenum:, 0], feature[dividenum:, 1], feature[dividenum:, 2], alpha=0.8)\n",
    "# #     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "# #     ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2],\"o\", alpha=1)\n",
    "#     for i in range(cellsize):\n",
    "#         start = i*8\n",
    "#         end = (i+1)*8\n",
    "#         if vec_var(dfs[start:end]) > 0.5:\n",
    "#             print(i)\n",
    "#             ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2],\"o\", alpha=1)\n",
    "#         else:\n",
    "#             ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2],\"o\", alpha=0.1)\n",
    "#     start = 0\n",
    "#     end = 8\n",
    "# #     ax3d.plot(feature[start:end, 0], feature[start:end, 1], feature[start:end, 2],\"o\", alpha=1)\n",
    "\n",
    "# #     for k in range(8):\n",
    "# #         points = np.arange(k,cellsize*8+k,step=8)\n",
    "# #         ax3d.plot(feature[points, 0], feature[points, 1], feature[points, 2], \"o\", alpha=0.1)\n",
    "# #     points = np.arange(2,cellsize*8+2,step=8)\n",
    "# #     ax3d.plot(feature[points, 0], feature[points, 1], feature[points, 2], \"o\", alpha=1)\n",
    "    \n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "#     for i in range(cellsize):\n",
    "#         start = i*8\n",
    "#         end = (i+1)*8\n",
    "#         if vec_var(dfs[start:end]) > 0:\n",
    "#             plt.figure()\n",
    "#             data = dfs[start:end]\n",
    "#             for k in range(4):\n",
    "#                 plt.plot(data[k])\n",
    "#                 plt.ylim(-1.1,1.1)\n",
    "# #                 print(lyapunov_exp(data[i]))\n",
    "# #                 print(nolds.lyap_r(data[k],min_tsep = 15, lag=1))\n",
    "#             plt.show()\n",
    "    \n",
    "#     print(\"Lyapnov\")\n",
    "#     for i in range(cellsize):\n",
    "#         print(nolds.lyap_r(np.array(Restate_noise)[:,i],min_tsep = 150, lag=55))\n",
    "            \n",
    "#     for i in range(1):\n",
    "#         plt.figure()\n",
    "#         plt.plot(np.array(PFCstate)[:100,0,i])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         print(Re_w.shape)\n",
    "        \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(5):\n",
    "#             plt.plot(np.array(PFCstate)[:400,k,i])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from scipy.special import expit\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "    # order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2,0,0,2])\n",
    "    # order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s7_100_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_161_s5_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s3_100_1_2_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s5_100_4.pth'\n",
    "#     model_path = 'model/R+/ReModel_L2_interRNNrand_AddRe_OUT5_151_s3_100_1_epoch80.pth'\n",
    "#     model_path = 'model/R+2/ReModel_L2_interRNNrand_AddRe100_OUT5_151_s1_100_1_epoch70.pth'\n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch125.pth'\n",
    "    \n",
    "\n",
    "\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_b = np.array(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 120\n",
    "    est_length = 5\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch105.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w = np.array(p.data)\n",
    "\n",
    "    length = 360\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "# #     plt.show()\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 20\n",
    "#             data = neurons[:length,k]*Re_w[i,k]\n",
    "#             if np.sum(np.abs(data)) > 5 and np.sum(np.abs(data)) > 5:\n",
    "#                 print(k,Re_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(Restate_noise)[:length]\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k+=0\n",
    "#             data = neurons[:length,k]*Re_inw[i,k]\n",
    "#             if np.sum(np.abs(data)) > 5 and np.sum(np.abs(data)) > 5:\n",
    "#                 print(k,Re_inw[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.concatenate((np.array(traj_noise)[:,0],np.array(Restate_noise)[:]),axis=1)\n",
    "#         neurons_b = np.concatenate((np.array(traj)[:,0],np.array(Restate)[:]),axis=1)\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(HPCstate_noise)[:length,0,9],alpha=0.3)\n",
    "# #         plt.plot(np.array(HPCstate)[:length,0,9],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         a = i\n",
    "#         i = 11\n",
    "#         for k in range(1):\n",
    "#             k = 2 + a \n",
    "#             data = moving_average(neurons[:length,k]*HPC_w[i,k])[:length]\n",
    "#             data_b = moving_average(neurons_b[:length,k]*HPC_w_b[i,k])[:length]\n",
    "#             if np.sum(np.abs(data)) > 0 and np.sum(np.abs(data)) > 0:\n",
    "#                 print(k,HPC_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "#                 plt.plot(data_b)\n",
    "#                 plt.plot(moving_average(neurons[:length,k]*HPC_w[i,k])[:length])\n",
    "#         ###### test zone for the difference between left and right  ########\n",
    "#         for k in range(1):\n",
    "#             k = 9\n",
    "#             data = neurons[:length,k]*HPC_w[i,k]\n",
    "#             if np.sum(np.abs(data)) > 0 and np.sum(np.abs(data)) > 0:\n",
    "#                 print(k,HPC_w[i,k],np.sum(np.abs(data)))\n",
    "# #                 plt.plot(data[:120])\n",
    "# #                 plt.plot(data[120:240])\n",
    "# #                 plt.plot(data[240:360])\n",
    "#                 plt.plot(data[120:240]-data[240:360])\n",
    "#         ##### test zone end ###########\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(Restate_noise)[:length]\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k+=0\n",
    "#             data = neurons[:length,k]*Re_inw[i,k]\n",
    "#             if np.sum(np.abs(data)) > 5 and np.sum(np.abs(data)) > 5:\n",
    "#                 print(k,Re_inw[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "\n",
    "#     for i in range(2):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(HPCstate_noise)[:,0]\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(traj_noise)[:length,0,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             data = neurons[:length,k]*OUT_w[i,k]\n",
    "#             if np.sum(np.abs(data)) > 3 and np.sum(np.abs(data)) > 3:\n",
    "#                 print(k,HPC_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "\n",
    "                \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(Restate_noise)[:length]\n",
    "#         for k in range(1):\n",
    "#             k+=0\n",
    "#             data = Re_inw[i]\n",
    "#             plt.plot(data)\n",
    "                \n",
    "#     ### random initials / batch\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(5):\n",
    "#             plt.plot(np.array(HPCstate)[:140,k,i])\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#v4 without Re\n",
    "#v4_1 revised forward function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.99\n",
    "        var = 0.99\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "#     model_path = 'model/ReModel_interRNN_long131test_s7_100_1.pth'\n",
    "#     model_path = 'model/ReModel_interRNNrand_AddRe_OUT5_161_s5_100_1.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s3_100_1_2_2.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s5_100_4.pth'\n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s6_100_1.pth'\n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s6_100_2_epoch90.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s5_100_2.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s4_100_2_epoch120.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s10_100_10.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s9_100_3_epoch325.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_TrainOUT_epoch0.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT1_151_s6_100_2_TrainOUT_cont_epoch1.pth'\n",
    "    model_path = 'model/R20_uniPFC/ReModel_L2_interRNNrand_OUT1_uniPFC_151_s5_100_1_epoch190.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "     \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 10\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "\n",
    "    length = 120\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "#     plt.show()\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 0\n",
    "#             data = neurons[:length,k]*Re_w[i,k]\n",
    "#             if np.sum(np.abs(data)) > 10 and np.sum(np.abs(data)) > 10:\n",
    "#                 print(k,Re_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(Restate_noise)[:length]\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             data = neurons[:length,k]*Re_inw[i,k]\n",
    "#             if np.sum(np.abs(data)) > 10 and np.sum(np.abs(data)) > 10:\n",
    "#                 print(k,Re_inw[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(10):\n",
    "#         plt.plot(traj[:,i,0],traj[:,i,1])\n",
    "#         plt.plot(traj_noise[:,i,0],traj_noise[:,i,1])\n",
    "        plt.plot(traj_noise[:,i,0])\n",
    "    plt.show()\n",
    "\n",
    "    ### random initials / batch\n",
    "    for i in range(2):\n",
    "        plt.figure()\n",
    "        for k in range(5):\n",
    "            plt.plot(np.array(Restate_noise)[:200,k,i])\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import collections\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "#             traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "#     order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2,0,0,2])\n",
    "#     order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "#     order = [1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2]\n",
    "#     #Test zone\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        index = np.array([11])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.ones(self.batch_size, index.size)*100\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.ones(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(9)/9\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 2\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_feedforward(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s4_100_2_epoch120.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s1_100_4_epoch220.pth'\n",
    "    model_path = 'model/R20_1212121/ReModel_L2_interRNNrand_OUT1_1212121_s3_100_3_epoch130.pth'\n",
    "#     model_path = 'model/R20_transfer3_1212121/ReModel_L2_interRNNrand_OUT1_transfers64_1212121_s9_100_3_epoch40.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s1_100_1_2_2.pth'\n",
    "#     model_path = 'model/R20_feed/FeedModel_L2_interRNNrand_OUT1_151_s5_100_2_epoch150.pth'\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 10\n",
    "    est_length = 2\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    print(np.array(Gate_states).shape)\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "                \n",
    "            \n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s2_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s3_100_5_epoch215.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_TrainOUT_epoch0.pth'\n",
    "#     model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s10_100_1_2_3.pth'\n",
    "#     model_path = 'model/R20_feed/FeedModel_L2_interRNNrand_OUT1_151_s5_100_2_epoch145.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[inputsize:,hidden_size:].sub_(p.data[inputsize:,hidden_size:])\n",
    " \n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_x, batch_size).float()\n",
    "#     data_limit = 20\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             hidden = rnn.noiseHidden_select(hidden)\n",
    "#             if traj_noise[-1][0][1] < 0.1:\n",
    "#                 for cell in range(1):\n",
    "# #                     hidden[2][0][cell+0] = np.average(np.array(Restate_noise)[-6:,cell+0])\n",
    "#                     hidden[2][0][cell+10] = np.average(np.array(Restate)[k-5+data_limit:k+5+data_limit,cell+10])\n",
    "# #                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[4+k+data_limit]\n",
    "# #                     hidden[2][0][cell+0] = np.array(Restate)[k+data_limit,cell+0] - moving_average(np.array(Restate)[:,cell+0])[4+k+data_limit]\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:,0,0],traj[:,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "#     plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "    plt.show()\n",
    "\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0])\n",
    "        plt.plot(traj_noise[:,0,0])\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "            plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "            plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,20+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate)[:300,i]),alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate_noise)[:300,i]),alpha=0.5)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     a = np.abs(np.corrcoef(np.array(PFCstate)[:,0].T) - np.corrcoef(np.array(PFCstate_noise)[:,0].T))\n",
    "# #     a = np.abs(np.corrcoef(np.array(Restate)[:].T) - np.corrcoef(np.array(Restate_noise)[:].T))\n",
    "#     plt.imshow(a,cmap=plt.get_cmap(\"Reds\"))\n",
    "\n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    plt.show()\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "    delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "#     delays = pick_traj(traj[:,0], feature[:])\n",
    "    bifur = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1.1,1.1)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for data in delays[1:-1]:\n",
    "#             plt.plot(np.array(data)[:,0+i,0],alpha=0.5)\n",
    "            plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "            print(len(data))\n",
    "#             check_bifur = np.argmax(np.abs(np.array(data)[:,0+i,0] - 0.5))\n",
    "#             bifur = np.append(bifur,data[check_bifur,i,0])\n",
    "#             print(check_bifur,data[check_bifur,i,0])\n",
    "        plt.title(\"PCA#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             k+=0\n",
    "#             data = PFC_w_a[i]\n",
    "#             plt.plot(data)\n",
    "#             data = PFC_w_b[i]\n",
    "#             plt.plot(data)\n",
    "\n",
    "#     length = 140\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "# #     plt.show()\n",
    "#     neuron_list = []\n",
    "#     neuron_list_Re = []\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons_a = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#         neurons_b = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(40):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_w_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_w_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_w_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_w_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_w_a[i,k],Re_w_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "            \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         i+=0\n",
    "#         neurons_a = np.array(Restate)[:]\n",
    "#         neurons_b = np.array(Restate_noise)[:]\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_inw_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_inw_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_inw_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_inw_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_inw_a[i,k],Re_inw_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list_Re.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "\n",
    "#     print(collections.Counter(neuron_list))\n",
    "#     print(collections.Counter(neuron_list_Re))\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "### fourier!!!\n",
    "\n",
    "import collections\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft \n",
    "import pandas as pd\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = hiddens[0][0]\n",
    "    HPC_input = torch.cat([input,Re],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def highpass(x, samplerate, fp, fs, gpass, gstop):\n",
    "    fn = samplerate / 2                           #ナイキスト周波数\n",
    "    wp = fp / fn                                  #ナイキスト周波数で通過域端周波数を正規化\n",
    "    ws = fs / fn                                  #ナイキスト周波数で阻止域端周波数を正規化\n",
    "    N, Wn = signal.buttord(wp, ws, gpass, gstop)  #オーダーとバターワースの正規化周波数を計算\n",
    "    b, a = signal.butter(N, Wn, \"high\")           #フィルタ伝達関数の分子と分母を計算\n",
    "    y = signal.filtfilt(b, a, x)                  #信号に対してフィルタをかける\n",
    "    return y    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "#             traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*v\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        index = np.array([3])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch160.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 2\n",
    "    est_length = 3\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "                \n",
    "            \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch170.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    data_limit = 2\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             hidden = rnn.noiseHidden_select(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    \n",
    "    linelist = search_delay(traj_noise[:,0])\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:,0,0],traj[:,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#     #########  FFT with numpy  ###########\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "#             data = np.array(PFCstate_noise)[:,k,i]\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(PFCstate_noise)[:,k,i]\n",
    "#             fourier = np.fft.fft(data)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*15\n",
    "#             plt.plot(freq,fourier)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "#             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             fourier = np.fft.fft(data)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*15\n",
    "#             plt.plot(freq,fourier)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "\n",
    "\n",
    "#     #########  FFT with scipy  ###########\n",
    "    \n",
    "#     fp = 2      #通過域端周波数[Hz]\n",
    "#     fs = 1      #阻止域端周波数[Hz]\n",
    "#     gpass = 3       #通過域端最大損失[dB]\n",
    "#     gstop = 40\n",
    "#     samplerate = 1500    \n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "#             data = np.array(PFCstate_noise)[:,k,i]\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(PFCstate)[:,k,i]\n",
    "#             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#             fourier = fft(data_filt)\n",
    "#             plt.plot(np.angle(fourier))\n",
    "#             data = np.array(PFCstate_noise)[:,k,i]\n",
    "#             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#             fourier = fft(data_filt)\n",
    "#             plt.plot(np.angle(fourier))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "#             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             fourier = np.fft.fft(data)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*15\n",
    "#             plt.plot(freq,fourier)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "        \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Restate_noise)[:,i]\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(Restate)[:,i]\n",
    "# # #             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "# #             data_filt = data\n",
    "# #             fourier = fft(data_filt)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,np.abs(fourier))\n",
    "# # #             plt.plot(np.degrees(np.angle(fourier)))\n",
    "            \n",
    "#             data = np.array(Restate_noise)[:,i]\n",
    "# #             data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#             data_filt = data\n",
    "#             fourier = fft(data_filt)\n",
    "#             freq = np.fft.fftfreq(len(fourier))*15\n",
    "#             plt.plot(np.log(np.abs(freq)),np.log(np.abs(fourier) ** 2),\"o\")\n",
    "# #             plt.plot(np.degrees(np.angle(fourier)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "        \n",
    "#     shift = 2\n",
    "#     seglen = 140\n",
    "        \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Restate_noise)[:,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx1 = signal.spectrogram(data,fs=15,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum')\n",
    "#             plt.pcolormesh(times,freqs, np.log10(sx1))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(Restate)[:,i]\n",
    "# #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx2 = signal.spectrogram(data,fs=15,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum')\n",
    "# #             plt.pcolormesh(times,freqs, np.log10(sx2))\n",
    "#             plt.pcolormesh(times,freqs, np.abs(np.log10(sx1)-np.log10(sx2)))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "        \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "# #             data = np.array(HPCstate_noise)[:,k,i]\n",
    "#             data = np.array(Restate)[:,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx = signal.spectrogram(data,fs=15,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum')\n",
    "#             plt.pcolormesh(times,freqs, np.log10(sx))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             data = np.array(HPCstate)[:,k,i]\n",
    "# #             fourier = np.fft.fft(data)\n",
    "# #             freq = np.fft.fftfreq(len(fourier))*15\n",
    "# #             plt.plot(freq,fourier)\n",
    "#             freqs,times,sx = signal.spectrogram(data,fs=15,nperseg=seglen,noverlap=seglen-shift,detrend=False,scaling='spectrum')\n",
    "#             plt.pcolormesh(times,freqs, np.log10(sx))\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     a = np.abs(np.corrcoef(np.array(PFCstate)[:,0].T) - np.corrcoef(np.array(PFCstate_noise)[:,0].T))\n",
    "# #     a = np.abs(np.corrcoef(np.array(Restate)[:].T) - np.corrcoef(np.array(Restate_noise)[:].T))\n",
    "#     plt.imshow(a,cmap=plt.get_cmap(\"Reds\"))\n",
    "    \n",
    "# #     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for data in delays[:]:\n",
    "#             plt.plot(np.array(data)[:300,i],alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))    \n",
    "\n",
    "\n",
    "    fp = 1     #通過域端周波数[Hz]\n",
    "    fs = 2      #阻止域端周波数[Hz]\n",
    "    gpass = 3       #通過域端最大損失[dB]\n",
    "    gstop = 40\n",
    "    samplerate = 15\n",
    "    result_a = []\n",
    "    result_b = []\n",
    "    for i in range(20):\n",
    "        data = np.array(PFCstate)[:,0,i]\n",
    "#         data = np.array(Restate)[:,i]\n",
    "\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.figure()\n",
    "#         plt.vlines(linelist,0,0.5)\n",
    "# #         plt.plot(data)\n",
    "#         plt.plot(data_filt)\n",
    "        result_a.append(data_filt)\n",
    "#         result_a.append(data)\n",
    "\n",
    "#     for i in range(20):\n",
    "        data = np.array(PFCstate_noise)[:,0,i]\n",
    "\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.plot(data_filt)\n",
    "        result_b.append(data_filt)\n",
    "#         result_b.append(data)\n",
    "\n",
    "    result_PFC = np.append(np.array(result_a).T,np.array(result_b).T,axis=0)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(result_PFC)[:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    plt.figure()\n",
    "    len = np.array(PFCstate).shape[0]\n",
    "#     plt.plot(feature[:len,0],alpha=0.5)\n",
    "#     plt.plot(feature[:len,1],alpha=0.5)\n",
    "#     plt.plot(feature[len:,0],alpha=0.5)\n",
    "#     plt.plot(feature[len:,1],alpha=0.5)\n",
    "#     plt.plot(feature[:len,0]-feature[len:,0],alpha=0.5)\n",
    "#     plt.plot(feature[:len,1]-feature[len:,1],alpha=0.5)\n",
    "#     plt.plot(feature[:len,2]-feature[len:,2],alpha=0.5)\n",
    "#     plt.plot(feature[:len,3]-feature[len:,3],alpha=0.5)\n",
    "\n",
    "\n",
    "#     fig3d = plt.figure()\n",
    "#     ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[len:, 0], feature[len:, 1], feature[len:, 2], \"o\",alpha=0.8)\n",
    "#     ax3d.plot(feature[:len, 0], feature[:len, 1], feature[:len, 2], \"o\",alpha=0.8)\n",
    "#     ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    result_a = []\n",
    "    result_b = []\n",
    "    for i in range(20):\n",
    "        data = np.array(HPCstate)[:,0,i]\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.figure()\n",
    "#         plt.vlines(linelist,0,0.5)\n",
    "# #         plt.plot(data)\n",
    "#         plt.plot(data_filt)\n",
    "        data = np.array(HPCstate)[:,0,i]\n",
    "        result_a.append(data_filt)\n",
    "#         result_a.append(data)\n",
    "#     for i in range(20):\n",
    "        data = np.array(HPCstate_noise)[:,0,i]\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.plot(data_filt)\n",
    "        result_b.append(data_filt)\n",
    "#         result_b.append(data)\n",
    "\n",
    "    result_HPC = np.append(np.array(result_a).T,np.array(result_b).T,axis=0)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(result_HPC)[:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    len = np.array(HPCstate).shape[0]\n",
    "#     plt.plot(feature[:len,0],alpha=0.5)\n",
    "#     plt.plot(feature[:len,1],alpha=0.5)\n",
    "#     plt.plot(feature[:len,2],alpha=0.5)\n",
    "#     plt.plot(feature[len:,0],alpha=0.5)\n",
    "#     plt.plot(feature[len:,1],alpha=0.5)\n",
    "#     plt.plot(feature[len:,2],alpha=0.5)\n",
    "#     plt.vlines(linelist,0,0.5)\n",
    "    \n",
    "    \n",
    "    result_a = []\n",
    "    result_b = []\n",
    "    for i in range(20):\n",
    "#         data = np.array(PFCstate)[:,0,i]\n",
    "        data = np.array(Restate)[:,i]\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.figure()\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.vlines(linelist,0,0.5)\n",
    "# #         plt.plot(data)\n",
    "#         plt.plot(data_filt)\n",
    "        data = np.array(Restate)[:,i]\n",
    "        result_a.append(data_filt)\n",
    "#         result_a.append(data)\n",
    "#     for i in range(20):\n",
    "#         data = np.array(PFCstate_noise)[:,0,i]\n",
    "        data = np.array(Restate_noise)[:,i]\n",
    "        data_filt = highpass(data, samplerate, fp, fs, gpass, gstop)\n",
    "#         plt.plot(data_filt)\n",
    "        result_b.append(data_filt)\n",
    "#         result_b.append(data)\n",
    "\n",
    "    result_Re = np.append(np.array(result_a).T,np.array(result_b).T,axis=0)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(result_Re)[:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    len = np.array(Restate).shape[0]\n",
    "    plt.plot(feature[:len,0],alpha=0.5)\n",
    "    plt.plot(feature[:len,0],alpha=0.5)\n",
    "#     plt.plot(feature[:len,1],alpha=0.5)\n",
    "#     plt.plot(feature[:len,2],alpha=0.5)\n",
    "    plt.plot(feature[len:,0],alpha=0.5)\n",
    "#     plt.plot(feature[len:,1],alpha=0.5)\n",
    "#     plt.plot(feature[len:,3],alpha=0.5)\n",
    "#     plt.plot(feature[:len,0]-feature[len:,0],alpha=0.5)\n",
    "#     plt.plot(feature[:len,1]-feature[len:,1],alpha=0.5)\n",
    "#     plt.plot(feature[:len,2]-feature[len:,2],alpha=0.5)\n",
    "#     plt.plot(feature[:len,3]-feature[len:,3],alpha=0.5)\n",
    "#     plt.vlines(linelist,0,0.5)\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[len:, 0], feature[len:, 1], feature[len:, 2], \"o\", alpha=0.8)\n",
    "    ax3d.plot(feature[:len, 0], feature[:len, 1], feature[:len, 2], \"o\", alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(feature[len:, 0],feature[len:, 1])\n",
    "#     plt.plot(feature[len:, 1])\n",
    "#     plt.plot(feature[len:, 2])\n",
    "#     plt.plot(feature[len:, 3])\n",
    "#     plt.plot(feature[len:, 4])\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "#     order = [1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.9\n",
    "        var = 0.9\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        index = np.array([11])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.ones(self.batch_size, index.size)*100\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.ones(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 7\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "            \n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            #Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw_a = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_w_a = np.array(p.data)\n",
    "\n",
    "                \n",
    "            \n",
    "    model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_TrainOUT_epoch0.pth'\n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch105.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[inputsize:,hidden_size:].sub_(p.data[inputsize:,hidden_size:])\n",
    "\n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     data_limit = 7\n",
    "    init_point = init_point*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             hidden = rnn.noiseHidden_select(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw_b = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_w_b = np.array(p.data)\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(traj[:dividenum,0,0],traj[:dividenum,0,1])\n",
    "#     plt.plot(traj[dividenum:,0,0],traj[dividenum:,0,1])\n",
    "    plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "#     plt.plot(data[1,0,0],data[1,0,1],\"o\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         plt.plot(traj[:dividenum,0,0])\n",
    "#         plt.plot(traj[dividenum:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "#         for k in range(1):\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate)[:dividenum,k,i]-np.array(HPCstate_noise)[:dividenum,k,i],alpha=0.5)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "        \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:dividenum,0,0])\n",
    "    plt.plot(traj_noise[:,0,0])\n",
    "#     plt.plot(traj[:dividenum,0,1])\n",
    "#     plt.plot(traj[dividenum:,0,1])\n",
    "#     plt.plot(feature[:dividenum,0]-feature[dividenum:,0],alpha=0.5)\n",
    "#     plt.plot(feature[:dividenum,1]-feature[dividenum:,1],alpha=0.5)\n",
    "#     plt.plot(feature[:dividenum,2]-feature[dividenum:,2],alpha=0.5)\n",
    "#     plt.plot(np.abs(feature[:dividenum,:5]-feature[dividenum:,:5]),alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    limit = 480\n",
    "    a = np.abs(traj[:limit,0,0]-0.5)\n",
    "    b = np.abs(traj[dividenum:dividenum+limit,0,0]-0.5)\n",
    "    c = distance_bet2traj(np.array(HPCstate)[:limit,0],np.array(HPCstate)[dividenum:dividenum+limit,0])\n",
    "    plt.figure()\n",
    "    plt.plot(a)\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.plot(np.abs(a-b))\n",
    "\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "    delays = pick_traj(traj[:dividenum,0], np.array(Restate)[:dividenum])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    print(len(delays[0]))\n",
    "    print(len(delays[-2]))\n",
    "#     for i in range(20):\n",
    "#         for data in delays[:-1]:\n",
    "#             print(len(data))\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "    delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj[dividenum:,0], np.array(Restate)[dividenum:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    print(len(delays[0]))\n",
    "    print(len(delays[-2]))\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for data in delays[:-1]:\n",
    "#             plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "#             print(len(data))\n",
    "#         plt.title(\"neuron#\"+str(i+1))      \n",
    "\n",
    "    fig2 = plt.figure(figsize=(10,5))\n",
    "    ax1 = fig2.add_subplot(141)\n",
    "    ax2 = fig2.add_subplot(142)\n",
    "    axre = fig2.add_subplot(143)\n",
    "    axout = fig2.add_subplot(144)\n",
    "    \n",
    "    ax1.imshow(PFC_w_a - PFC_w_b,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_w_a - HPC_w_b,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_w_a - Re_w_b,cmap=\"coolwarm\")\n",
    "    axout.imshow(Output_w_a - Output_w_b,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w_a - PFC_w_b),np.min(PFC_w_a - PFC_w_b)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w_a - HPC_w_b),np.min(HPC_w_a - HPC_w_b)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_w_a - Re_w_b),np.min(Re_w_a - Re_w_b)))\n",
    "    axout.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Output_w_a - Output_w_b),np.min(Output_w_a - Output_w_b)))\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(131)\n",
    "    ax2 = fig2.add_subplot(132)\n",
    "    axre = fig2.add_subplot(133)\n",
    "    \n",
    "    ax1.imshow(PFC_inw_a - PFC_inw_b,cmap=\"coolwarm\")\n",
    "    ax2.imshow(HPC_inw_a - HPC_inw_b,cmap=\"coolwarm\")\n",
    "    axre.imshow(Re_inw_a - Re_inw_b,cmap=\"coolwarm\")\n",
    "    ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_inw_a - PFC_inw_b),np.min(PFC_inw_a - PFC_inw_b)))\n",
    "    ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_inw_a - HPC_inw_b),np.min(HPC_inw_a - HPC_inw_b)))\n",
    "    axre.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(Re_inw_a - Re_inw_b),np.min(Re_inw_a - Re_inw_b)))  \n",
    "    \n",
    "    uvr,uw,uvl = np.linalg.svd(Re_inw_a - Re_inw_b,full_matrices=False)\n",
    "    print(uw)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "import scipy.stats as st\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_?.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "model_list = glob.glob('model/R20_cont_add/*OUT1**s*_100_*_epoch1??.pth')\n",
    "# model_list = glob.glob('model_test/4_2/*.pth')\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"attract2_list.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "# with open(\"attract_contfail_test_list2.txt\") as f:\n",
    "with open(\"attract_contfail_list_add_test.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "# with open(\"attract_contgood_test_list.txt\") as f:\n",
    "with open(\"attract_contgood_list_add_test.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "    \n",
    "test_list_A_selected = []\n",
    "test_list_B_selected = []\n",
    "test_list_A_limited = []\n",
    "test_list_B_limited = []\n",
    "\n",
    "for model_path in model_list:\n",
    "    if model_path in test_list_A:\n",
    "        test_list_A_selected.append(model_path)\n",
    "    if model_path in test_list_B:\n",
    "        test_list_B_selected.append(model_path)            \n",
    "\n",
    "# if len(test_list_A_selected) > len(test_list_B_selected):\n",
    "#     random_num = np.random.randint(0,len(test_list_A_selected),len(test_list_B_selected))\n",
    "#     for i in random_num:\n",
    "#         test_list_A_limited.append(test_list_A_selected[i])\n",
    "#     test_list_B_limited = test_list_B_selected\n",
    "# else:\n",
    "#     random_num = np.random.randint(0,len(test_list_B_selected),len(test_list_A_selected))\n",
    "#     for i in random_num:\n",
    "#         test_list_B_limited.append(test_list_B_selected[i])\n",
    "#     test_list_A_limited = test_list_A_selected\n",
    "\n",
    "limited_number = 0\n",
    "if limited_number > 0:\n",
    "    random_num = np.random.randint(0,len(test_list_A_selected),limited_number)\n",
    "    for i in random_num:\n",
    "        test_list_A_limited.append(test_list_A_selected[i])\n",
    "    random_num = np.random.randint(0,len(test_list_B_selected),limited_number)\n",
    "    for i in random_num:\n",
    "        test_list_B_limited.append(test_list_B_selected[i])\n",
    "else:\n",
    "    test_list_A_limited = test_list_A_selected\n",
    "    test_list_B_limited = test_list_B_selected\n",
    "\n",
    "    \n",
    "print(len(test_list_A_limited),len(test_list_B_limited))\n",
    "    \n",
    "# test_list = glob.glob('model/R20/*s1*_100_2*.pth')\n",
    "# test_list = glob.glob('model/R20_cont/*OUT1*s*_100_*.pth')\n",
    "# test_list = glob.glob('model_test/4_2/*.pth')\n",
    "test_list = model_list\n",
    "# test_list = lines\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# target = [11,12,-2]\n",
    "# target = [21,22,23]\n",
    "target = [-7, -2]\n",
    "test_target = []\n",
    "\n",
    "for i in target:\n",
    "    test_target.append(test_list[i])\n",
    "test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "\n",
    "target_list = model_list[:]\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(111)\n",
    "test_colors = []\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "PCA_list_A = np.array([[0,1,2,3,4]])\n",
    "PCA_list_B = np.array([[0,1,2,3,4]])\n",
    "\n",
    "stat_list_A = []\n",
    "stat_list_B = []\n",
    "\n",
    "stat_list_xy_A = [np.array([0]),np.array([0])]\n",
    "stat_list_xy_B = [np.array([0]),np.array([0])]\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "    \n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "# #     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "# #     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "# #     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "# #     fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "#     a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "#     a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "#     fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "#     b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "#     b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "# #     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "#     Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "#     c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "#     c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "#     Re_uw,Re_uv = LA.eig(Re_w[:,20:])\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "#     print(np.count_nonzero(Re_uw.real>0))\n",
    "#     print(np.count_nonzero(Re_uw.imag==0))\n",
    "#     print(np.count_nonzero((Re_uw.imag==0)*(Re_uw.real>0)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20])\n",
    "#     print(PFC_inuw,PFC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=testcolor,zorder=2)\n",
    "#     else :\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=color,alpha=0.01,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(PFC_inuw.real[k],PFC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(PFC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(PFC_inuw.real>0))\n",
    "#     print(np.count_nonzero(PFC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((PFC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "#     print(HPC_inuw,HPC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "# #     elif num < 40:\n",
    "# #         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=\"b\",alpha=1)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(HPC_inuw.real[k],HPC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(HPC_inuw.real>0))\n",
    "#     print(np.count_nonzero(HPC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "#     HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,2:],[(0,0),(0,0)]))\n",
    "#     HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,:2],[(0,0),(0,18)]))\n",
    "#     print(HPC_uw,HPC_uv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     print(np.count_nonzero(HPC_uw.real>0))\n",
    "#     print(np.count_nonzero(HPC_uw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_uw.imag==0)*(HPC_uw.real>0)))\n",
    "\n",
    "# #     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "# #     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "# #     HPC_allw = HPC_inw[0:20]\n",
    "# #     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "# #     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = (PFC_w[0:20,:20]+PFC_inw[0:20])*(PFC_w[40:60,:20]+PFC_inw[40:60])\n",
    "# #     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw2 = (PFC_w[0:20,20:]+PFC_inw[0:20])*(PFC_w[40:60,20:]+PFC_inw[40:60])\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20]\n",
    "#     Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2)\n",
    "    all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(Re_inw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * Re_allw2 + PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw * Re_allw2 + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw * Re_allw * HPC_allw + PFC_allw2 * Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw @ Re_allw @ HPC_allw + PFC_allw2 @ Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(np.pad(Out_w[:,:],[(0,18),(0,0)]))\n",
    "#     all_uw,all_uv = LA.eig(Out_w[:,:]@(HPC_w[0:20,:2]*HPC_w[40:60,:2]))\n",
    "#     all_uw,all_uv = LA.eig(np.pad(HPC_w[20:40,:2],[(0,0),(0,18)]))\n",
    "#     all_uw,all_uv = LA.eig(np.pad(HPC_w[60:,:2],[(0,0),(0,18)]))\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[20:40])\n",
    "# #     print(HPC_inuw,HPC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "# #         testcolor = \"r\"\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "#         print(model_path,testcolor,np.average(abs(all_uw)))\n",
    "# #         print(all_uw)\n",
    "# #         print(all_uv.T)\n",
    "# #         print(np.count_nonzero(all_uw.real>0))\n",
    "# #         print(np.count_nonzero(all_uw.imag==0))\n",
    "# #         print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "# #         print(np.average(abs(all_uw)))\n",
    "# #         for k in range(20):\n",
    "# #             fig_eigenval.text(all_uw.real[k],all_uw.imag[k],str(model_path.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "#     else:\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "        \n",
    "    if model_path in test_list_A_limited:\n",
    "#     if not model_path in test_list_B_limited:\n",
    "#         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [0],\"o\", color = \"r\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "        fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.zeros(20),all_uw.imag,\"o\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(1,np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],\"o\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.max(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.max(np.abs(all_uw.real)),np.average(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "#         print(model_path,\"bad\")\n",
    "#         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "#         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "        PCA_list_A = np.concatenate((PCA_list_A,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "        stat_list_A.append(np.sort((abs(all_uw))))\n",
    "#         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.array(all_uw.real))\n",
    "#         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.abs(all_uw.imag))\n",
    "#         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],abs(all_uw))\n",
    "#         stat_list_xy_A[0] = np.append(stat_list_xy_A[0],all_uw.imag[np.where(all_uw.imag>0)])\n",
    "#         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],abs(all_uw)[np.where(all_uw.imag>0)])\n",
    "        stat_list_xy_A[0] = np.append(stat_list_xy_A[0],np.average(abs(all_uw)))\n",
    "        stat_list_xy_A[1] = np.append(stat_list_xy_A[1],np.max(abs(all_uw)))\n",
    "#         stat_list_xy_A[1] = np.append(stat_list_xy_A[1],np.average(abs(all_uw))/np.max(abs(all_uw)))\n",
    "#         fig_eigenval.text(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(0,np.average(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "    if model_path in test_list_B_limited:\n",
    "#         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [1],\"o\", color = \"b\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))],[np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "        fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.ones(20),all_uw.imag,\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(0,np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(np.max(np.abs(all_uw.real)),np.average(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         print(model_path,\"good\")\n",
    "#         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "#         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "        PCA_list_B = np.concatenate((PCA_list_B,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "        stat_list_B.append(np.sort((abs(all_uw))))\n",
    "#         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],all_uw.real)\n",
    "#         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],np.abs(all_uw.imag))\n",
    "#         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],abs(all_uw))\n",
    "#         stat_list_xy_B[0] = np.append(stat_list_xy_B[0],abs(all_uw.imag[np.where(all_uw.imag>0)]))\n",
    "#         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],abs(all_uw)[np.where(all_uw.imag>0)])\n",
    "        stat_list_xy_B[0] = np.append(stat_list_xy_B[0],np.average(abs(all_uw)))\n",
    "        stat_list_xy_B[1] = np.append(stat_list_xy_B[1],np.max(abs(all_uw)))\n",
    "#         stat_list_xy_B[1] = np.append(stat_list_xy_B[1],np.average(abs(all_uw))/np.max(abs(all_uw)))\n",
    "#         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(1,np.average(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "        \n",
    "        \n",
    "# #     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(all_uw.real>0))\n",
    "#     print(np.count_nonzero(all_uw.imag==0))\n",
    "#     print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "    \n",
    "    \n",
    "#     PCA_list = np.concatenate((PCA_list,[[a1,a2,c2]]),axis=0)\n",
    "#     print(a1-a2)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# # # print(PCA_list[1:])\n",
    "# PCA_list = np.concatenate((PCA_list_A[1:],PCA_list_B[1:]),axis=0)\n",
    "# length = PCA_list_A[1:].shape[0]\n",
    "# pca = PCA()\n",
    "# dfs = PCA_list\n",
    "# pca.fit(dfs)\n",
    "# feature = pca.transform(dfs)\n",
    "# # print(length,feature)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(feature[:length, 0], feature[:length, 1], color=\"r\",alpha=0.2)\n",
    "# plt.scatter(feature[length:, 0], feature[length:, 1], color=\"b\",alpha=0.2)\n",
    "# #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# # for i,n in enumerate(target_list):\n",
    "# #     plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "\n",
    "# fig3d = plt.figure()\n",
    "# ax3d = Axes3D(fig3d)\n",
    "# ax3d.plot(feature[:length, 0], feature[:length, 1], feature[:length, 2], \"o\", alpha=0.1)\n",
    "# ax3d.plot(feature[length:, 0], feature[length:, 1], feature[length:, 2], \"o\", alpha=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# gradient = np.array(test_colors)\n",
    "# gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(gradient, cmap=plt.cm.jet)\n",
    "# ax.set_axis_off()\n",
    "\n",
    "\n",
    "# print(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T)\n",
    "# st.f_oneway(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T)\n",
    "st.f_oneway(np.array(stat_list_A).reshape(-1,1),np.array(stat_list_B).reshape(-1,1))\n",
    "# st.ttest_ind(np.array(stat_list_xy_A).T,np.array(stat_list_xy_B).T,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "# model_list = glob.glob('model/R20_cont_add/*OUT1**s*_100_*.pth')\n",
    "model_list = glob.glob('model/R20_uniPFC/*s*_100_*.pth')\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "\n",
    "test_list = glob.glob('model/R20/*s*_100_1_*.pth')\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# # target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# # target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# # target = [11,12,-2]\n",
    "# # target = [19,20,21,22]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "f = open(\"attract_uniPFCgood_list.txt\",mode=\"w\")\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig = plt.figure()\n",
    "test_colors = []\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list = np.array([[0,1,2]])\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    \n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN_uniPFC(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 7\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "#     print(bifur,check_bifur)\n",
    "#     print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "    if bifur.shape[0] == 0:\n",
    "        continue\n",
    "    if np.var(bifur) < np.abs(np.median(bifur)-np.mean(bifur)) or np.var(bifur) < 0.0001:\n",
    "#     if np.abs(np.median(bifur)-np.mean(bifur)) < 0.0001 and np.var(bifur) < 0.0001:\n",
    "#         print(model_path)\n",
    "#         f.write(model_path+\"\\n\")\n",
    "        pass\n",
    "    else:\n",
    "        print(model_path)\n",
    "        plt.plot(np.log(np.var(bifur)),np.log(np.median(bifur)-np.mean(bifur)),\"o\")\n",
    "        print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "        f.write(model_path+\"\\n\")\n",
    "#         pass\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "model_list = glob.glob('model/R20_cont/*OUT1*s*_100_*.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"attract1_list.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "# with open(\"attract1_3_list.txt\") as f:\n",
    "#     test_list_A = f.read().splitlines()\n",
    "# with open(\"attract2_list.txt\") as f:\n",
    "#     test_list_B = f.read().splitlines()\n",
    "\n",
    "with open(\"attract_contfail_test_list.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "with open(\"attract_contgood_test_list.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "\n",
    "test_list = glob.glob('model/R20_cont/*s6*_100_2_*.pth')\n",
    "# test_list = lines\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(111)\n",
    "test_colors = []\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list_A = np.array([np.ones(6)])\n",
    "PCA_list_B = np.array([np.ones(6)])\n",
    "\n",
    "path_namelist_A = []\n",
    "path_namelist_B = []\n",
    "\n",
    "stat_list_A = []\n",
    "stat_list_B = []\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "\n",
    "    PCA_val = np.array([])\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "    PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "    PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "    Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "    Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_inuv = LA.eig(PFC_allw)\n",
    "#     all_uw,all_inuv = LA.eig(Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * Re_allw + PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * Re_allw + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw * Re_allw + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_inuv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * Re_allw)\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#     all_uw,all_inuv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#     all_uw,all_inuv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "\n",
    "    all_uw,all_inuv = LA.eig(HPC_allw)\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "    PCA_val = np.append(PCA_val, np.max(abs(all_uw)))\n",
    "    eigen_Re = np.average(abs(all_uw))\n",
    "    \n",
    "#     all_uw,all_inuv = LA.eig(PFC_allw)\n",
    "# #     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#     PCA_val = np.append(PCA_val, np.max(abs(all_uw)))\n",
    "# #     eigen_Re = np.average(abs(all_uw))\n",
    "\n",
    "    all_uw,all_inuv = LA.eig(HPC_allw @ Re_allw2 + PFC_allw2 @ Re_allw)\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "    PCA_val = np.append(PCA_val, np.max(abs(all_uw)))\n",
    "#     eigen_Re = np.max(abs(all_uw))\n",
    "    \n",
    "    all_uw,all_inuv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "#     PCA_val = np.append(PCA_val, [np.average(abs(all_uw)),np.max(abs(all_uw))])\n",
    "    PCA_val = np.append(PCA_val, np.average(abs(all_uw)))\n",
    "    eigen_HPC = np.max(abs(all_uw))\n",
    "    \n",
    "    all_uw,all_inuv = LA.eig(PFC_allw @ Re_allw @ HPC_allw + PFC_allw2 @ Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     PCA_val = np.append(PCA_val, [np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "    PCA_val = np.append(PCA_val, [np.max(abs(all_uw))])\n",
    "    eigen_PFC = np.average(abs(all_uw))\n",
    "    \n",
    "    all_uw,all_uv = LA.eig(np.pad(Out_w[:,:],[(0,18),(0,0)]))\n",
    "    PCA_val = np.append(PCA_val, [np.max(all_uw.real),np.min(all_uw.real)])\n",
    "#     PCA_val = np.append(PCA_val, [np.max(all_uw.real),np.min(all_uw.real), np.count_nonzero(all_uw.real>0), np.count_nonzero(all_uw.imag>0)])\n",
    "\n",
    "    if model_path in test_list_A:\n",
    "        PCA_list_A = np.concatenate((PCA_list_A,[PCA_val]),axis=0)\n",
    "        fig_eigenval.plot(eigen_HPC,eigen_PFC,\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "        fig_eigenval.text(eigen_HPC,eigen_PFC,str(model_path.split(\"s\")[-1]))\n",
    "        ax3d.plot([eigen_HPC],[eigen_Re],[eigen_PFC], \"o\", color = \"r\",alpha=0.1)\n",
    "        path_namelist_A.append(str(model_path.split(\"s\")[-1].split(\"epoch\")[0]))\n",
    "#         path_namelist_A.append(str(model_path.split(\"s\")[-1]))\n",
    "        stat_list_A.append([eigen_HPC,eigen_PFC])\n",
    "    if model_path in test_list_B:\n",
    "        PCA_list_B = np.concatenate((PCA_list_B,[PCA_val]),axis=0)\n",
    "        fig_eigenval.plot(eigen_HPC,eigen_PFC,\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.text(eigen_HPC,eigen_PFC,str(model_path.split(\"s\")[-1]))\n",
    "        ax3d.plot([eigen_HPC],[eigen_Re],[eigen_PFC], \"o\", color = \"b\",alpha=0.1)\n",
    "        path_namelist_B.append(str(model_path.split(\"s\")[-1].split(\"epoch\")[0]))\n",
    "#         path_namelist_B.append(str(model_path.split(\"s\")[-1]))\n",
    "        stat_list_B.append([eigen_HPC,eigen_PFC])\n",
    "\n",
    "# # print(PCA_list[1:])\n",
    "PCA_list = np.concatenate((PCA_list_A[1:],PCA_list_B[1:]),axis=0)\n",
    "length = PCA_list_A[1:].shape[0]\n",
    "pca = PCA()\n",
    "dfs = PCA_list\n",
    "pca.fit(dfs)\n",
    "feature = pca.transform(dfs)\n",
    "# print(length,feature)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(feature[:length, 0], feature[:length, 1], color=\"r\",alpha=0.2)\n",
    "plt.scatter(feature[length:, 0], feature[length:, 1], color=\"b\",alpha=0.2)\n",
    "#plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "# for i,n in enumerate(path_namelist_A):\n",
    "#     plt.annotate(n,(feature[i, 0], feature[i, 1]))\n",
    "# for i,n in enumerate(path_namelist_B):\n",
    "#     plt.annotate(n,(feature[length+i, 0], feature[length+i, 1]))\n",
    "plt.show()\n",
    "\n",
    "print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "ax3d.plot(feature[:length, 0], feature[:length, 1], feature[:length, 2], \"o\", color = \"r\",alpha=0.1)\n",
    "ax3d.plot(feature[length:, 0], feature[length:, 1], feature[length:, 2], \"o\", color = \"b\",alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "st.ttest_ind(stat_list_A,stat_list_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from scipy.special import expit\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "#     order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 20\n",
    "    est_length = 5\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "                \n",
    "        \n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch105.pth'\n",
    "    model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_TrainOUT_epoch0.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_pre = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)        \n",
    "        \n",
    "        \n",
    "    model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "#     rnn.PFC.weight_ih.data = PFC_w_pre\n",
    "#     rnn.HPC.weight_ih.data = HPC_w_pre\n",
    "#     rnn.Re.weight_ih.data[:20,:20] = 0.1*Re_w_pre[:20,:20] + 0.9*rnn.Re.weight_ih.data[:20,:20]\n",
    "#     rnn.Re.weight_ih.data[:20,:20] = 1*Re_w_pre[:20,:20] + 0*rnn.Re.weight_ih.data[:20,:20]\n",
    "#     rnn.Re.weight_ih.data = 1*Re_w_pre + 0*rnn.Re.weight_ih.data\n",
    "#     rnn.Re.weight_hh.data = 1*Re_inw_pre + 0*rnn.Re.weight_hh.data\n",
    "    rnn.Re.weight_hh.data[5:15] = 1*Re_inw_pre[5:15]\n",
    "#     rnn.linear.weight.data = 1*OUT_w_pre + 0*rnn.linear.weight.data\n",
    "\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                print(p.data)\n",
    "#             if n == \"HPC.weight_ih\":\n",
    "#                 HPC_w_b = np.array(p.data)\n",
    "#             if n == \"Re.weight_ih\":\n",
    "#                 Re_w_b = np.array(p.data)\n",
    "#             if n == \"Re.weight_hh\":\n",
    "#                 Re_inw = np.array(p.data)\n",
    "#             if n == \"linear.weight\":\n",
    "#                 OUT_w_b = np.array(p.data)\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj_noise[:,0,0])\n",
    "#     length = 360\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "# #     plt.show()\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 20\n",
    "#             data = neurons[:length,k]*Re_w[i,k]\n",
    "#             if np.sum(np.abs(data)) > 5 and np.sum(np.abs(data)) > 5:\n",
    "#                 print(k,Re_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.array(Restate_noise)[:length]\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k+=0\n",
    "#             data = neurons[:length,k]*Re_inw[i,k]\n",
    "#             if np.sum(np.abs(data)) > 5 and np.sum(np.abs(data)) > 5:\n",
    "#                 print(k,Re_inw[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons = np.concatenate((np.array(traj_noise)[:,0],np.array(Restate_noise)[:]),axis=1)\n",
    "# #         print(neurons,Re_w[i])\n",
    "# #         print((neurons*Re_w[i]))\n",
    "#         plt.plot(np.array(HPCstate_noise)[:length,0,9],alpha=0.3)\n",
    "# #         plt.plot(np.array(HPCstate)[:length,0,9],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         a = i\n",
    "#         i = 11\n",
    "#         for k in range(1):\n",
    "#             k = 2 + a \n",
    "#             data = moving_average(neurons[:length,k]*HPC_w[i,k])[:length]\n",
    "#             if np.sum(np.abs(data)) > 0 and np.sum(np.abs(data)) > 0:\n",
    "#                 print(k,HPC_w[i,k],np.sum(np.abs(data)))\n",
    "#                 plt.plot(data)\n",
    "# #                 plt.plot(data_b)\n",
    "# #                 plt.plot(moving_average(neurons[:length,k]*HPC_w[i,k])[:length])\n",
    "\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0])\n",
    "        plt.plot(traj_noise[:,0,0])\n",
    "    #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "    #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "                plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "def moving_var_test(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    var_seq = (data-mean_seq[2:-2])**2\n",
    "    return var_seq\n",
    "\n",
    "def moving_var_roll(data):\n",
    "    var_seq = []\n",
    "    for i in range(len(data)-4):\n",
    "        var_seq.append(np.var(data[i:i+4]))\n",
    "    return np.array(var_seq)\n",
    "\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "# model_list = glob.glob('model/R20_cont/*OUT1**s*_100_*.pth')\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "\n",
    "test_list = glob.glob('model/R20/*s1*_100_1_*.pth')\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# # target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# # target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# # target = [11,12,-2]\n",
    "# # target = [19,20,21,22]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "with open(\"attract1_3_list.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "with open(\"attract2_list.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "\n",
    "fig = plt.figure()\n",
    "test_colors = []\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(111)\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list = np.array([[0,1,2]])\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    \n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 7\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "\n",
    "    var_mean = []\n",
    "    for i in range(20):\n",
    "        var_mean.append(np.average(moving_var_roll(np.array(Restate)[:,i])))\n",
    "    print(model_path,np.average(var_mean))\n",
    "    \n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])\n",
    "    bifur = np.array([])\n",
    "    for data in delays[1:-1]:\n",
    "        print(len(data))\n",
    "        bifur = np.append(bifur,len(data))\n",
    "    \n",
    "    fig_eigenval.set_xlim(0,3)\n",
    "    if model_path in test_list_A:\n",
    "#         fig_eigenval.plot(1,np.average(var_mean),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "        fig_eigenval.plot(1,np.average(bifur),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "    if model_path in test_list_B:\n",
    "#         fig_eigenval.plot(2,np.average(var_mean),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "        fig_eigenval.plot(2,np.average(bifur),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## test for weight structure ###############\n",
    "\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "model_list = glob.glob('model/R20_cont/*OUT1*s5_100_1*.pth')\n",
    "# model_list = glob.glob('model/R20_cont/*s*_100_*.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"attract1_list.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "with open(\"attract1_3_list.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "with open(\"attract2_list.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "\n",
    "test_list = glob.glob('model/R20_cont/*s8*_100_1_*.pth')\n",
    "# test_list = lines\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list_A = np.array([np.ones(6)])\n",
    "PCA_list_B = np.array([np.ones(6)])\n",
    "\n",
    "path_namelist_A = []\n",
    "path_namelist_B = []\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "fig = plt.figure()\n",
    "i_f = fig.add_subplot(131)\n",
    "i_c = fig.add_subplot(132)\n",
    "i_o = fig.add_subplot(133)\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "\n",
    "\n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "    for t in range(20):\n",
    "        for i in range(2):\n",
    "            for k in range(1):\n",
    "#                 plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=color,alpha=0.1)\n",
    "#                 print(HPC_w[i,t],Out_w[k,i])\n",
    "                i_f.scatter(HPC_w[0+t,i],HPC_w[20+t,i],color=color,alpha=0.1)\n",
    "                i_c.scatter(HPC_w[0+t,i],HPC_w[40+t,i],color=color,alpha=0.1)\n",
    "                i_o.scatter(HPC_w[0+t,i],HPC_w[60+t,i],color=color,alpha=0.1)\n",
    "            \n",
    "    \n",
    "#     for t in range(20):\n",
    "#         for i in range(2):\n",
    "#             for k in range(1):\n",
    "#                 if model_path in test_list_A:\n",
    "#                     plt.scatter(HPC_w[0+t,i],HPC_w[40+t,i],color=\"r\",alpha=0.1)\n",
    "# #                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"r\",alpha=0.1)\n",
    "#                 elif model_path in test_list_B:\n",
    "#                     plt.scatter(HPC_w[0+t,i],HPC_w[40+t,i],color=\"b\",alpha=0.1)\n",
    "# #                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"b\",alpha=0.1)\n",
    "#                 else:\n",
    "#                     plt.scatter(HPC_w[0+t,i],HPC_w[40+t,i],color=\"g\",alpha=0.1)\n",
    "# #                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"g\",alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## test for weight structure ###############\n",
    "\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "# model_list = glob.glob('model/R20_cont/*OUT1*s*_100_?.pth')\n",
    "model_list = glob.glob('model/R20_cont_add/*OUT1*s*_100_*.pth')\n",
    "# model_list = glob.glob('model/R20/*s4_100_1_*.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"attract1_list.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "# with open(\"attract_contfail_test_list.txt\") as f:\n",
    "with open(\"attract_contfail_list_add_test.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "# with open(\"attract_contgood_test_list.txt\") as f:\n",
    "with open(\"attract_contgood_list_add_test.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "    \n",
    "    \n",
    "test_list_A_selected = []\n",
    "test_list_B_selected = []\n",
    "test_list_A_limited = []\n",
    "test_list_B_limited = []\n",
    "\n",
    "for model_path in model_list:\n",
    "    if model_path in test_list_A:\n",
    "        test_list_A_selected.append(model_path)\n",
    "    if model_path in test_list_B:\n",
    "        test_list_B_selected.append(model_path)            \n",
    "\n",
    "if len(test_list_A_selected) > len(test_list_B_selected):\n",
    "    random_num = np.random.randint(0,len(test_list_A_selected),len(test_list_B_selected))\n",
    "    for i in random_num:\n",
    "        test_list_A_limited.append(test_list_A_selected[i])\n",
    "    test_list_B_limited = test_list_B_selected\n",
    "else:\n",
    "    random_num = np.random.randint(0,len(test_list_B_selected),len(test_list_A_selected))\n",
    "    for i in random_num:\n",
    "        test_list_B_limited.append(test_list_B_selected[i])\n",
    "    test_list_A_limited = test_list_A_selected\n",
    "\n",
    "# limited_number = 0\n",
    "# if limited_number > 0:\n",
    "#     random_num = np.random.randint(0,len(test_list_A_selected),limited_number)\n",
    "#     for i in random_num:\n",
    "#         test_list_A_limited.append(test_list_A_selected[i])\n",
    "#     random_num = np.random.randint(0,len(test_list_B_selected),limited_number)\n",
    "#     for i in random_num:\n",
    "#         test_list_B_limited.append(test_list_B_selected[i])\n",
    "# else:\n",
    "#     test_list_A_limited = test_list_A_selected\n",
    "#     test_list_B_limited = test_list_B_selected\n",
    "    \n",
    "\n",
    "# test_list = glob.glob('model/R20_cont/*s8*_100_1_*.pth')\n",
    "# # test_list = lines\n",
    "# test_list = sorted(test_list)\n",
    "# test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list_A = np.array([np.ones(6)])\n",
    "PCA_list_B = np.array([np.ones(6)])\n",
    "\n",
    "path_namelist_A = []\n",
    "path_namelist_B = []\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "fig = plt.figure()\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "                \n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "#     HPC_allw = HPC_inw[0:20]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "    PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "    PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "    Re_allw  = Re_w[:,0:20]\n",
    "    Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw)\n",
    "#     all_uw,all_uv = LA.eig(Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * Re_allw2 + PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw * Re_allw2 + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw * Re_allw * HPC_allw + PFC_allw2 * Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw @ Re_allw @ HPC_allw + PFC_allw2 @ Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(np.pad(Out_w[:,:],[(0,18),(0,0)]))\n",
    "#     all_uw,all_uv = LA.eig(Out_w[:,:]@(HPC_w[0:20,:2]*HPC_w[40:60,:2]))\n",
    "\n",
    "#     uvr,uw,uvl = np.linalg.svd(Re_inw,full_matrices=False)\n",
    "#     uvr,uw,uvl = np.linalg.svd(PFC_inw,full_matrices=False)\n",
    "#     print(uw)\n",
    "    ranknum = 0\n",
    "    plt.xlim(-0.4,0.4)\n",
    "    plt.ylim(-0.6,0.6)\n",
    "    for t in range(1):\n",
    "        for i in range(20):\n",
    "            for k in range(1):\n",
    "#                 plt.scatter(uvr[i,ranknum],uvl.T[i,ranknum],color=color,alpha=0.3)\n",
    "#                 plt.scatter(HPC_w[i,1],uvl.T[i,ranknum],color=color,alpha=0.3)\n",
    "#                 plt.scatter(HPC_w[i,0],uvr.T[i,ranknum],color=color,alpha=0.3)\n",
    "                if model_path in test_list_A_limited:\n",
    "                    uvr,uw,uvl = np.linalg.svd(PFC_inw[:60],full_matrices=False)\n",
    "                    plt.scatter(uvr[i,ranknum],uvl.T[i,ranknum],color=\"r\",alpha=0.1)\n",
    "#                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"r\",alpha=0.1)\n",
    "#                     plt.scatter(0,HPC_w[20+t,i],color=\"r\",alpha=0.1)\n",
    "                    pass\n",
    "                elif model_path in test_list_B_limited:\n",
    "                    uvr,uw,uvl = np.linalg.svd(PFC_inw[:60],full_matrices=False)\n",
    "                    plt.scatter(uvr[i,ranknum],uvl.T[i,ranknum],color=\"b\",alpha=0.1)\n",
    "#                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"b\",alpha=0.1)\n",
    "#                     plt.scatter(1,HPC_w[20+t,i],color=\"b\",alpha=0.1)\n",
    "                    pass\n",
    "\n",
    "#                 else:\n",
    "#                     plt.scatter(uvr[i,ranknum],uvl.T[i,ranknum],color=\"g\",alpha=0.1)\n",
    "# #                     plt.scatter(HPC_w[0+t,i],Out_w[k,t],color=\"g\",alpha=0.1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######　面倒なんで別枠にしたelseテスト用\n",
    "\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "# model_list = glob.glob('model/R20_cont/*OUT1**s*_100_?.pth')\n",
    "# model_list = glob.glob('model/R20_131/*OUT1**s*_100_*epoch*.pth')\n",
    "# model_list = glob.glob('model/R20_cont_add/*OUT1**s*_100_5_*epoch???.pth')\n",
    "model_list = glob.glob('model/R20_uniPFC/*s*_100_?_*epoch*.pth')\n",
    "model_list = glob.glob('model/R20_uniPFCHPC_151/*s*_100_?_*epoch*.pth')\n",
    "# model_list = glob.glob('model/R20_uniPFC_131/*s*_100_?_*epoch*.pth')\n",
    "# model_list = glob.glob('model_test/average_abs/*.pth')\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "with open(\"attract2_list.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "with open(\"attract_contfail_list.txt\") as f:\n",
    "    test_list_A = f.read().splitlines()\n",
    "# with open(\"attract_contgood_list_add.txt\") as f:\n",
    "# with open(\"model/R20_131/good_list.txt\") as f:\n",
    "# with open(\"model/R20_uniPFC_131/good_list.txt\") as f:\n",
    "with open(\"model/R20_uniPFCHPC_151/good_list.txt\") as f:\n",
    "    test_list_B = f.read().splitlines()\n",
    "\n",
    "# test_list = glob.glob('model/R20/*s1*_100_2*.pth')\n",
    "test_list = glob.glob('model/R20_cont/*OUT1*s*_100_*.pth')\n",
    "# test_list = glob.glob('model_test/4_2/*.pth')\n",
    "# test_list = lines\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# target = [11,12,-2]\n",
    "# target = [21,22,23]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig_eigen = plt.figure()\n",
    "fig_eigenval = fig_eigen.add_subplot(111)\n",
    "test_colors = []\n",
    "\n",
    "fig3d = plt.figure()\n",
    "ax3d = Axes3D(fig3d)\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list_A = np.array([[0,1,2,3,4]])\n",
    "PCA_list_B = np.array([[0,1,2,3,4]])\n",
    "\n",
    "average_list = []\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "#     rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN_uniPFCHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_initw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_initw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\" or n == \"Re.weight\":\n",
    "                Re_initw = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Output_initw = np.array(p.data)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"HPC.weight_hh\":\n",
    "                HPC_inw = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = np.array(p.data)\n",
    "            if n == \"PFC.bias_ih\":\n",
    "                PFC_b = np.array(p.data)\n",
    "            if n == \"PFC.bias_hh\":\n",
    "                PFC_inb = np.array(p.data)\n",
    "            if n == \"HPC.bias_ih\":\n",
    "                HPC_b = np.array(p.data)\n",
    "            if n == \"HPC.bias_hh\":\n",
    "                HPC_inb = np.array(p.data)\n",
    "            if n == \"Re.bias_ih\":\n",
    "                Re_b = np.array(p.data)\n",
    "            if n == \"Re.bias_hh\":\n",
    "                Re_inb = np.array(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                Out_w = np.array(p.data)\n",
    "    \n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w>0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw>0]),bins=40,density=True)\n",
    "# #     fig1.plot((make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w<0]),bins=80,density=True)\n",
    "# #     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw<0]),bins=40,density=True)\n",
    "#     PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "#     PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     PFC_hist = np.histogram(np.abs(np.append(PFC_w[PFC_w.nonzero()],PFC_inw[PFC_inw.nonzero()])),bins=40,density=True)\n",
    "# #     PFC_b_hist = np.histogram(np.abs(PFC_b[PFC_b.nonzero()]),bins=80,density=True)\n",
    "# #     PFC_inb_hist = np.histogram(np.abs(PFC_inb[PFC_inb.nonzero()]),bins=40,density=True)\n",
    "# #     fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01),color=color)\n",
    "#     fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01),color=color)\n",
    "# #     fig1.plot((make_bins(PFC_hist[1])),np.log(PFC_hist[0]))\n",
    "#     a1 = regression(make_bins(PFC_w_hist[1]),np.log(PFC_w_hist[0]+0.01))\n",
    "#     a2 = regression(make_bins(PFC_inw_hist[1]),np.log(PFC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     HPC_w_hist = np.histogram(HPC_w[HPC_w>0],bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(HPC_inw[HPC_inw>0],bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w<0]),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw<0]),bins=40,density=True)\n",
    "#     HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "#     HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "# #     HPC_w_hist = np.histogram(np.abs(HPC_w),bins=80,density=True)\n",
    "# #     HPC_inw_hist = np.histogram(np.abs(HPC_inw),bins=40,density=True)\n",
    "# #     fig2.plot((make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]))\n",
    "# #     fig2.plot((make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]))\n",
    "# #     fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01),color=color)\n",
    "#     fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01),color=color)\n",
    "#     b1 = regression(make_bins(HPC_w_hist[1]),np.log(HPC_w_hist[0]+0.01))\n",
    "#     b2 = regression(make_bins(HPC_inw_hist[1]),np.log(HPC_inw_hist[0]+0.01))\n",
    "\n",
    "\n",
    "# #     Re_w_hist = np.histogram(Re_w[Re_w>0],bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(Re_inw[Re_inw>0],bins=100,density=True)\n",
    "# #     Re_w_hist = np.histogram(np.abs(Re_w[Re_w<0]),bins=100,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw<0]),bins=20,density=True)\n",
    "#     Re_w_hist = np.histogram(np.abs(Re_w[Re_w.nonzero()]),bins=40,density=True)\n",
    "#     Re_inw_hist = np.histogram(np.abs(Re_inw[Re_inw.nonzero()]),bins=40,density=True)\n",
    "# #     Re_inw_hist = np.histogram(np.abs(Re_inw),bins=40,density=True)\n",
    "#     Re_initw_hist = np.histogram(np.abs(Re_initw),bins=40,density=True)\n",
    "#     fig3.plot(np.log(make_bins(Re_w_hist[1])),np.log(Re_w_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_inw_hist[1])),np.log(Re_inw_hist[0]+0.01),color=color)\n",
    "# #     fig3.plot(np.log(make_bins(Re_initw_hist[1])),np.log(Re_initw_hist[0]+0.01))\n",
    "#     c1 = regression(make_bins(Re_w_hist[1]),np.log(Re_w_hist[0]+0.01))\n",
    "#     c2 = regression(make_bins(Re_inw_hist[1]),np.log(Re_inw_hist[0]+0.01))\n",
    "    \n",
    "#     Re_uw,Re_uv = LA.eig(Re_w[:,20:])\n",
    "#     fig_eigenval.plot(Re_inuw.real,Re_inuw.imag,\"o\",color=color)\n",
    "#     print(Re_inuw)\n",
    "#     print(np.count_nonzero(Re_uw.real>0))\n",
    "#     print(np.count_nonzero(Re_uw.imag==0))\n",
    "#     print(np.count_nonzero((Re_uw.imag==0)*(Re_uw.real>0)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    PFC_inuw,PFC_inuv = LA.eig(PFC_inw[i:i+20])\n",
    "#     print(PFC_inuw,PFC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=testcolor,zorder=2)\n",
    "#     else :\n",
    "#         fig_eigenval.plot(PFC_inuw.real,PFC_inuw.imag,\"o\",color=color,alpha=0.01,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(PFC_inuw.real[k],PFC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(PFC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(PFC_inuw.real>0))\n",
    "#     print(np.count_nonzero(PFC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((PFC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "    i = 0\n",
    "    HPC_inuw,HPC_inuv = LA.eig(HPC_inw[i:i+20])\n",
    "#     print(HPC_inuw,HPC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "# #     elif num < 40:\n",
    "# #         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=\"b\",alpha=1)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_inuw.real,HPC_inuw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     for k in range(20):\n",
    "#         fig_eigenval.text(HPC_inuw.real[k],HPC_inuw.imag[k],k)\n",
    "#     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(HPC_inuw.real>0))\n",
    "#     print(np.count_nonzero(HPC_inuw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_inuw.imag==0)*(HPC_inuw.real>0)))\n",
    "    \n",
    "    HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,2:],[(0,0),(0,0)]))\n",
    "#     HPC_uw,HPC_uv = LA.eig(np.pad(HPC_w[i:i+20,:2],[(0,0),(0,18)]))\n",
    "#     print(HPC_uw,HPC_uv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "#     else:\n",
    "#         fig_eigenval.plot(HPC_uw.real,HPC_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "#     print(np.count_nonzero(HPC_uw.real>0))\n",
    "#     print(np.count_nonzero(HPC_uw.imag==0))\n",
    "#     print(np.count_nonzero((HPC_uw.imag==0)*(HPC_uw.real>0)))\n",
    "\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+2*HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]\n",
    "    HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]+HPC_inw[0:20]*HPC_w[40:60,2:]+HPC_w[0:20,2:]*HPC_inw[40:60]+HPC_inw[0:20]*HPC_inw[40:60]\n",
    "#     HPC_allw = HPC_w[0:20,2:]*HPC_w[40:60,2:]\n",
    "#     HPC_allw = HPC_inw[0:20]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+2*PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]\n",
    "    PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]+PFC_inw[0:20]*PFC_w[40:60,:20]+PFC_w[0:20,:20]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]+PFC_inw[0:20]*PFC_w[40:60,20:]+PFC_w[0:20,20:]*PFC_inw[40:60]+PFC_inw[0:20]*PFC_inw[40:60]\n",
    "#     PFC_allw = PFC_w[0:20,:20]*PFC_w[40:60,:20]\n",
    "#     PFC_allw2 = PFC_w[0:20,20:]*PFC_w[40:60,20:]\n",
    "#     Re_allw  = Re_w[:,0:20] + Re_w[:,20:] + Re_inw\n",
    "    Re_allw  = Re_w[:,0:20] + Re_inw\n",
    "#     Re_allw2  = Re_w[:,20:] + Re_inw\n",
    "#     Re_allw  = Re_w[:,0:20]\n",
    "#     Re_allw2  = Re_w[:,20:]\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw)\n",
    "    all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(Re_inw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * Re_allw2 + PFC_allw2 * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw2 @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw * Re_allw2 + HPC_allw * PFC_allw * Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[0:20]*HPC_inw[40:60] + HPC_allw @ Re_allw2 + HPC_allw @ PFC_allw @ Re_allw)\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw * Re_allw * HPC_allw + PFC_allw2 * Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(PFC_allw @ Re_allw @ HPC_allw + PFC_allw2 @ Re_allw + PFC_inw[0:20]*PFC_inw[40:60])\n",
    "#     all_uw,all_uv = LA.eig(np.pad(Out_w[:,:],[(0,18),(0,0)]))\n",
    "#     all_uw,all_uv = LA.eig(Out_w[:,:]@(HPC_w[0:20,:2]*HPC_w[40:60,:2]))\n",
    "#     all_uw,all_uv = LA.eig(np.pad(HPC_w[20:40,:2],[(0,0),(0,18)]))\n",
    "#     all_uw,all_uv = LA.eig(HPC_inw[20:40])\n",
    "# #     print(HPC_inuw,HPC_inuv)\n",
    "#     if model_path in test_list:\n",
    "#         testnum+=1\n",
    "#         testcolor=cm.jet(testnum/len(test_list))\n",
    "# #         testcolor = \"r\"\n",
    "#         test_colors.append(testnum/len(test_list))\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=testcolor,alpha=1,zorder=2)\n",
    "#         print(model_path)\n",
    "# #         print(all_uw)\n",
    "# #         print(all_uv.T)\n",
    "# #         print(np.count_nonzero(all_uw.real>0))\n",
    "# #         print(np.count_nonzero(all_uw.imag==0))\n",
    "# #         print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "# #         print(np.average(abs(all_uw)))\n",
    "# #         for k in range(20):\n",
    "# #             fig_eigenval.text(all_uw.real[k],all_uw.imag[k],str(model_path.split(\"epoch\")[-1].split(\".\")[0]))\n",
    "#     else:\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=color,alpha=0.1,zorder=1)\n",
    "        \n",
    "    if model_path in test_list_B:\n",
    "#         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [1],\"o\", color = \"b\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))],[np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"b\", alpha=0.1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",alpha=0.3,zorder=2)\n",
    "        fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"b\",alpha=0.3,zorder=2)\n",
    "#         print(model_path,\"good\")\n",
    "#         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "#         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "        PCA_list_B = np.concatenate((PCA_list_B,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#         fig_eigenval.text(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],str(model_path.split(\"s\")[-1]))\n",
    "#         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"s\")[-1]))\n",
    "    else:\n",
    "#         ax3d.plot([np.count_nonzero(all_uw.real>0)], [np.count_nonzero(all_uw.imag==0)], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [0],\"o\", color = \"r\", alpha=0.1)\n",
    "#         ax3d.plot([np.count_nonzero((all_uw.imag==0)*(all_uw.real>0))], [np.count_nonzero((all_uw.imag==0)*(all_uw.real<0))], [np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0))],\"o\", color = \"r\", alpha=0.1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",color=\"r\",alpha=0.3,zorder=1)\n",
    "#         fig_eigenval.plot(all_uw.real,all_uw.imag,\"o\",alpha=0.3,zorder=1)\n",
    "        fig_eigenval.plot(np.average(abs(all_uw)),np.max(abs(all_uw)),\"o\",color=\"r\",alpha=0.3,zorder=2)\n",
    "#         print(model_path,\"bad\")\n",
    "#         print([np.average(abs(all_uw)),np.max(all_uw.real),np.min(all_uw.real)])\n",
    "#         print([np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))])\n",
    "        PCA_list_A = np.concatenate((PCA_list_A,[[np.count_nonzero((all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)), np.count_nonzero((all_uw.imag==0)*(all_uw.real<0)), np.count_nonzero((all_uw.imag!=0)*(all_uw.real>0)),np.count_nonzero((all_uw.imag!=0)*(all_uw.real<0))]]),axis=0)\n",
    "#         fig_eigenval.text(all_uw.real[np.argmax(abs(all_uw))],all_uw.imag[np.argmax(abs(all_uw))],str(model_path.split(\"s\")[-1]))    \n",
    "#         fig_eigenval.text(np.average(abs(all_uw)),np.max(abs(all_uw)),str(model_path.split(\"epoch\")[-1]))      \n",
    "    \n",
    "# #     print(LA.matrix_rank(HPC_inw[i:i+20]))\n",
    "#     print(np.count_nonzero(all_uw.real>0))\n",
    "#     print(np.count_nonzero(all_uw.imag==0))\n",
    "#     print(np.count_nonzero((all_uw.imag==0)*(all_uw.real>0)))\n",
    "    \n",
    "    average_list.append(np.average(abs(all_uw)))\n",
    "    \n",
    "#     PCA_list = np.concatenate((PCA_list,[[a1,a2,c2]]),axis=0)\n",
    "#     print(a1-a2)\n",
    "    \n",
    "#     fig1.hist(PFC_w[PFC_w>0],bins=40,alpha=0.5,density=True)\n",
    "#     fig1.hist(np.abs(PFC_w[PFC_w<0]),bins=40,alpha=0.5,density=True)\n",
    "#     fig2.hist(HPC_w[HPC_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig2.hist(np.abs(HPC_w[HPC_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(Re_w[Re_w>0],bins=40,alpha=0.5,log=True,density=True)\n",
    "#     fig3.hist(np.abs(Re_w[Re_w<0]),bins=40,alpha=0.5,log=True,density=True)\n",
    "\n",
    "# # # print(PCA_list[1:])\n",
    "# PCA_list = np.concatenate((PCA_list_A[1:],PCA_list_B[1:]),axis=0)\n",
    "# length = PCA_list_A[1:].shape[0]\n",
    "# pca = PCA()\n",
    "# dfs = PCA_list\n",
    "# pca.fit(dfs)\n",
    "# feature = pca.transform(dfs)\n",
    "# # print(length,feature)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(feature[:length, 0], feature[:length, 1], color=\"r\",alpha=0.2)\n",
    "# plt.scatter(feature[length:, 0], feature[length:, 1], color=\"b\",alpha=0.2)\n",
    "# #plt.scatter(feature[100:200, 0], feature[100:200, 1], alpha=0.8)\n",
    "# plt.grid()\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# # for i,n in enumerate(target_list):\n",
    "# #     plt.annotate(n[-12:],(feature[i, 0], feature[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "# print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "# print(pd.DataFrame(pca.components_, columns=[\"Hidden{}\".format(x + 1) for x in range(dfs.shape[1])], index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "    \n",
    "\n",
    "# fig3d = plt.figure()\n",
    "# ax3d = Axes3D(fig3d)\n",
    "# ax3d.plot(feature[:length, 0], feature[:length, 1], feature[:length, 2], \"o\", alpha=0.1)\n",
    "# ax3d.plot(feature[length:, 0], feature[length:, 1], feature[length:, 2], \"o\", alpha=0.1)\n",
    "# plt.show()\n",
    "\n",
    "# gradient = np.array(test_colors)\n",
    "# gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(gradient, cmap=plt.cm.jet)\n",
    "# ax.set_axis_off()\n",
    "print(np.count_nonzero(np.array(average_list)<0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############  compare list 作成用  ######################\n",
    "\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    \n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        hidden1 = self.LSTM1(input, hiddens[0])\n",
    "        hidden2 = self.LSTM2(hidden1[0], hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "\n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.2, torch.rand(self.batch_size, self.hidden_size)*0.2]\n",
    "        return [hidden,hidden]    \n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "def check_bifur_posi(data):\n",
    "    data = data - 0.5\n",
    "    positive = np.count_nonzero(data>=0)\n",
    "    negative = np.count_nonzero(data<0)\n",
    "    \n",
    "    return np.abs(positive - negative)\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "# model_list = glob.glob('model/R20_cont_add/*OUT1**s*_100_*.pth')\n",
    "# model_list = glob.glob('model/compare_cont/*s*_100_??.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "\n",
    "test_list = glob.glob('model/R20/*s1*_100_1_*.pth')\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# # target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# # target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# # target = [11,12,-2]\n",
    "# # target = [19,20,21,22]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "# f = open(\"compare_contgood_list_add.txt\",mode=\"w\")\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig = plt.figure()\n",
    "test_colors = []\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list = np.array([[0,1,2]])\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    \n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 7\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "#     print(bifur,check_bifur)\n",
    "#     print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "    if bifur.shape[0] == 0:\n",
    "        continue\n",
    "#     if np.var(bifur) < np.abs(np.median(bifur)-np.mean(bifur)) or np.var(bifur) < 0.0001:\n",
    "# #     if np.abs(np.median(bifur)-np.mean(bifur)) < 0.0001 and np.var(bifur) < 0.0001:\n",
    "# #         print(model_path)\n",
    "# #         f.write(model_path+\"\\n\")\n",
    "#         pass\n",
    "#     else:\n",
    "#         print(model_path)\n",
    "#         plt.plot(np.log(np.var(bifur)),np.log(np.median(bifur)-np.mean(bifur)),\"o\")\n",
    "#         print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "#         f.write(model_path+\"\\n\")\n",
    "# #         pass\n",
    "\n",
    "    if np.var(bifur) > 0.0001:\n",
    "#     if np.abs(np.median(bifur)-np.mean(bifur)) < 0.0001 and np.var(bifur) < 0.0001:\n",
    "        print(model_path)\n",
    "        print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)),check_bifur_posi(bifur))\n",
    "#         print(np.median(bifur),np.mean(bifur),bifur)\n",
    "#         pass\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### imihu test ####################\n",
    "\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import matplotlib.cm as cm\n",
    "import numpy.linalg as LA\n",
    "\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.normal_(self.PFC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_ih.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_ih.data,0,0.1)\n",
    "        nn.init.normal_(self.PFC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.HPC.weight_hh.data,0,1)\n",
    "        nn.init.normal_(self.Re.weight_hh.data,0,0.1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def regression(datax,datay):\n",
    "    clf = linear_model.LinearRegression()\n",
    "    x = datax[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    y = datay[datay!=-float(\"inf\")].reshape(-1,1)\n",
    "    clf.fit(x,y)\n",
    "    coef = clf.coef_\n",
    "    score = clf.score(x,y)\n",
    "    print(coef,score)\n",
    "    return coef[0][0]\n",
    "\n",
    "def check_bifur_posi(data):\n",
    "    data = data - 0.5\n",
    "    positive = np.count_nonzero(data>=0)\n",
    "    negative = np.count_nonzero(data<0)\n",
    "    \n",
    "    return np.abs(positive - negative)\n",
    "\n",
    "\n",
    "\n",
    "# model_list = glob.glob('model/ReModel_interRNN_long_s5_200_1.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_OUT5_1212121_s*_100_1_2_2.pth')\n",
    "# model_list = glob.glob('model/ReModel_L2_interRNNrand_AddRe_PnoiseRe_OUT5_161_s*_100_4.pth')\n",
    "# model_list = glob.glob('model/R+2/*s2*_100_1*.pth')\n",
    "# model_list = glob.glob('model/P+/*s3_100_1*add.pth')\n",
    "# model_list = glob.glob('model/R20/*s*_100_*.pth')\n",
    "model_list = glob.glob('model/R20_cont_add/*OUT1**s*_100_*epoch??.pth')\n",
    "\n",
    "\n",
    "model_list = sorted(model_list)\n",
    "model_list = sorted(model_list,key=len,reverse=False)\n",
    "\n",
    "# print(model_list)\n",
    "\n",
    "test_list = glob.glob('model/R20/*s1*_100_1_*.pth')\n",
    "test_list = sorted(test_list)\n",
    "test_list = sorted(test_list,key=len,reverse=False)[:]\n",
    "\n",
    "# # target = [1,3,4,11,12,13,16,-2,-1]\n",
    "# # target = [0,2,5,6,7,8,9,10,14,15,17]\n",
    "# # target = [11,12,-2]\n",
    "# # target = [19,20,21,22]\n",
    "# test_target = []\n",
    "\n",
    "# for i in target:\n",
    "#     test_target.append(test_list[i])\n",
    "# test_list = test_target\n",
    "\n",
    "# print(test_list)\n",
    "\n",
    "training_size = 100\n",
    "test_size = 1000\n",
    "epochs_num = 10\n",
    "hidden_size = 20\n",
    "batch_size = 10\n",
    "data_length = 100\n",
    "inputsize = 2\n",
    "outputsize = 2\n",
    "\n",
    "fig_weight = plt.figure(figsize=(10,5))\n",
    "fig1 = fig_weight.add_subplot(131)\n",
    "fig2 = fig_weight.add_subplot(132)\n",
    "fig3 = fig_weight.add_subplot(133)\n",
    "\n",
    "# target = [22,23,-2,-1]\n",
    "# target_list = []\n",
    "\n",
    "# for i in target:\n",
    "#     target_list.append(model_list[i])\n",
    "\n",
    "fig = plt.figure()\n",
    "test_colors = []\n",
    "\n",
    "target_list = model_list[:]\n",
    "PCA_list = np.array([[0,1,2]])\n",
    "\n",
    "testnum = 0\n",
    "num=0\n",
    "for model_path in target_list:\n",
    "    num+=1\n",
    "    color=cm.jet(num/len(target_list))\n",
    "#     print(model_path)\n",
    "    \n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 7\n",
    "    est_length = 8\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "#     print(bifur,check_bifur)\n",
    "\n",
    "    if bifur.shape[0] == 0:\n",
    "        continue\n",
    "    if np.var(bifur) > 0.0001:\n",
    "#     if np.abs(np.median(bifur)-np.mean(bifur)) < 0.0001 and np.var(bifur) < 0.0001:\n",
    "        print(model_path)\n",
    "        print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)),check_bifur_posi(bifur))\n",
    "#         print(np.median(bifur),np.mean(bifur),bifur)\n",
    "#         pass\n",
    "    else:\n",
    "#         print(model_path)\n",
    "#         plt.plot(np.log(np.var(bifur)),np.log(np.median(bifur)-np.mean(bifur)),\"o\")\n",
    "#         print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "#         f.write(model_path+\"\\n\")\n",
    "        pass\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## uni PFC test ################\n",
    "\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "#             traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "#     order = [1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_delay_num(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(int(start))\n",
    "        start = int(k)\n",
    "    states_list.append(int(start))\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "#         HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.05\n",
    "        index = np.array([11])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.ones(self.batch_size, index.size)*100\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.ones(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "class MyLSTM_RNN_uniPFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "    \n",
    "    \n",
    "class MyLSTM_RNN_uniHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = hiddens[0][0]\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "\n",
    "class MyLSTM_RNN_uniPFCHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_RNN_uniPFCHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size+0\n",
    "        self.hidden_size_HPC = hidden_size+0\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.Re.weight_hh.data,sparse)\n",
    "        # nn.init.normal_(self.PFC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_ih.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_ih.data,0,0.1/10)\n",
    "        # nn.init.normal_(self.PFC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.HPC.weight_hh.data,0,1/10)\n",
    "        # nn.init.normal_(self.Re.weight_hh.data,0,1/10)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = hiddens[0][0]\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0.02\n",
    "        v = 0.02\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*v\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*c\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def hidden_size_list(self):\n",
    "        return [self.hidden_size_PFC,self.hidden_size_HPC,self.hidden_size_Re]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(9)/9\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 5\n",
    "\n",
    "    colors = ['C0','C1','C2','C3','C4','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s4_100_2_epoch115.pth'\n",
    "#     model_path = 'model/R20_uniPFC/ReModel_L2_interRNNrand_OUT1_uniPFC_151_s1_100_3_epoch195.pth'\n",
    "#     model_path = 'model/R20_uniHPC_151/ReModel_L2_interRNNrand_OUT1_uniHPC_151_s1_100_1_epoch185.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s1_100_2_epoch195.pth'\n",
    "#     model_path = 'model/R20_uniPFCHPC_151/ReModel_L2_interRNNrand_OUT1_uniPFCHPC_151_s3_100_2_epoch135.pth'\n",
    "    model_path = 'model/R20_traintest/ReModel_L2_interRNNrand_OUT1_131_s1_100_1_epoch50.pth'\n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s5_100_1_epoch85.pth'\n",
    "#     model_path = 'model/R20_slow_bigbatch/ReModel_L2_interRNNrand_OUT1_131_s6_100_3_epoch115.pth'\n",
    "\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 87\n",
    "    est_length = 4\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            output,hidden = rnn(output,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    print(np.array(Gate_states).shape)\n",
    "            \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_a = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_a = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_a = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_a = np.array(p.data)\n",
    "                \n",
    "    delays = pick_delay_num(traj[:,0], np.array(Restate)[:])\n",
    "    \n",
    "#     model_path = 'model/R20/ReModel_L2_interRNNrand_OUT5_151_s2_100_1_epoch100.pth'\n",
    "#     model_path = 'model/R20_cont/ReModel_L2_interRNNrand_OUT1_151_s4_100_2_epoch125.pth'\n",
    "#     model_path = 'model/R20_Retrain/ReModel_L2_interRNNrand_OUT5_151_s4_100_1_TrainOUT_epoch0.pth'\n",
    "#     model_path = 'model/R20_uniPFC/ReModel_L2_interRNNrand_OUT1_uniPFC_151_s1_100_1_epoch195.pth'\n",
    "#     model_path = 'model/R20_cont_add/ReModel_L2_interRNNrand_OUT1_151_s1_100_2_epoch195.pth'\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "#     for n, p in rnn.named_parameters():\n",
    "#         if n == \"HPC.weight_ih\":\n",
    "#             p.data[inputsize:,hidden_size:].sub_(p.data[inputsize:,hidden_size:])\n",
    " \n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "#     data_limit = 20\n",
    "    init_point = init_point*1\n",
    "    Delayflag = False\n",
    "    Delaynum = 0\n",
    "    Delaytime = 0\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    for k in range(data.shape[0]*est_length):\n",
    "            if traj_noise[-1][0][1] < 0.1:\n",
    "                Delayflag = True\n",
    "#                 startpoint = delays[Delaynum]\n",
    "                for cell in range(20):\n",
    "#                     print(hidden[2][0][cell+0],np.array(Restate)[int(delays[Delaynum])+Delaytime,cell+0]-moving_average(np.array(Restate)[:,cell+0])[4+int(delays[Delaynum])+Delaytime])\n",
    "#                     hidden[2][0][cell+8] = np.average(np.array(Restate_noise)[-6:,cell+8])\n",
    "#                     hidden[2][0][cell+8] = np.average(np.array(Restate)[k-5+data_limit:k+5+data_limit,cell+8])\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[4+k+data_limit]\n",
    "#                     hidden[2][0][cell+0] = moving_average(np.array(Restate)[:,cell+0])[4+int(delays[Delaynum])+Delaytime]\n",
    "#                     hidden[2][0][cell+0] = np.array(Restate)[startpoint+Delaytime,cell+0]-moving_average(np.array(Restate)[:,cell+0])[4+startpoint+Delaytime]\n",
    "                    hidden[2][0][cell+0] = np.array(Restate)[k+data_limit,cell+0] - moving_average(np.array(Restate)[:,cell+0])[4+k+data_limit]\n",
    "                Delaytime += 1\n",
    "            hidden = rnn.noiseHidden_rand(hidden)\n",
    "            hidden = rnn.noiseHidden_select(hidden)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "#             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "#             hidden = rnn.noiseHidden_rand(hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "            if Delayflag == True and traj_noise[-1][0][1] > 0.1:\n",
    "                Delayflag = False\n",
    "                Delaynum += 1\n",
    "                Delaytime = 0\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:,0,0],traj[:,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "    plt.show()\n",
    "\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "        plt.plot(traj[:,0,0],alpha=0.5)\n",
    "        plt.plot(traj_noise[:,0,0],alpha=0.5)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "            plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "            plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])[2:],alpha=1)\n",
    "#             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "#             plt.plot(np.array(Restate)[:,i]-moving_average(np.array(Restate)[:,i])[4:-4],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "#             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "#             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:300,i],alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate)[:300,i]),alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate_noise)[:300,i]),alpha=0.5)\n",
    "#         plt.title(\"HPCneuron#\"+str(i+1))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     a = np.abs(np.corrcoef(np.array(PFCstate)[:,0].T) - np.corrcoef(np.array(PFCstate_noise)[:,0].T))\n",
    "# #     a = np.abs(np.corrcoef(np.array(Restate)[:].T) - np.corrcoef(np.array(Restate_noise)[:].T))\n",
    "#     plt.imshow(a,cmap=plt.get_cmap(\"Reds\"))\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "    delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "    bifur = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        plt.ylim(-1,1)\n",
    "#         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "        for data in delays[1:-1]:\n",
    "#             plt.plot(np.array(data)[:,0+i,0],alpha=0.5)\n",
    "            plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "            print(len(data))\n",
    "#             check_bifur = np.argmax(np.abs(np.array(data)[:,0+i,0] - 0.5))\n",
    "#             bifur = np.append(bifur,data[check_bifur,i,0])\n",
    "#             print(check_bifur,data[check_bifur,i,0])\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         for k in range(1):\n",
    "#             k+=0\n",
    "#             data = PFC_w_a[i]\n",
    "#             plt.plot(data)\n",
    "#             data = PFC_w_b[i]\n",
    "#             plt.plot(data)\n",
    "\n",
    "#     length = 140\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(np.array(Restate_noise)[:length,0])\n",
    "# #     plt.show()\n",
    "#     neuron_list = []\n",
    "#     neuron_list_Re = []\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         neurons_a = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "#         neurons_b = np.concatenate((np.array(PFCstate_noise)[:,0],np.array(HPCstate_noise)[:,0]),axis=1)\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(40):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_w_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_w_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_w_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_w_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_w_a[i,k],Re_w_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "            \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         i+=0\n",
    "#         neurons_a = np.array(Restate)[:]\n",
    "#         neurons_b = np.array(Restate_noise)[:]\n",
    "#         plt.plot(np.array(Restate)[:length,i],alpha=0.3)\n",
    "#         plt.plot(np.array(Restate_noise)[:length,i],alpha=0.3)\n",
    "#         plt.ylim(-1,1)\n",
    "#         for k in range(20):\n",
    "#             k += 0\n",
    "#             data_a = neurons_a[:length,k]*Re_inw_a[i,k]\n",
    "#             data_b = neurons_b[:length,k]*Re_inw_b[i,k]\n",
    "#             diff = data_a - data_b\n",
    "#             if np.sum(np.abs(data_a)) > 5 and np.sum(np.abs(data_a)) > 5:\n",
    "#                 print(\"a\",k,Re_inw_a[i,k],np.sum(np.abs(data_a)))\n",
    "#                 plt.plot(data_a)\n",
    "#             if np.sum(np.abs(data_b)) > 5 and np.sum(np.abs(data_b)) > 5:\n",
    "#                 print(\"b\",k,Re_inw_b[i,k],np.sum(np.abs(data_b)))\n",
    "#                 plt.plot(data_b)\n",
    "#             if np.sum(np.abs(diff)) > 5 and np.sum(np.abs(diff)) > 5:\n",
    "#                 print(\"diff\",k,Re_inw_a[i,k],Re_inw_b[i,k],np.sum(np.abs(diff)))\n",
    "#                 neuron_list_Re.append(k+1)\n",
    "# #                 plt.plot(diff)\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[0:,0]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    PFC_feature = np.copy(feature)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "\n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "#     ax3d.plot(feature[:100, 0], feature[:100, 1], feature[:100, 2], alpha=0.8)\n",
    "#     ax3d.plot(feature[100:, 0], feature[100:, 1], feature[100:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2], alpha=0.8)\n",
    "    ax3d.plot(feature[0:1, 0], feature[0:1, 1], feature[0:1, 2],\"o\", alpha=1)\n",
    "    plt.show()\n",
    "\n",
    "#     print(collections.Counter(neuron_list))\n",
    "#     print(collections.Counter(neuron_list_Re))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0],alpha=0.5)\n",
    "    plt.plot(traj_noise[:,0,0],alpha=0.5)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Accuray check ###\n",
    "%matplotlib notebook\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "def epoch_count(path):\n",
    "    epoch_list = np.arange(0,400,5)\n",
    "    epoch_num_list = []\n",
    "    epoch_rate_list = []\n",
    "    with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "        good_list = f.read().splitlines()\n",
    "    for i in epoch_list:\n",
    "        model_list = glob.glob(path+'*epoch'+str(i)+'.pth')\n",
    "        n = 0\n",
    "        for model_path in model_list:\n",
    "            if model_path in good_list:\n",
    "                n+=1\n",
    "        epoch_num_list.append(n)\n",
    "        epoch_rate_list.append(n/len(model_list))\n",
    "    return epoch_num_list,epoch_rate_list\n",
    "\n",
    "def epoch_count_b(path):\n",
    "#     model_list = glob.glob(path+'*OUT1*.pth')\n",
    "#     sparse_max = np.max(np.array(int(model_list.split(\"_s\")[-1].split(\"_100\")[0])))\n",
    "    sparse_max = 10\n",
    "#     index_max = np.max(np.array(int(model_list.split(\"_100_\")[-1].split(\"_epoch\")[0])))\n",
    "    index_max = 10\n",
    "    sparse_list = []\n",
    "    for i in range(sparse_max):\n",
    "        for k in range(index_max):\n",
    "            sparse_list.append(\"s\"+str(i+1)+\"_100_\"+str(k+1))\n",
    "    epoch_num_list = []\n",
    "    epoch_rate_list = []\n",
    "    with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "        good_list = f.read().splitlines()\n",
    "    for i in sparse_list:\n",
    "        n = -1\n",
    "        model_list = glob.glob(path+'*'+str(i)+'_epoch*.pth')\n",
    "        model_list = sorted(model_list)\n",
    "        model_list = sorted(model_list,key=len,reverse=False)\n",
    "        for model_path in model_list:\n",
    "            if model_path in good_list:\n",
    "                n = model_path.split(\"_epoch\")[-1].split(\".pth\")[0]\n",
    "#                 print(n)\n",
    "                break\n",
    "        epoch_num_list.append(int(n))\n",
    "        \n",
    "        \n",
    "# ##### simple version ##########        \n",
    "#     epoch_list = np.arange(0,200,5)\n",
    "#     cumulate = [0]\n",
    "#     cumulate_rate = []\n",
    "# #     modelnum = len(glob.glob(path+'*epoch5.pth'))\n",
    "#     modelnum = len(glob.glob(path+'*100_1_*epoch5.pth'))*index_max\n",
    "#     for k in epoch_list:\n",
    "# #         model_list = glob.glob(path+'*epoch'+str(k)+'.pth')\n",
    "#         cumulate.append(cumulate[-1]+np.count_nonzero(epoch_num_list == k))\n",
    "#         cumulate_rate.append(cumulate[-1]/modelnum)\n",
    "# #         print(modelnum)\n",
    "#     return epoch_num_list, cumulate, cumulate_rate\n",
    "\n",
    "##### divided version ##########\n",
    "    epoch_list = np.arange(0,265,5)\n",
    "    divided_list = []\n",
    "    result_list = []\n",
    "    result_rate_list = []\n",
    "#     modelnum = len(glob.glob(path+'*epoch5.pth'))\n",
    "    divide_num = 5\n",
    "    modelnum = int(len(epoch_num_list)/divide_num)\n",
    "    cumulate_result = np.zeros(epoch_list.size)\n",
    "    cumulate_rate_result = []\n",
    "    \n",
    "#     random.shuffle(epoch_num_list)  # shuffle control\n",
    "    \n",
    "    for i in range(divide_num):\n",
    "        divided_list.append(epoch_num_list[modelnum*i:modelnum*(i+1)])\n",
    "    for epoch_num_divided in divided_list:\n",
    "        cumulate = [0]\n",
    "        cumulate_rate = []\n",
    "        for k in epoch_list:\n",
    "    #         model_list = glob.glob(path+'*epoch'+str(k)+'.pth')\n",
    "            cumulate.append(cumulate[-1]+np.count_nonzero(epoch_num_divided == k))\n",
    "            cumulate_rate.append(cumulate[-1]/modelnum)\n",
    "    #         print(modelnum)\n",
    "        cumulate_result += cumulate[1:]\n",
    "        cumulate_rate_result.append(cumulate_rate)\n",
    "    return divided_list, cumulate, np.mean(cumulate_rate_result,axis=0), np.std(cumulate_rate_result,axis=0)\n",
    "\n",
    "# colorlist = [\"r\",\"#ff7f0e\",\"y\"]\n",
    "colornum = 0\n",
    "plt.figure()\n",
    "plt.ylim(-0.1,1.1)\n",
    "# plotlist = [\"model/R20_cont_add/\",\"model/compare30_151/\",\"model/PFCHPC_30_151/\",\"model/single60_151/\"]\n",
    "# plotlist = [\"model/PFCHPC_30_151/\",\"model/single60_151/\"]\n",
    "# plotlist = [\"model/R20_cont_add/\",\"model/compare_cont/\"]\n",
    "delay_length = 3\n",
    "# plotlist = [\"model/R20_1\"+str(delay_length)+\"1/\",\"model/compare30_1\"+str(delay_length)+\"1/\",\"model/PFCHPC_30_1\"+str(delay_length)+\"1/\"]\n",
    "# plotlist = [\"model/R20_traintest/\",\"model/compare30_traintest/\",\"model/PFCHPC_30_1\"+str(delay_length)+\"1/\"]\n",
    "plotlist = [\"model/R20_traintest/\",\"model/compare30_traintest/\",\"model/PFCHPC30_traintest/\"]\n",
    "# plotlist = [\"model/R20_traintest_bigbatch/\",\"model/compare30_traintest_bigbatch/\",\"model/PFCHPC30_1\"+str(delay_length)+\"1_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_traintest/\",\"model/R20_traintest_bigbatch/\"]\n",
    "# plotlist = [\"model/compare_1\"+str(delay_length)+\"1/\",\"model/compare25_1\"+str(delay_length)+\"1/\",\"model/compare30_1\"+str(delay_length)+\"1/\"]\n",
    "# plotlist = [\"model/R20_H/\",\"model/R20_H_transferB/\",\"model/R20_uniPFC_H/\",\"model/compare30_H/\",\"model/PFCHPC30_H/\"]\n",
    "# plotlist = [\"model/R20_H/\",\"model/R20_H_transferB/\",\"model/compare30_H/\",\"model/PFCHPC_H/\",\"model/compare_transferB/\",\"model/R20_H_transfer2/\",\"model/R20_H_transfer3/\"]\n",
    "# plotlist = [\"model/R20_H/\",\"model/R20_H_transferB/\",\"model/compare30_H/\",\"model/PFCHPC_H/\",\"model/compare_transferB/\",\"model/R20_H_transfer2/\",\"model/R20_H_transfer3/\"]\n",
    "# plotlist = [\"model/R20_H_transfer3/\",\"model/R20_H_transfer3B/\",\"model/compare30_transfer2/\",\"model/compare30_transfer2B/\"]\n",
    "# plotlist = [\"model/R20_H_transfer3/\",\"model/compare30_transfer3/\"]\n",
    "# plotlist = [\"model/R20_cont_add/\",\"model/R20_uniPFC/\",\"model/R20_uniPFCHPC_151/\",\"model/R20_uniHPC_151/\"]\n",
    "# plotlist = [\"model/R20_131/\",\"model/R20_uniPFC_131/\"]\n",
    "# plotlist = [\"model/PFCHPC_30_1\"+str(delay_length)+\"1/\",\"model/PFCHPC_1\"+str(delay_length)+\"1/\"]\n",
    "# plotlist = [\"model/R20_cont_add/\",\"model/R20_uniPFC/\",\"model/R20_uniPFCHPC_151/\",\"model/R20_uniHPC_151/\",\"model/PFCHPC_30_151/\"]\n",
    "# plotlist = [\"model/compare30_H/\",\"model/compare30_transfer3/\",\"model/compare30_transfer3B/\"]\n",
    "# plotlist = [\"model/compare30_transfer/\",\"model/compare30_transfer2/\",\"model/compare30_transfer3/\"]\n",
    "# plotlist = [\"model/R20_H/\",\"model/compare30_H/\",\"model/PFCHPC30_H/\",\"model/R20_uniPFC_H/\"]\n",
    "# plotlist = [\"model/R20_feedReinhReLU_H_bigbatch/\",\"model/compare25_H_bigbatch/\",\"model/PFCHPC25_H_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_traintest_bigbatch/\",\"model/R20_H_bigbatch/\",\"model/compare30_traintest_bigbatch/\",\"model/compare30_H_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_H_bigbatch/\",\"model/compare30_H_bigbatch/\",\"model/PFCHPC30_H_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_H_bigbatch/\",\"model/PFCHPC30_H_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_H_bigbatch/\",\"model/R20_H_uniHPC_bigbatch/\",\"model/R20_H_uniPFC_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_H_bigbatch/\",\"model/R20_H_stopinit_bigbatch/\"]\n",
    "# plotlist = [\"model/R20_H/\",\"model/R20_uniPFC_H/\"]\n",
    "# plotlist = [\"model/R20_131/\",\"model/R20_141/\",\"model/R20_cont_add/\",\"model/R20_161/\",\"model/R20_171/\"]\n",
    "# plotlist = [\"model/compare_131/\",\"model/compare_141/\",\"model/compare_cont/\",\"model/compare_161/\",\"model/compare_171/\"]\n",
    "# plotlist = [\"model/R20_cue_1\"+str(delay_length)+\"1/\",\"model/compare30_cue_1\"+str(delay_length)+\"1/\",\"model/PFCHPC_30_cue_1\"+str(delay_length)+\"1/\",\"model/PFCHPC_30_cue_1to3/\"]\n",
    "# plotlist = [\"model/R20_cue_1\"+str(delay_length)+\"1_smallbatch5/\",\"model/compare30_cue_1\"+str(delay_length)+\"1_smallbatch5/\",\"model/PFCHPC30_cue_1\"+str(delay_length)+\"1_smallbatch5/\"]\n",
    "# plotlist = [\"model/R20_cue_131_1to3/\",\"model/compare30_cue_1to3/\",\"model/PFCHPC_30_cue_1to3/\",\"model/compare30_cue_1to3_cue2/\"]\n",
    "# plotlist = [\"model/R20_cue_1to3_smallbatch5/\",\"model/compare30_cue_1to3_smallbatch5/\",\"model/PFCHPC30_cue_1to3_smallbatch5/\"]\n",
    "# plotlist = [\"model/R20_cue_1to3_smallbatch4/\",\"model/compare30_cue_1to3_smallbatch4/\",\"model/PFCHPC30_cue_1to3_smallbatch4/\"]\n",
    "# plotlist = [\"model/R20_cue_1until3_smallbatch5/\",\"model/compare30_cue_1until3_smallbatch5/\",\"model/PFCHPC30_cue_1until3_smallbatch5/\"]\n",
    "# plotlist = [\"model/R20_cue_1until3_smallbatch4/\",\"model/compare30_cue_1until3_smallbatch4/\",\"model/PFCHPC30_cue_1until3_smallbatch4/\"]\n",
    "# plotlist = [\"model/R20_cue_1until3_smallbatch5_decay/\",\"model/compare30_cue_1until3_smallbatch5_decay/\"]\n",
    "# plotlist = [\"model/R20_traintest/\"]\n",
    "\n",
    "# plotlist = [\"model/R20_traintest/\",\"model/R20_H_bigbatch/\",\"model/R20_cue_1until3_smallbatch5/\"]\n",
    "\n",
    "\n",
    "epoch_list = np.arange(0,265,5)\n",
    "colorlist = [\"C0\",\"C8\",\"C9\"]\n",
    "colornum=0\n",
    "for model in plotlist:\n",
    "    a,b,c,v = epoch_count_b(model)\n",
    "    print(model)\n",
    "    print(a,b,c)\n",
    "#     plt.plot(c)\n",
    "    plt.plot(epoch_list,c,color=colorlist[colornum])\n",
    "    plt.fill_between(epoch_list,c-v,c+v, color=colorlist[colornum], alpha=0.25)\n",
    "    colornum+=1\n",
    "plt.yticks(fontsize=26)\n",
    "plt.xticks(fontsize=26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_maxmodel(path,sparse,indexnum):\n",
    "    model_list = glob.glob(path+'*s'+str(sparse)+'_100_'+str(indexnum)+'_*epoch*.pth')\n",
    "    model_list = sorted(model_list)\n",
    "    model_list = sorted(model_list,key=len,reverse=False)\n",
    "    n = model_list[-1].split(\"_epoch\")[-1].split(\".pth\")[0]\n",
    "    return model_list[-1], int(n)\n",
    "\n",
    "sparse = 1\n",
    "indexnum = 2\n",
    "model_path,past_epochnum = choose_maxmodel(\"model/R20_cont_add/\",sparse,indexnum)\n",
    "print(model_path,past_epochnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########    Test for mixture weight!!!!!!!!!!!!!   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"figure.subplot.left\"] = 0.15\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "#     order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data_limit = 100\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_test()\n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "            Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0],color=colors[-1])\n",
    "    plt.plot(traj_noise[:,0,0],color=colors[-2])\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "    plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "    plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "    plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "    print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,0]-feature[data_limit:,0]))[0,1]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,1]-feature[data_limit:,1]))[0,1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:data_limit,2]-feature[data_limit:,2]))[0,1]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(feature[:data_limit,0]-feature[data_limit:,0]))\n",
    "    plt.plot(np.abs(feature[:data_limit,1]-feature[data_limit:,1]))\n",
    "    plt.plot(np.abs(feature[:data_limit,2]-feature[data_limit:,2]))\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "    plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "    plt.yticks(fontsize=28)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.show()\n",
    "\n",
    "#     print(pd.DataFrame(feature, columns=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]).head())\n",
    "#     print(pd.DataFrame(pca.explained_variance_ratio_, index=[\"PC{}\".format(x + 1) for x in range(dfs.shape[1])]))\n",
    "\n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    HPCfeature = pca.transform(dfs)\n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    PFCfeature = pca.transform(dfs)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(HPCfeature[:,0],HPCfeature[:,2])\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(PFCfeature[:,0],PFCfeature[:,2])\n",
    "    plt.yticks(fontsize=26)\n",
    "    plt.xticks(fontsize=26)\n",
    "    plt.show()\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     Re_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]\n",
    "#     Re_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]\n",
    "#     Re_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]\n",
    "    \n",
    "#     plt.figure()\n",
    "# #     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "# #     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "# #     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,0])-moving_average(feature[100:,0])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,1])-moving_average(feature[100:,1])))\n",
    "# #     plt.plot(np.abs(moving_average(feature[:100,2])-moving_average(feature[100:,2])))\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "    \n",
    "    return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    for i in range(1):\n",
    "        model_list = glob.glob('model/R20_traintest/*OUT1**s'+str(i+9)+'_100_9_*epoch150.pth')\n",
    "        model_list = sorted(model_list)\n",
    "        model_list = sorted(model_list,key=len,reverse=False)\n",
    "        ratio_list = []\n",
    "        ratio_list_max = []\n",
    "        k=0\n",
    "        for model in model_list:\n",
    "            print(model)\n",
    "#             PFC,HPC = main(model)\n",
    "            PFC,HPC,PFC_max,HPC_max = main(model)\n",
    "            ratio_list.append(PFC/HPC)\n",
    "#             ratio_list_max.append(PFC_max/HPC_max)\n",
    "            ratio_list_max.append(np.abs(PFC_max-HPC_max))\n",
    "#             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "#             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "    #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "            k+=1\n",
    "#         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "#         ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "#         ratio_list = moving_average(ratio_list)[2:-2]\n",
    "#         correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "        \n",
    "        ratio_list_max = np.array(ratio_list_max).clip(-2,2)\n",
    "        ratio_list_max = moving_average(ratio_list_max)[2:-2]\n",
    "        correlation_fig.plot(np.arange(0,len(ratio_list_max)*5,5),np.array(ratio_list_max))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################  Compare!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!   #############################################\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "class MyLSTM_comp(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM_comp, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        hidden1 = self.LSTM1(input, hiddens[0])\n",
    "        hidden2 = self.LSTM2(hidden1[0], hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.01, torch.rand(self.batch_size, self.hidden_size)*0.01]\n",
    "        return [hidden,hidden]  \n",
    "\n",
    "class MyLSTM_PFCHPC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=1):\n",
    "        super(MyLSTM_PFCHPC, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re = hiddens[0][0]\n",
    "        HPC_input = torch.cat([input,Re],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = hiddens[1][0]\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.01\n",
    "        var = 0.01\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size)*const, torch.rand(self.batch_size, self.hidden_size)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size)*var, torch.rand(self.batch_size, self.hidden_size)*var]\n",
    "        return [PFC_hidden,HPC_hidden]\n",
    "    \n",
    "    \n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 30\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_cue18_s5_100_1_2.pth'\n",
    "    # model_path = 'model/ReModel_L2_interRNNrand_AddRe_OUT5_cue13_s9_100_1.pth'\n",
    "    # model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_2_epoch150.pth'\n",
    "#     model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_3_epoch195.pth'\n",
    "#     model_path = 'model/R20_cue_131/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_1_epoch195.pth'\n",
    "#     model_path = 'model/R20_cue_131_1to3/ReModel_L2_interRNNrand_OUT1_cue7_131_1to3_s4_100_1_epoch175.pth'\n",
    "    model_path = model\n",
    "    # model_path = 'model/v4_2Model_MTRNN2_cue_9.pth'\n",
    "    filename = \"primal_long131test\"\n",
    "    sparse = 1\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 3\n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_PFCHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_y, batch_size)\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    # hidden = rnn.initHidden()\n",
    "    data_limit = 100\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "#     for k in range(data.shape[0]*8):\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             if np.any(cue_point==k+data_limit):\n",
    "#                 output = torch.cat([output,torch.ones(10,1)],axis=1)\n",
    "#             else:\n",
    "#                 output = torch.cat([output,torch.zeros(10,1)],axis=1)\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "#     fig = plt.figure()\n",
    "#     print(pltdata.shape)\n",
    "#     plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "#     plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "#     plt.show()\n",
    "#     MakeAnimation2(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    # MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    # MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    # MakeAnimation_img(np.array(Restate),\"Re\")\n",
    "    #MakeAnimation_testdata(pltdata[:,0,0],pltdata[:,0,1])\n",
    "    \n",
    "    \n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#     for k in range(data.shape[0]*8):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             if np.any(cue_point_noise==k+data_limit):\n",
    "#                 output = torch.cat([output,torch.ones(10,1)],axis=1)\n",
    "#             else:\n",
    "#                 output = torch.cat([output,torch.zeros(10,1)],axis=1)\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_b = np.array(p.data)\n",
    "            if n == \"PFC.weight_hh\":\n",
    "                PFC_inw_b = np.array(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w = np.array(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_b = np.array(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw_b = np.array(p.data)\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "#     MakeAnimation(traj[:,0,0],traj[:,0,1], traj_noise[:,0,0], traj_noise[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "# #     plt.plot(traj_noise[:,0,0],traj_noise[:,0,1])\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(traj[:,0,0])\n",
    "#     plt.plot(traj_noise[:,0,0])\n",
    "\n",
    "\n",
    "#     PFC_corrlist = np.array([])\n",
    "#     HPC_corrlist = np.array([])\n",
    "#     cross_corrlist = np.array([])\n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "#         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "#         plt.plot(traj_noise[:,0,0])\n",
    "# #         plt.plot(np.abs(traj[:,0,0]-traj_noise[:,0,0]))\n",
    "#     #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "# #                 plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(HPCstate_noise)[:,k,i],alpha=0.5)\n",
    "#                 plt.plot(np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]),alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "#     #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #                 plt.plot(np.array(Gate_states_noise)[:,1,20+i],alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #                 plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #                 print(np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 cross_corrlist = np.append(cross_corrlist,np.corrcoef(np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i])))\n",
    "#                 PFC_corrlist = np.append(PFC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(PFCstate)[:,k,i]-np.array(PFCstate_noise)[:,k,i]))[0,1])\n",
    "#                 HPC_corrlist = np.append(HPC_corrlist,np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(np.array(HPCstate)[:,k,i]-np.array(HPCstate_noise)[:,k,i]))[0,1])\n",
    "# #         plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.mean(PFC_corrlist),np.mean(HPC_corrlist),np.mean(cross_corrlist))\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"PFC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    PFC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "    PFC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "    PFC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "#     plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "#     plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.abs(feature[:100,0]),color=colors[-3])\n",
    "#     plt.plot(np.abs(feature[100:,0]),color=colors[-4])\n",
    "#     plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    ratios = pca.explained_variance_ratio_\n",
    "    print(\"HPC correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "    HPC_a = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0]))[0,1]*ratios[0]\n",
    "    HPC_b = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1]))[0,1]*ratios[1]\n",
    "    HPC_c = np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2]))[0,1]*ratios[2]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.abs(feature[:100,0]-feature[100:,0]))\n",
    "    plt.plot(np.abs(feature[:100,1]-feature[100:,1]))\n",
    "    plt.plot(np.abs(feature[:100,2]-feature[100:,2]))\n",
    "    plt.show()\n",
    "\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c])\n",
    "    return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/compare30_131/*s10_100_1_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "    \n",
    "    for i in range(10):\n",
    "#         model_list = glob.glob('model/compare30_131/*s'+str(i+1)+'_100_1_*epoch??.pth')\n",
    "        model_list = glob.glob('model/PFCHPC_30_131/*s'+str(i+1)+'_100_2_*epoch*.pth')\n",
    "        model_list = sorted(model_list)\n",
    "        model_list = sorted(model_list,key=len,reverse=False)\n",
    "        ratio_list = []\n",
    "        k=0\n",
    "        for model in model_list:\n",
    "            PFC,HPC = main(model)\n",
    "            ratio_list.append(PFC/HPC)\n",
    "#             ratio_list.append(np.abs(PFC-HPC))\n",
    "#             correlation_fig.plot(PFC,HPC,\"o\")\n",
    "#             correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#             correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "    #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "            k+=1\n",
    "#         correlation_fig.plot(np.arange(0,200,5),np.array(ratio_list)-np.mean(ratio_list),\"o\")\n",
    "        ratio_list = np.array(ratio_list).clip(-2,2)\n",
    "        ratio_list = moving_average(ratio_list)[2:-2]\n",
    "        correlation_fig.plot(np.arange(0,len(ratio_list)*5,5),np.array(ratio_list))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jul 11 00:31:22 2020\n",
    "\n",
    "@author: munenoritakaku\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jul  3 10:30:01 2020\n",
    "\n",
    "@author: munenoritakaku\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        else:\n",
    "            traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims,interval=10)    \n",
    "    ani.save('Comp_anim_0_l.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def mkDataSet(data_size, data_length=50, freq=60., noise=0.02):\n",
    "    \"\"\"\n",
    "    params\n",
    "      data_size : データセットサイズ\n",
    "      data_length : 各データの時系列長\n",
    "      freq : 周波数\n",
    "      noise : ノイズの振幅\n",
    "    returns\n",
    "      train_x : トレーニングデータ（t=1,2,...,size-1の値)\n",
    "      train_t : トレーニングデータのラベル（t=sizeの値）\n",
    "    \"\"\"\n",
    "    train_x = []\n",
    "    train_t = []\n",
    "\n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[math.cos(2 * math.pi * (offset + i) / freq) + np.random.normal(loc=0.0, scale=noise), math.sin(4 * math.pi * (offset + i) / freq) + np.random.normal(loc=0.0, scale=noise)] for i in range(data_length)])\n",
    "        train_t.append([math.cos(2 * math.pi * (offset + data_length) / freq),math.sin(4 * math.pi * (offset + data_length) / freq)])\n",
    "    print(len(train_x[0]))\n",
    "    return train_x, train_t\n",
    "\n",
    "def mkOwnDataSet(data_size, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(\"primal_long131test_r.csv\",delimiter=',')\n",
    "    y = np.loadtxt(\"primal_long131test_l.csv\",delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 20\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x = make_Ttraj(1)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y = make_Ttraj(2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_x = np.array([[0,0]])\n",
    "    data_y = np.array([[0,0]])\n",
    "    order  = np.array([1,0,0,1])\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2,0,0,2])\n",
    "    order = np.append(order, [2])\n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "#     order = [1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2,0,0,0,0,0,1,0,0,0,0,0,2]\n",
    "    for idx in order:\n",
    "        if idx == 1:\n",
    "            target_x = x\n",
    "            target_y = y\n",
    "        elif idx == 0:\n",
    "            target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], 20)])\n",
    "            target_x = target\n",
    "            target_y = target\n",
    "        else:\n",
    "            target_x = y\n",
    "            target_y = x\n",
    "        if idx != 0:\n",
    "            target_x += np.random.normal(loc=0.0, scale=noise, size=target_x.shape)\n",
    "            target_y += np.random.normal(loc=0.0, scale=noise, size=target_y.shape)\n",
    "\n",
    "        data_x = np.append(data_x,target_x,axis=0)\n",
    "        data_y = np.append(data_y,target_y,axis=0)\n",
    "        \n",
    "    print(data_x.shape,data_y.shape)\n",
    "    return data_x[1:],data_y[1:]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.01):\n",
    "   \n",
    "    x,y = make_traj(delay_length)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x.shape[0])])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y.shape[0])])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    batch_t = []\n",
    "    idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "    for _ in range(batch_size):\n",
    "        batch_x.append(train_x[idx])\n",
    "        batch_t.append(train_t[idx])\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        #idx += 1\n",
    "    return torch.tensor(batch_x).transpose(0,1), torch.tensor(batch_t)\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "    for _ in range(batch_size):\n",
    "        batch_x.append(train_x[idx])\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        #idx += 1\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.LSTM2 = nn.LSTMCell(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        hidden1 = self.LSTM1(input, hiddens[0])\n",
    "        hidden2 = self.LSTM2(hidden1[0], hiddens[1])\n",
    "        output = self.linear(hidden2[0])\n",
    "        return output, [hidden1,hidden2]\n",
    "\n",
    "    def initHidden(self):\n",
    "        hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [hidden,hidden]\n",
    "\n",
    "    def initHidden_rand(self):\n",
    "        hidden = [torch.rand(self.batch_size, self.hidden_size)*0.2, torch.rand(self.batch_size, self.hidden_size)*0.2]\n",
    "        return [hidden,hidden]    \n",
    "\n",
    "\n",
    "def make_bins(data):\n",
    "    bins = np.array([])\n",
    "    for i in range(len(data)-1):\n",
    "        bins = np.append(bins,(data[i]+data[i+1])/2)\n",
    "    return bins\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(states[start:])\n",
    "    return states_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 30\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    # model_path = 'model/compstack_model_long131test_3.pth'\n",
    "    # model_path = 'model/compstack_model_171_s5_100_1.pth'\n",
    "    # model_path = 'model/compstack_model_151_s10_100_1.pth'\n",
    "    # model_path = 'model/compare/Compare_151_s2_100_2_epoch170.pth'\n",
    "    # model_path = 'model/compare_cont/compstack_model_151_s9_100_10.pth'\n",
    "    # model_path = 'model/compare_cont/Compare_151_s5_100_8_epoch125.pth'\n",
    "    # model_path = 'model/compare_Y/compstack_model_151Y_s2_100_1add_5.pth'\n",
    "    # model_path = 'model/compare_Y/Compare_151Y_s1_100_2add_1_epoch40.pth'\n",
    "    # model_path = 'model/compare_H/Compare_121H_s10_100_1add_epoch230.pth'\n",
    "    # model_path = 'model/compare30_H/Compare30_121H_s9_100_3_epoch125.pth'\n",
    "    # model_path = 'model/compare_171/Compare_171_s3_100_3_epoch180.pth'\n",
    "    model_path = 'model/compare30_131/compare30_131_s7_100_1_epoch105.pth'\n",
    "#     model_path = 'model/compare30_151/compare30_151_s6_100_2_epoch195.pth'\n",
    "#     model_path = 'model/compare_1212121/compare30_121_s1_100_3_epoch145.pth'\n",
    "    # model_path = 'model/compare_transfer/Compare_121H_transfers1010_s2_100_1_epoch140.pth'\n",
    "    # model_path = 'model/compare_transfer_1212121/compare_transfer_121_s2_100_1_epoch25.pth'\n",
    "\n",
    "    # train_x,train_y = mkOwnDataSet(training_size,data_length)\n",
    "    train_x,train_y = mkOwnDataSet_auto(training_size, delay_length)\n",
    "\n",
    "    rnn = MyLSTM(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    data = mkOwnRandomBatch(train_x, batch_size)\n",
    "    \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            traj.append(output.tolist())\n",
    "    for k in range(data.shape[0]*4):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(output,hidden) \n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            traj.append(output.tolist())\n",
    "#             print(output)\n",
    "    traj = torch.tensor(traj)\n",
    "    pltdata = torch.squeeze(data).numpy()\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    fig = plt.figure()\n",
    "    print(pltdata.shape)\n",
    "    plt.plot(pltdata[:,0,0],pltdata[:,0,1],\"--\")\n",
    "    plt.plot(traj[:,0,0],traj[:,0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    # MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    \n",
    "    \n",
    "    # for n, p in rnn.named_parameters():\n",
    "    #     if n == \"LSTM1.weight_ih\":\n",
    "    #         PFC_w = np.array(p.data)\n",
    "    #     if n == \"LSTM2.weight_ih\":\n",
    "    #         HPC_w = np.array(p.data)\n",
    "    #     if n == \"LSTM1.weight_hh\":\n",
    "    #         PFC_inw = np.array(p.data)\n",
    "    #     if n == \"LSTM2.weight_hh\":\n",
    "    #         HPC_inw = np.array(p.data)\n",
    "                \n",
    "    # fig2 = plt.figure()\n",
    "    # ax1 = fig2.add_subplot(121)\n",
    "    # ax2 = fig2.add_subplot(122)\n",
    "    \n",
    "    # ax1.imshow(PFC_w,cmap=\"coolwarm\")\n",
    "    # ax2.imshow(HPC_w,cmap=\"coolwarm\")\n",
    "    # ax1.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(PFC_w),np.min(PFC_w)))\n",
    "    # ax2.set_title(\"max = {:.2f},min = {:.2f}\".format(np.max(HPC_w),np.min(HPC_w)))\n",
    "    \n",
    "    \n",
    "    fig3 = plt.figure()\n",
    "    ax3 = fig3.add_subplot(121)\n",
    "    ax4 = fig3.add_subplot(122)\n",
    "    ax3.imshow(np.corrcoef(np.array(PFCstate)[:,0]),cmap=plt.get_cmap(\"seismic\"))\n",
    "    ax4.imshow(np.corrcoef(np.array(HPCstate)[:,0]),cmap=plt.get_cmap(\"seismic\"))\n",
    "    ax3.set_title(\"PFC\")   \n",
    "    ax4.set_title(\"HPC\")  \n",
    "    \n",
    "    pca = PCA()\n",
    "    dfs = np.array(HPCstate)[:,0,:]\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "    pred = KMeans(n_clusters=2).fit_predict(feature)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    for i in range(200):\n",
    "        plt.annotate(i,(feature[i, 0], feature[i, 1]))\n",
    "    plt.show()\n",
    "    \n",
    "    fig3d = plt.figure()\n",
    "    ax3d = Axes3D(fig3d)\n",
    "    ax3d.plot(feature[:, 0], feature[:, 1], feature[:, 2],  alpha=0.3)\n",
    "    \n",
    "    # fig4 = plt.figure(figsize=(10,5))\n",
    "    # ax5 = fig4.add_subplot(211)\n",
    "    # ax6 = fig4.add_subplot(212)\n",
    "    # #ax5.plot(np.array(PFCstate)[:,0,pred==1])\n",
    "    # ax5.imshow(np.array(PFCstate)[:,0,:].T)\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==0],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "    # # ax5.plot(np.average(np.array(HPCstate)[:,0],axis=1))\n",
    "    # ax6.imshow(np.array(HPCstate)[:,0,:].T)\n",
    "    # ax5.set_title(\"PFC\")   \n",
    "    # ax6.set_title(\"HPC\")  \n",
    "    # print(pred==0)\n",
    "    \n",
    "    # fig5 = plt.figure(figsize=(5,5))\n",
    "    # plt.plot(np.average(np.array(PFCstate)[:,0,:],axis=1),np.average(np.array(HPCstate)[:,0,:],axis=1))\n",
    "    # plt.show()\n",
    "    # #MakeAnimation_attracter(np.average(np.array(PFCstate)[:,0,pred==0],axis=1),np.average(np.array(PFCstate)[:,0,pred==1],axis=1))\n",
    "        \n",
    "    # #np.save(\"right_good_traj_PFC.npy\",dfs)\n",
    "    # #np.save(\"left_traj.npy\",dfs)\n",
    "    \n",
    "    # fig_weight = plt.figure(figsize=(10,5))\n",
    "    # fig1 = fig_weight.add_subplot(131)\n",
    "    # fig2 = fig_weight.add_subplot(132)\n",
    "    # fig3 = fig_weight.add_subplot(133)\n",
    "    # PFC_w_hist = np.histogram(np.abs(PFC_w[PFC_w.nonzero()]),bins=80,density=True)\n",
    "    # PFC_inw_hist = np.histogram(np.abs(PFC_inw[PFC_inw.nonzero()]),bins=40,density=True)\n",
    "    # fig1.plot(np.log(make_bins(PFC_w_hist[1])),np.log(PFC_w_hist[0]+0.01))\n",
    "    # fig1.plot(np.log(make_bins(PFC_inw_hist[1])),np.log(PFC_inw_hist[0]+0.01))\n",
    "    \n",
    "    # HPC_w_hist = np.histogram(np.abs(HPC_w[HPC_w.nonzero()]),bins=80,density=True)\n",
    "    # HPC_inw_hist = np.histogram(np.abs(HPC_inw[HPC_inw.nonzero()]),bins=40,density=True)\n",
    "    # fig2.plot(np.log(make_bins(HPC_w_hist[1])),np.log(HPC_w_hist[0]+0.01))\n",
    "    # fig2.plot(np.log(make_bins(HPC_inw_hist[1])),np.log(HPC_inw_hist[0]+0.01))\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         plt.figure()\n",
    "# #         plt.ylim(-1,1)\n",
    "#         plt.plot(traj[:,0,0])\n",
    "# #         plt.plot(np.array(PFCstate_noise)[:400,0,17],alpha=0.5)\n",
    "#         for k in range(1):\n",
    "#             plt.plot(np.array(HPCstate)[:,k,i],alpha=0.5)\n",
    "#             plt.plot(np.array(PFCstate)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:120,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate)[:120,k,i]-np.array(PFCstate)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(PFCstate_noise)[:120,k,i]-np.array(PFCstate_noise)[120:240,k,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Restate)[:,i]-np.array(Restate_noise)[:,i],alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate)[:,i]),alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #             plt.plot(moving_average(np.array(Restate)[:,i])-moving_average(np.array(Restate_noise)[:,i]),alpha=0.5)\n",
    "# #             plt.plot(np.array(Gate_states)[:,0,0+i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Gate_states)[:,1,0+i],alpha=0.5)\n",
    "# #             plt.plot(np.array(Gate_states_noise)[:,1,0+i],alpha=0.5)\n",
    "# #             plt.plot(np.abs(np.array(Gate_states)[:,1,0+i]-np.array(Gate_states_noise)[:,1,0+i]),alpha=0.5)\n",
    "# #             plt.plot(np.log(np.array(Gate_states)[:,1,0+i]/np.array(Gate_states)[:,1,20+i]),alpha=0.5)\n",
    "# #             plt.plot(np.log(np.array(Gate_states_noise)[:,1,0+i]/np.array(Gate_states_noise)[:,1,20+i]),alpha=0.5)\n",
    "# #             plt.plot(np.log(np.array(Gate_states)[:,0,0+i]/np.array(Gate_states)[:,0,20+i]),alpha=0.5)\n",
    "# #             plt.plot(np.log(np.array(Gate_states_noise)[:,0,0+i]/np.array(Gate_states_noise)[:,0,20+i]),alpha=0.5)\n",
    "#         plt.title(\"neuron#\"+str(i+1))\n",
    "\n",
    "\n",
    "    delays = pick_traj(traj[:,0], np.array(traj)[:])[3:-1]\n",
    "    bifur = np.array([])\n",
    "    for data in delays:\n",
    "        check_bifur = np.argmax(np.abs(np.array(data)[:,0,0] - 0.5))\n",
    "        bifur = np.append(bifur,data[check_bifur,:,0])\n",
    "    if bifur.shape[0] == 0:\n",
    "        pass\n",
    "    plt.figure()\n",
    "    plt.plot(traj[:,0,0])\n",
    "    plt.plot(traj[:,0,1])\n",
    "    print(np.var(bifur),np.abs(np.median(bifur)-np.mean(bifur)))\n",
    "    print(bifur)\n",
    "    \n",
    "    pca = PCA()\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0],np.array(Restate)),axis=1)\n",
    "    # dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(HPCstate)[:,0]),axis=1)\n",
    "    dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.array(Restate)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    \n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(PFCstate_noise)[:,0])\n",
    "    delays = pick_traj(traj[:,0], np.array(PFCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(HPCstate_noise)[:,0])\n",
    "#     delays = pick_traj(traj[:,0], np.array(HPCstate)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Restate_noise)[:])\n",
    "#     delays = pick_traj(traj[:,0], np.array(Restate)[:])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(traj_noise)[:])[3:-1]\n",
    "#     delays = pick_traj(traj[:,0], np.array(Gate_states)[:,1])\n",
    "#     delays = pick_delay(traj[:,0], np.array(Gate_states)[:,0])\n",
    "#     delays = pick_traj(traj_noise[:,0], np.array(Gate_states_noise)[:,1])\n",
    "#     delays = pick_delay(traj_noise[:,0], np.array(Gate_states_noise)[:,0])\n",
    "#     delays = pick_delay(traj[:,0], feature[:])\n",
    "#     delays = pick_traj(traj[:,0], feature[:])\n",
    "    bifur = np.array([])\n",
    "    for i in range(20):\n",
    "        plt.figure()\n",
    "        for data in delays[1:-1]:\n",
    "            plt.plot(np.array(data)[:,0+i],alpha=0.5)\n",
    "            print(len(data))\n",
    "        plt.title(\"neuron#\"+str(i+1))\n",
    "#     print(np.var(bifur),np.median(bifur)-np.mean(bifur))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"model/R20_cue_1until3_smallbatch4/\"\n",
    "path = \"model/compare30_cue_1until3_smallbatch4/\"\n",
    "\n",
    "with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "with open(path+\"good_list_long.txt\", mode=\"r\") as f:\n",
    "    good_list_long = f.read().splitlines()\n",
    "for model in good_list:\n",
    "    if model in good_list_long:\n",
    "        print(model)\n",
    "        \n",
    "model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s1_100_2_epoch65.pth\n",
    "model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s5_100_1_epoch95.pth\n",
    "model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_3_epoch80.pth\n",
    "model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_3_epoch50.pth\n",
    "model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s10_100_3_epoch40.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"model/R20_cue_1until3_smallbatch4/\"\n",
    "path = \"model/compare30_cue_1until3_smallbatch4/\"\n",
    "\n",
    "with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "with open(path+\"good_list_long.txt\", mode=\"r\") as f:\n",
    "    good_list_long = f.read().splitlines()\n",
    "for model in good_list:\n",
    "    if model in good_list_long:\n",
    "        print(model)\n",
    "\n",
    "        \n",
    "model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s1_100_3_epoch35.pth\n",
    "model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s6_100_1_epoch85.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = \"model/R20_cue_1until3_smallbatch4/\"\n",
    "path = \"model/compare30_cue_1until3_smallbatch5/\"\n",
    "\n",
    "with open(path+\"good_list_short.txt\", mode=\"r\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "with open(path+\"good_list_long.txt\", mode=\"r\") as f:\n",
    "    good_list_long = f.read().splitlines()\n",
    "for model in good_list:\n",
    "    if model in good_list_long:\n",
    "        print(model)\n",
    "        \n",
    "# compare5\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s1_100_2_epoch145.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s2_100_2_epoch80.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s3_100_1_epoch175.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s3_100_3_epoch125.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s4_100_1_epoch95.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s4_100_2_epoch135.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s6_100_3_epoch85.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s7_100_1_epoch135.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s7_100_2_epoch90.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s7_100_3_epoch170.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s8_100_2_epoch55.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s8_100_3_epoch185.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s9_100_1_epoch140.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s9_100_2_epoch140.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s9_100_3_epoch185.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s10_100_2_epoch65.pth\n",
    "# model/compare30_cue_1until3_smallbatch5/Compare30_cue_131_s10_100_3_epoch95.pth\n",
    "\n",
    "# compare4\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s1_100_3_epoch35.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s2_100_3_epoch120.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s3_100_3_epoch100.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s4_100_1_epoch120.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s6_100_1_epoch110.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s7_100_2_epoch120.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s8_100_1_epoch150.pth\n",
    "# model/compare30_cue_1until3_smallbatch4/Compare30_cue_131_s10_100_3_epoch175.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = \"model/R20_cue_1until3_smallbatch5/\"\n",
    "# path = \"model/compare30_cue_1until3_smallbatch5/\"\n",
    "\n",
    "with open(path+\"good_list_short.txt\", mode=\"r\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "with open(path+\"good_list_long.txt\", mode=\"r\") as f:\n",
    "    good_list_long = f.read().splitlines()\n",
    "for model in good_list:\n",
    "    if model in good_list_long:\n",
    "        print(model)\n",
    "        \n",
    "# Re5\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s1_100_1_epoch110.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s1_100_2_epoch95.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s2_100_1_epoch50.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s2_100_2_epoch155.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s2_100_3_epoch135.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s3_100_1_epoch40.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s3_100_3_epoch130.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s4_100_2_epoch140.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s5_100_2_epoch55.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s6_100_2_epoch90.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s6_100_3_epoch120.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_3_epoch85.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s8_100_1_epoch65.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s8_100_2_epoch150.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s8_100_3_epoch85.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_1_epoch150.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_2_epoch85.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_3_epoch130.pth\n",
    "# model/R20_cue_1until3_smallbatch5/ReModel_L2_interRNNrand_OUT1_cue7_131_s10_100_2_epoch10.pth\n",
    "\n",
    "# # Re4\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s1_100_1_epoch100.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s1_100_2_epoch65.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s2_100_3_epoch120.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s3_100_1_epoch145.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s4_100_2_epoch120.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s5_100_1_epoch95.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s6_100_2_epoch155.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_2_epoch155.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s7_100_3_epoch95.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s8_100_2_epoch140.pth\n",
    "# model/R20_cue_1until3_smallbatch4/ReModel_L2_interRNNrand_OUT1_cue7_131_s9_100_3_epoch50.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = \"model/R20_cue_1until3_smallbatch5_decay/\"\n",
    "path = \"model/compare30_cue_1until3_smallbatch5_decay/\"\n",
    "# path = \"model/PFCHPC30_cue_1until3_smallbatch5/\"\n",
    "\n",
    "\n",
    "with open(path+\"good_list_short.txt\", mode=\"r\") as f:\n",
    "    good_list = f.read().splitlines()\n",
    "with open(path+\"good_list_long.txt\", mode=\"r\") as f:\n",
    "    good_list_long = f.read().splitlines()\n",
    "for model in good_list:\n",
    "#     if int(model.split(\"_epoch\")[-1].split(\".pth\")[0]) < 190:\n",
    "#         continue\n",
    "    if model in good_list_long:\n",
    "        print(model)\n",
    "        \n",
    "        \n",
    "\n",
    "# 5\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s1_100_3_epoch140.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s2_100_1_epoch100.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s2_100_3_epoch150.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s3_100_2_epoch85.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s4_100_1_epoch110.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s4_100_2_epoch180.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s5_100_3_epoch175.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s6_100_1_epoch115.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s6_100_2_epoch75.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s6_100_3_epoch50.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s7_100_1_epoch95.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s7_100_2_epoch75.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s7_100_3_epoch155.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s9_100_1_epoch175.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s9_100_2_epoch65.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s9_100_3_epoch135.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch5/v4_3_N30_cue_131_s10_100_1_epoch115.pth\n",
    "        \n",
    "# 4\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s1_100_1_epoch70.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s1_100_2_epoch165.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s1_100_3_epoch170.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s2_100_1_epoch115.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s2_100_2_epoch55.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s3_100_2_epoch50.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s5_100_2_epoch95.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s6_100_3_epoch50.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s7_100_1_epoch75.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s8_100_2_epoch85.pth\n",
    "# model/PFCHPC30_cue_1until3_smallbatch4/v4_3_N30_cue_131_s9_100_1_epoch165.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########    Checker of Activity difference and grad   #########################\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import sklearn \n",
    "import nolds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "def Culc_gate(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniPFC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = hiddens[1][0][0]\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "\n",
    "def Culc_gate_uniHPC(input, params, hiddens):\n",
    "    Re = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "    #Re = torch.zeros(10, 20)\n",
    "    HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "    PFC_input = torch.cat([hiddens[1][0][0],hiddens[2][0]])\n",
    "    PFC_gates = params[0]@PFC_input+params[1]@hiddens[0][1][0]+params[2]+params[3]\n",
    "    HPC_gates = params[4]@HPC_input[0]+params[5]@hiddens[1][1][0]+params[6]+params[7]\n",
    "    PFC_gates = torch.sigmoid(PFC_gates)\n",
    "    HPC_gates = torch.sigmoid(HPC_gates)\n",
    "    \n",
    "    return [PFC_gates.tolist(), HPC_gates.tolist()]\n",
    "    \n",
    "    \n",
    "\n",
    "def MakeAnimation(data_x,data_y,traj_x,traj_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(traj_x.shape[0]):\n",
    "        if t < data_limit:\n",
    "            traj = ax.plot(data_x[:t], data_y[:t], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#         else:\n",
    "#             traj = ax.plot(data_x[:data_limit], data_y[:data_limit], \"b\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\", data_x[data_limit-1:t], data_y[data_limit-1:t], \"--b\")\n",
    "        else:\n",
    "            traj = ax.plot(traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "#             traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\", traj_x[:t], traj_y[:t], \"r\", traj_x[t-1], traj_y[t-1], \"or\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_v4_2_1_r.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_data(data_x,data_y, data_limit):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0.2,0.8)\n",
    "    ax.set_ylim(-0.05,0.8)\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\")\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=30)    \n",
    "    ani.save('anim_Re_0.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def MakeAnimation_attracter(data_x,data_y):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data_x.shape[0]):\n",
    "        traj = ax.plot(data_x[:t], data_y[:t], \"b\", data_x[t-1], data_y[t-1], \"ob\",)\n",
    "        title = ax.text(0.5, 1.01, 'time={}'.format(t),\n",
    "                     ha='center', va='bottom',\n",
    "                     transform=ax.transAxes, fontsize='large')\n",
    "        ims.append(traj+[title])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=10)    \n",
    "    ani.save('anim_attracter2.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "    \n",
    "def MakeAnimation_img(data,module):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "    for t in range(data.shape[0]):\n",
    "        img = ax.imshow(data[t].reshape(1,data.shape[1]))\n",
    "        title = ax.text(0.5, 1.01, module+' time={}'.format(t),\n",
    "             ha='center', va='bottom',\n",
    "             transform=ax.transAxes, fontsize='large')\n",
    "        ims.append([img,title])\n",
    "    ani = animation.ArtistAnimation(fig, ims)    \n",
    "    ani.save('anim_fire_'+module+'_.gif', writer='pillow')\n",
    "    plt.show()\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def mkOwnDataSet(data_size, filename, data_length=100, freq=60., noise=0.005):\n",
    "    \n",
    "    x = np.loadtxt(str(filename+\"_r.csv\"),delimiter=',')\n",
    "    y = np.loadtxt(str(filename+\"_l.csv\"),delimiter=',')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x.append([[x[i][0] + np.random.normal(loc=0.0, scale=noise),x[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,x.shape[0],round(x.shape[0]/data_length))])\n",
    "        train_y.append([[y[i][0] + np.random.normal(loc=0.0, scale=noise),y[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(0,y.shape[0],round(y.shape[0]/data_length))])\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def mkOwnRandomBatch(train_x, train_t, batch_size=10):\n",
    "    \"\"\"\n",
    "    train_x, train_tを受け取ってbatch_x, batch_tを返す\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    for _ in range(batch_size):\n",
    "        idx = np.random.randint(0, len(train_x) - batch_size)\n",
    "        batch_x.append(train_x[idx])\n",
    "    return torch.tensor(batch_x).transpose(0,1)\n",
    "\n",
    "def make_Ttraj(direction):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(5)*0.5\n",
    "    if direction == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.5, 5)        \n",
    "    backstraight_x = np.ones(5)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 5)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    branch2_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 5)\n",
    "    \n",
    "    traj_x = np.append(traj_x, [straight_x,branch1_x,branch2_x,backstraight_x])\n",
    "    traj_y = np.append(traj_y, [straight_y,branch1_y,branch2_y,backstraight_y])\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "def make_Htraj(direction1, direction2):\n",
    "    traj_x = np.array([])\n",
    "    traj_y = np.array([])\n",
    "    straight_x = np.ones(10)*0.5\n",
    "    if direction1 == 1:\n",
    "        branch1_x = np.linspace(0.5, 0.75, 5)\n",
    "        branch2_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch3_x = np.linspace(0.75, 0.75, 5)\n",
    "        branch4_x = np.linspace(0.75, 0.5, 5)\n",
    "    elif direction1 == 2:\n",
    "        branch1_x = np.linspace(0.5, 0.25, 5)\n",
    "        branch2_x = np.linspace(0.25, 0.25, 5)   \n",
    "        branch3_x = np.linspace(0.25, 0.25, 5)  \n",
    "        branch4_x = np.linspace(0.25, 0.5, 5)       \n",
    "    backstraight_x = np.ones(10)*0.5\n",
    "\n",
    "    straight_y = np.linspace(0, 0.5, 10)\n",
    "    branch1_y = np.linspace(0.5, 0.5, 5)\n",
    "    if direction2 == 1:\n",
    "        branch2_y = np.linspace(0.5, 0.25, 5)\n",
    "        branch3_y = np.linspace(0.25, 0.5, 5)\n",
    "    elif direction2 == 2:\n",
    "        branch2_y = np.linspace(0.5, 0.75, 5)\n",
    "        branch3_y = np.linspace(0.75, 0.5, 5)\n",
    "    branch4_y = np.linspace(0.5, 0.5, 5)\n",
    "    backstraight_y = np.linspace(0.5 , 0, 10)\n",
    "    \n",
    "    traj_x = np.append(traj_x, straight_x)\n",
    "    traj_x = np.append(traj_x, [branch1_x,branch2_x,branch3_x,branch4_x])\n",
    "    traj_x = np.append(traj_x, backstraight_x)\n",
    "    traj_y = np.append(traj_y, straight_y)\n",
    "    traj_y = np.append(traj_y, [branch1_y,branch2_y,branch3_y,branch4_y])\n",
    "    traj_y = np.append(traj_y, backstraight_y)\n",
    "    traj = np.concatenate([[traj_x],[traj_y]],axis=0).T\n",
    "    return traj\n",
    "\n",
    "\n",
    "def make_traj(delay_length):\n",
    "    freq=60\n",
    "    noise=0.005\n",
    "    data_length = 40\n",
    "    \n",
    "    # x = np.loadtxt(\"right1.csv\",delimiter=',')\n",
    "    x_1 = make_Htraj(1,1)\n",
    "    x_2 = make_Htraj(1,2)\n",
    "    # y = np.loadtxt(\"left1.csv\",delimiter=',')\n",
    "    y_1 = make_Htraj(2,1)\n",
    "    y_2 = make_Htraj(2,2)\n",
    "    z = np.loadtxt(\"stay1.csv\",delimiter=',')\n",
    "    data_list = []\n",
    "\n",
    "    ###  ver1  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    \n",
    "#     ###  ver2  ###\n",
    "#     orders = []\n",
    "#     order  = np.array([1])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [2])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([2])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [3])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([3])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [4])\n",
    "#     orders.append(order) \n",
    "#     order  = np.array([4])\n",
    "#     order  = np.append(order,np.zeros(delay_length))\n",
    "#     order = np.append(order, [1])\n",
    "#     orders.append(order) \n",
    "\n",
    "    ###  ver1's test  ###\n",
    "    orders = []\n",
    "    order  = np.array([1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    orders.append(order) \n",
    "    order  = np.array([2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    orders.append(order) \n",
    "    order  = np.array([3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    orders.append(order) \n",
    "    order  = np.array([4])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [2])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [3])\n",
    "    order  = np.append(order,np.zeros(delay_length))\n",
    "    order = np.append(order, [1])\n",
    "    orders.append(order) \n",
    "    \n",
    "    # order = [1,0,0,0,2]\n",
    "    # order = [2,0,0,1,0,0,0,2,0,0,1]\n",
    "    for order in orders:\n",
    "        data = np.array([[0,0]])\n",
    "        for idx in order:\n",
    "            if idx == 1:\n",
    "                target = x_1\n",
    "            elif idx == 2:\n",
    "                target = x_2\n",
    "            elif idx == 3:\n",
    "                target = y_1\n",
    "            elif idx == 4:\n",
    "                target = y_2\n",
    "            elif idx == 0:\n",
    "#                 target = np.array([[z[i][0],z[i][1]] for i in np.random.choice(z.shape[0], data_length)])\n",
    "                target = np.array([[0.5,0] for i in np.random.choice(z.shape[0], data_length)])\n",
    "            if idx != 0:\n",
    "                target += np.random.normal(loc=0.0, scale=noise, size=target.shape)\n",
    "    \n",
    "            data = np.append(data,target,axis=0)\n",
    "        data_list.append(data[1:])\n",
    "    return data_list[0],data_list[1],data_list[2],data_list[3]\n",
    "\n",
    "def mkOwnDataSet_auto(data_size, delay_length, freq=60., noise=0.0001):\n",
    "   \n",
    "    x1,x2,y1,y2 = make_traj(delay_length)\n",
    "    train_x1 = []\n",
    "    train_x2 = []\n",
    "    train_y1 = []\n",
    "    train_y2 = []\n",
    "    \n",
    "    for offset in range(data_size):\n",
    "        train_x1.append([[x1[i][0] + np.random.normal(loc=0.0, scale=noise),x1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x1.shape[0])])\n",
    "        train_x2.append([[x2[i][0] + np.random.normal(loc=0.0, scale=noise),x2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(x2.shape[0])])\n",
    "\n",
    "        train_y1.append([[y1[i][0] + np.random.normal(loc=0.0, scale=noise),y1[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y1.shape[0])])\n",
    "        train_y2.append([[y2[i][0] + np.random.normal(loc=0.0, scale=noise),y2[i][1]+ np.random.normal(loc=0.0, scale=noise)] for i in np.arange(y2.shape[0])])\n",
    "\n",
    "    return train_x1, train_x2, train_y1, train_y2\n",
    "\n",
    "def plot_distance_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    plt.figure()\n",
    "    plt.plot(result)\n",
    "    \n",
    "    plt.vlines(linelist,np.min(result),np.max(result))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def distance_bet2traj(traj1,traj2):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.linalg.norm(traj1[i]-traj2[i]))\n",
    "    return result\n",
    "\n",
    "def plot_activity_bet2traj(traj1,traj2,linelist):\n",
    "    traj1 = np.array(traj1)\n",
    "    traj2 = np.array(traj2)\n",
    "    result = []\n",
    "    threshold = 0.5\n",
    "    for i in range(traj1.shape[0]):\n",
    "        result.append(np.abs(traj1[i]-traj2[i]))\n",
    "        \n",
    "    plt.figure()\n",
    "    for i,data in enumerate(np.array(result).T):\n",
    "        if np.any(data[20:105]>threshold):\n",
    "            print(i)\n",
    "            plt.plot(data)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_delay(traj):\n",
    "    linelist = np.array([])\n",
    "    flag = False\n",
    "    for i in range(traj.shape[0]):\n",
    "        if traj[i,1] > 0.45 and flag == False:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] < 0.45 and flag == True:\n",
    "            linelist = np.append(linelist,i)\n",
    "            flag = False\n",
    "    return linelist\n",
    "\n",
    "def pick_delay(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "        start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def pick_traj(traj,states):\n",
    "    pointlist = np.array([])\n",
    "    flag = False\n",
    "    threshold = 0.2\n",
    "    for i in range(traj.shape[0]):\n",
    "        if i < 5:\n",
    "            continue\n",
    "        if traj[i,1] < threshold and flag == False:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = True\n",
    "        if traj[i,1] > threshold and flag == True:\n",
    "            pointlist = np.append(pointlist,i)\n",
    "            flag = False\n",
    "    states_list = []\n",
    "    start = 0\n",
    "    for i,k in enumerate(pointlist):\n",
    "        end = int(k)\n",
    "        if i % 2 != 0:\n",
    "            states_list.append(states[start:end])\n",
    "            start = int(k)\n",
    "    states_list.append(traj[start:])\n",
    "    return states_list\n",
    "\n",
    "def match_length(states_list):\n",
    "    min_length = 1000\n",
    "    result = []\n",
    "    for state in states_list:\n",
    "        min_length = np.min((min_length, len(state)))\n",
    "    for state in states_list:\n",
    "        result.append(state[-min_length:])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def vec_var(datas):\n",
    "    datas = np.array(datas)\n",
    "    average = np.average(datas,axis=0)\n",
    "    result = 0\n",
    "    for data in datas:\n",
    "        result += np.linalg.norm(data-average)\n",
    "    result /= datas.shape[0]\n",
    "    return result\n",
    "    \n",
    "def lyapunov_exp(data):\n",
    "    result = np.mean(np.log(np.abs(np.diff(data))))\n",
    "    return result\n",
    "\n",
    "def culc_grad(data):\n",
    "    datalen = len(data)\n",
    "    grad_list = np.array([])\n",
    "    pre_value = data[0]\n",
    "    for i in range(datalen):\n",
    "        grad = np.abs(data[i] - pre_value)\n",
    "        grad_list = np.append(grad_list,grad)\n",
    "        pre_value = data[i]\n",
    "        \n",
    "    return grad_list\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+hidden_size, hidden_size)\n",
    "        self.Re = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,1)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,1)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,1)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2][0]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2][0]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "\n",
    "class MyLSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, sparse=5):\n",
    "        super(MyLSTM_RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size_PFC = hidden_size\n",
    "        self.hidden_size_HPC = hidden_size\n",
    "        self.hidden_size_Re = hidden_size+0\n",
    "        self.PFC = nn.LSTMCell(self.hidden_size_HPC+self.hidden_size_Re, self.hidden_size_PFC)\n",
    "        # self.PFC = nn.LSTMCell(hidden_size*2, hidden_size)\n",
    "        self.HPC = nn.LSTMCell(input_size+self.hidden_size_Re, self.hidden_size_HPC)\n",
    "        self.Re = nn.RNNCell(self.hidden_size_HPC+self.hidden_size_PFC, self.hidden_size_Re)\n",
    "        self.linear = nn.Linear(self.hidden_size_HPC, output_size)\n",
    "        self.batch_size = batch_size\n",
    "        sparse = 0.1*int(sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_ih.data,sparse)\n",
    "        nn.init.sparse_(self.PFC.weight_hh.data,sparse)\n",
    "        nn.init.sparse_(self.HPC.weight_hh.data,sparse)\n",
    "\n",
    "    def forward(self, input, hiddens):\n",
    "        input = input.float()\n",
    "        Re_input = torch.cat([hiddens[0][0],hiddens[1][0]],dim=1)\n",
    "        Re_hidden = self.Re(Re_input, hiddens[2])\n",
    "        HPC_input = torch.cat([input,hiddens[2]],dim=1)\n",
    "        HPC_hidden = self.HPC(HPC_input, hiddens[1])\n",
    "        PFC_input = torch.cat([hiddens[1][0],hiddens[2]],dim=1)\n",
    "        PFC_hidden = self.PFC(PFC_input, hiddens[0])\n",
    "        output = self.linear(HPC_hidden[0])\n",
    "        return output, [PFC_hidden, HPC_hidden, Re_hidden]\n",
    "\n",
    "    def initHidden(self):\n",
    "        HPC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        PFC_hidden = [torch.zeros(self.batch_size, self.hidden_size), torch.zeros(self.batch_size, self.hidden_size)]\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_rand(self):\n",
    "        const = 0.1\n",
    "        var = 0.1\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*const\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def initHidden_test(self):\n",
    "        const = 0.2\n",
    "        var = 0.2\n",
    "        HPC_hidden = [torch.rand(self.batch_size, self.hidden_size_HPC)*const, torch.rand(self.batch_size, self.hidden_size_HPC)*const]\n",
    "#         HPC_hidden = [torch.ones(self.batch_size, self.hidden_size_HPC)*const, torch.ones(self.batch_size, self.hidden_size_HPC)*const]\n",
    "        PFC_hidden = [torch.rand(self.batch_size, self.hidden_size_PFC)*var, torch.rand(self.batch_size, self.hidden_size_PFC)*var]\n",
    "#         PFC_hidden = [torch.ones(self.batch_size, self.hidden_size_PFC)*const, torch.ones(self.batch_size, self.hidden_size_PFC)*const]\n",
    "#         Re_hidden = torch.ones(self.batch_size, self.hidden_size_Re)*const\n",
    "        Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*var\n",
    "        return [PFC_hidden,HPC_hidden,Re_hidden]\n",
    "    \n",
    "    def noiseHidden_rand(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.1\n",
    "        HPC_hidden = torch.randn(self.batch_size, self.hidden_size_HPC)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.randn(self.batch_size, self.hidden_size_PFC)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_select(self, hiddens):\n",
    "        c = 0\n",
    "        v = 0.01\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "        Re_hidden[:,index] += torch.randn(self.batch_size, index.size)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "    \n",
    "    def noiseHidden_dis(self, hiddens, statr, statl):\n",
    "        c = 0\n",
    "        v =-0.1\n",
    "        index = np.array([1,2,8,9,17])\n",
    "        HPC_hidden = torch.zeros(self.batch_size, self.hidden_size_HPC)\n",
    "        HPC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[1][0].add_(HPC_hidden)\n",
    "        PFC_hidden = torch.zeros(self.batch_size, self.hidden_size_PFC)\n",
    "        PFC_hidden[:,index] += torch.randn(self.batch_size, index.size)*c\n",
    "        hiddens[0][0].add_(PFC_hidden)\n",
    "        Re_hidden = torch.randn(self.batch_size, self.hidden_size_Re)*0.0\n",
    "        Re_hidden += (-statr+statl)*v\n",
    "#         Re_hidden = torch.rand(self.batch_size, self.hidden_size_Re)*v\n",
    "#         Re_hidden[:,index] = torch.zeros(self.batch_size, index.size)*c\n",
    "#         Re_hidden = torch.zeros(self.batch_size, self.hidden_size_Re)*c\n",
    "#         Re_hidden[:,index] += hiddens[2][:,index]*v\n",
    "        hiddens[2].add_(Re_hidden)\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "def moving_average(data):\n",
    "    y = np.ones(5)/5\n",
    "    mean_seq = np.convolve(data, y)\n",
    "    return mean_seq    \n",
    "\n",
    "\n",
    "def main(model):\n",
    "    training_size = 100\n",
    "    test_size = 1000\n",
    "    epochs_num = 10\n",
    "    hidden_size = 20\n",
    "    batch_size = 10\n",
    "    data_length = 100\n",
    "    inputsize = 2\n",
    "    outputsize = 2\n",
    "    delay_length = 3\n",
    "    \n",
    "    model_path = model\n",
    "    \n",
    "    colors = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "    \n",
    "#     delay_length = np.random.randint(1, 3)\n",
    "    delay_length = 2\n",
    "    train_x1,train_x2,train_y1,train_y2 = mkOwnDataSet_auto(training_size,delay_length)\n",
    "\n",
    "#     rnn = MyLSTM_comp(inputsize, hidden_size, outputsize, batch_size)\n",
    "    rnn = MyLSTM_RNN(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyLSTM_RNN_uniHPC(inputsize, hidden_size, outputsize, batch_size)\n",
    "#     rnn = MyMTRNN2(inputsize, hidden_size, outputsize, batch_size)\n",
    "\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    \n",
    "    pattern = 1\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    params = []\n",
    "    for p in rnn.parameters():\n",
    "        params.append(p.data)\n",
    "    \n",
    "        \n",
    "#     model_path = 'model/R20_131/ReModel_L2_interRNNrand_OUT1_131_s6_100_1_epoch125.pth'\n",
    "    model_path = model\n",
    "    rnn.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    for n, p in rnn.named_parameters():\n",
    "            if n == \"PFC.weight_ih\":\n",
    "                PFC_w_pre = torch.clone(p.data)\n",
    "            if n == \"HPC.weight_ih\":\n",
    "                HPC_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_ih\":\n",
    "                Re_w_pre = torch.clone(p.data)\n",
    "            if n == \"Re.weight_hh\":\n",
    "                Re_inw = torch.clone(p.data)\n",
    "            if n == \"linear.weight\":\n",
    "                OUT_w_pre = torch.clone(p.data)\n",
    "                   \n",
    "    traj = []\n",
    "    PFCstate = []\n",
    "    HPCstate = []\n",
    "    Restate = []\n",
    "    Gate_states = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "    data_limit = 120\n",
    "    est_length = 0\n",
    "    init_point = torch.rand(10,2)*1\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj.append(output.tolist())\n",
    "            PFCstate.append(hidden[0][0].tolist())\n",
    "            HPCstate.append(hidden[1][0].tolist())\n",
    "            Restate.append(hidden[2][0].tolist())\n",
    "            Gate_states.append(Culc_gate(output,params,hidden))\n",
    "#             Gate_states.append(Culc_gate_uniPFC(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "#             output,hidden = rnn(output,hidden)\n",
    "#             traj.append(output.tolist())\n",
    "#             PFCstate.append(hidden[0][0].tolist())\n",
    "#             HPCstate.append(hidden[1][0].tolist())\n",
    "#             Restate.append(hidden[2][0].tolist())\n",
    "#             Gate_states.append(Culc_gate(output,params,hidden))\n",
    "    traj = torch.tensor(traj)\n",
    "    traj = torch.squeeze(traj).numpy()\n",
    "    \n",
    "    pattern = 3\n",
    "    if  pattern == 1:\n",
    "        data = mkOwnRandomBatch(train_x1, train_x1, batch_size).float()\n",
    "    elif pattern == 2:\n",
    "        data = mkOwnRandomBatch(train_x2, train_x2, batch_size).float()\n",
    "    elif pattern == 3:\n",
    "        data = mkOwnRandomBatch(train_y1, train_y1, batch_size).float()\n",
    "    else:\n",
    "        data = mkOwnRandomBatch(train_y2, train_y2, batch_size).float()\n",
    "    \n",
    "    dividenum = int(np.array(PFCstate)[0:,0].shape[0]/2)\n",
    "    traj_noise = []\n",
    "    PFCstate_noise = []\n",
    "    HPCstate_noise = []\n",
    "    Restate_noise = []\n",
    "    Gate_states_noise = []\n",
    "    hidden = rnn.initHidden_rand()\n",
    "#     data = mkOwnRandomBatch(train_y, batch_size)\n",
    "#     init_point = torch.rand(10,2)*1\n",
    "#     data_limit = 125\n",
    "    for k in range(data_limit):\n",
    "            #print(data[k].shape)\n",
    "            output,hidden = rnn(data[k],hidden)\n",
    "#             output,hidden = rnn(init_point,hidden)\n",
    "            traj_noise.append(output.tolist())\n",
    "            PFCstate_noise.append(hidden[0][0].tolist())\n",
    "            HPCstate_noise.append(hidden[1][0].tolist())\n",
    "            Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "#     for k in range(data.shape[0]*est_length):\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             output,hidden = rnn(output,hidden) \n",
    "# #             hidden = rnn.noiseHidden_dis(hidden, np.array(Restate)[k+data_limit], np.array(Restate)[dividenum+k+data_limit])\n",
    "# #             hidden = rnn.noiseHidden_rand(hidden)\n",
    "#             traj_noise.append(output.tolist())\n",
    "#             PFCstate_noise.append(hidden[0][0].tolist())\n",
    "#             HPCstate_noise.append(hidden[1][0].tolist())\n",
    "#             Restate_noise.append(hidden[2][0].tolist())\n",
    "#             Gate_states_noise.append(Culc_gate(output,params,hidden))\n",
    "    traj_noise = torch.tensor(traj_noise)\n",
    "    traj_noise = torch.squeeze(traj_noise).numpy()\n",
    "\n",
    "    \n",
    "    print(np.array(PFCstate)[:,0].shape)\n",
    "#     MakeAnimation(pltdata[:,0,0],pltdata[:,0,1], traj[:,0,0], traj[:,0,1], data_limit)\n",
    "    #MakeAnimation_img(np.array(PFCstate)[:,0],\"PFC\")\n",
    "    #MakeAnimation_img(np.array(HPCstate)[:,0],\"HPC\")\n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "    dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "#     dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"PFC correlation\")\n",
    "#     PFC_activity = np.abs(feature[:data_limit,0]-feature[data_limit:,0])\n",
    "#     PFC_activity = np.abs(moving_average(feature[:data_limit,0])-moving_average(feature[data_limit:,0]))\n",
    "#     PFC_activity = np.abs((feature[:data_limit,0]-moving_average(feature[:data_limit,0])[2:-2])-(feature[data_limit:,0]-moving_average(feature[data_limit:,0])[2:-2]))\n",
    "    PFC_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(feature[:data_limit,0],color=\"b\")\n",
    "#     plt.plot(feature[data_limit:,0],color=\"r\")\n",
    "#     plt.plot(moving_average(feature[:data_limit,0]),\":\",color=\"b\")\n",
    "#     plt.plot(moving_average(feature[data_limit:,0]),\":\",color=\"r\")\n",
    "#     plt.show()\n",
    "    \n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(HPCstate)[:,0],np.array(HPCstate_noise)[:,0]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"HPC correlation\")\n",
    "#     HPC_activity = np.abs(feature[:data_limit,0]-feature[data_limit:,0])\n",
    "    HPC_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "\n",
    "\n",
    "    pca = PCA()\n",
    "#     dfs = np.array(PFCstate)[:,0]\n",
    "#     dfs = np.concatenate((np.array(PFCstate)[:,0],np.array(PFCstate_noise)[:,0]),axis=0)\n",
    "    dfs = np.concatenate((np.array(Restate)[:],np.array(Restate_noise)[:]),axis=0)\n",
    "    print(dfs.shape)\n",
    "    pca.fit(dfs)\n",
    "    feature = pca.transform(dfs)\n",
    "    print(\"Re correlation\")\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,0]-feature[100:,0])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,1]-feature[100:,1])))\n",
    "#     print(np.corrcoef(np.abs(traj[:,0,0]-traj_noise[:,0,0]),np.abs(feature[:100,2]-feature[100:,2])))\n",
    "#     Re_activity = np.abs(feature[:data_limit,0]-feature[data_limit:,0])\n",
    "    Re_activity = np.abs(moving_average(feature[:data_limit,0])-moving_average(feature[data_limit:,0]))\n",
    "#     Re_activity = np.abs((feature[:data_limit,0]-moving_average(feature[:data_limit,0])[2:-2])-(feature[data_limit:,0]-moving_average(feature[data_limit:,0])[2:-2]))\n",
    "#     Re_activity = culc_grad(moving_average(feature[:data_limit,0]))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(feature[:data_limit,0],color=\"b\")\n",
    "#     plt.plot(feature[data_limit:,0],color=\"r\")\n",
    "#     plt.plot(moving_average(feature[:data_limit,0]),\":\",color=\"b\")\n",
    "#     plt.plot(moving_average(feature[data_limit:,0]),\":\",color=\"r\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    return PFC_activity, HPC_activity, Re_activity\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]),HPC_d\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, frac_amp\n",
    "#     return np.mean([PFC_a,PFC_b,PFC_c]),np.mean([HPC_a,HPC_b,HPC_c]),np.max([PFC_d]), HPC_e, np.sum(coherence_diff_list)\n",
    "#     return np.max([PFC_a,PFC_b,PFC_c]),np.max([HPC_a,HPC_b,HPC_c])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fig = plt.figure()\n",
    "    correlation_fig = fig.subplots()\n",
    "#     correlation_fig.set_xlim(-1,1)\n",
    "#     correlation_fig.set_ylim(0,1)\n",
    "\n",
    "#     model_list = glob.glob('model/R20_131/*OUT1**s8_100_2_*epoch*.pth')\n",
    "#     model_list = sorted(model_list)\n",
    "#     model_list = sorted(model_list,key=len,reverse=False)\n",
    "#     k=0\n",
    "#     for model in model_list:\n",
    "#         print(model,PFC,HPC)\n",
    "#         PFC,HPC = main(model)\n",
    "# #         correlation_fig.plot(PFC,HPC,\"o\")\n",
    "# #         correlation_fig.text(PFC,HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         correlation_fig.plot(k*5,PFC/HPC,\"o\")\n",
    "# #         correlation_fig.text(k*5,PFC/HPC,model.split(\"epoch\")[-1].split(\".\")[0])\n",
    "#         k+=1\n",
    "\n",
    "    allRe_list = []\n",
    "    allHPC_list = []\n",
    "    allPFC_list = []\n",
    "    for num in range(3):\n",
    "        for i in range(10):\n",
    "            path = 'model/R20_H_bigbatch/'\n",
    "#             path = 'model/R20_H_uniHPC_bigbatch/'\n",
    "            model_list = glob.glob(path+'*s'+str(i+1)+'_100_'+str(num+1)+'_*epoch*.pth')\n",
    "            model_list = sorted(model_list)\n",
    "            model_list = sorted(model_list,key=len,reverse=False)\n",
    "            Re_list = []\n",
    "            ratio_list_max = []\n",
    "            with open(path+\"good_list.txt\", mode=\"r\") as f:\n",
    "                good_list = f.read().splitlines()\n",
    "#             good_list = []\n",
    "#             if i+1 == 4 and num+1 == 3:\n",
    "#                 continue\n",
    "#             if i+1 == 5 and num+1 == 2:\n",
    "#                 continue\n",
    "            \n",
    "            first_goodmodel = [0,0]\n",
    "            good_flag = False\n",
    "            k=0\n",
    "            for model in model_list:\n",
    "#                 if model in good_list:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     continue\n",
    "                print(model)\n",
    "                if int(model.split(\"epoch\")[-1].split(\".\")[0])>299:\n",
    "                    continue\n",
    "                PFC_activity, HPC_activity, Re_activity = main(model)\n",
    "                allRe_list.append(Re_activity)\n",
    "                allHPC_list.append(HPC_activity)\n",
    "                allPFC_list.append(PFC_activity)\n",
    "\n",
    "                k+=1\n",
    "#             correlation_fig.plot(Re_activity,color=\"C{}\".format(i))\n",
    "    allRe_list = np.array(allRe_list)\n",
    "    allHPC_list = np.array(allHPC_list)\n",
    "    allPFC_list = np.array(allPFC_list)\n",
    "    print(allRe_list.shape)\n",
    "    correlation_fig.plot(np.mean(allRe_list,axis=0).T,color=\"C0\")\n",
    "    correlation_fig.errorbar(np.arange(allRe_list.shape[1]),np.mean(allRe_list,axis=0).T,yerr=np.sqrt(np.var(allRe_list,axis=0).T), color=\"C0\", alpha=0.3)\n",
    "#     correlation_fig.plot(np.mean(allHPC_list,axis=0).T,color=\"C1\")\n",
    "#     correlation_fig.errorbar(np.arange(allHPC_list.shape[1]),np.mean(allHPC_list,axis=0).T,yerr=np.sqrt(np.var(allHPC_list,axis=0).T), color=\"C1\", alpha=0.3)\n",
    "#     correlation_fig.plot(np.mean(allPFC_list,axis=0).T,color=\"C2\")\n",
    "#     correlation_fig.errorbar(np.arange(allPFC_list.shape[1]),np.mean(allPFC_list,axis=0).T,yerr=np.sqrt(np.var(allPFC_list,axis=0).T), color=\"C2\", alpha=0.3)\n",
    "\n",
    "#             allratio_list.append(np.array(ratio_list_max))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
